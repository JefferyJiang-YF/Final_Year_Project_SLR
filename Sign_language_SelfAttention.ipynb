{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d00ef8b",
   "metadata": {},
   "source": [
    "## 1. Import and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026a05f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T04:08:25.323067Z",
     "start_time": "2023-01-12T04:08:24.567024Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pip install --user tensorflow==2.6.0 tensorflow-gpu==2.6.0 opencv-python mediapipe sklearn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bc7e92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T08:53:52.807044Z",
     "start_time": "2023-01-15T08:53:51.645005Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from keras_self_attention import SeqSelfAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a61cdf6",
   "metadata": {},
   "source": [
    "## 2. Keypoints using Mediapipe Holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dd32af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T08:53:53.744988Z",
     "start_time": "2023-01-15T08:53:53.739007Z"
    }
   },
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic #Holistic model 整体模型mp\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities 绘图工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da11ddb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T08:53:54.398998Z",
     "start_time": "2023-01-15T08:53:54.388036Z"
    }
   },
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR Conversion BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                  # Image is now writeable\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR Conversion RGB 2  BGR\n",
    "    return image, results\n",
    "\n",
    "def draw_styled_landmarks(image, results):\n",
    "    \n",
    "     # 轮廓线 Draw face connection\n",
    "    #mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS,\n",
    "                             #mp_drawing.DrawingSpec(color=(80,110,10), thickness = 1, circle_radius = 1),\n",
    "                             #mp_drawing.DrawingSpec(color=(80,256,121), thickness = 1, circle_radius = 1))\n",
    "    \n",
    "     # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness = 2, circle_radius = 4),\n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness = 2, circle_radius = 2)) \n",
    "    \n",
    "    # draw left hand connections,\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness = 2, circle_radius = 4),\n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness = 2, circle_radius = 2))\n",
    "    \n",
    "    # draw right hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness = 2, circle_radius = 4),\n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness = 2, circle_radius = 2))\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    #如果frame中没有左手关键点就会抛出错误 注意左右手没有 res.visibility参数\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)# 压平 33 * 4\n",
    "    #face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose,face,lh,rh])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd8b2d3",
   "metadata": {},
   "source": [
    "## 4. Setup folders for collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce4d55b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T08:54:37.196994Z",
     "start_time": "2023-01-15T08:54:37.188023Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays 制作关键点数据集文件夹\n",
    "DATA_PATH = os.path.join('data/train') \n",
    "wlasl = ['book', 'drink', 'computer', 'before', 'chair', 'go', 'clothes', 'who', 'candy', 'cousin','deaf', 'fine', 'help', 'no', 'thin', 'walk', 'year', 'yes', 'all', 'black', 'cool', 'finish', 'hot', 'like', 'many', 'mother', 'now', 'orange', 'table', 'thanksgiving', 'what', 'woman', 'bed', 'blue', 'bowling', 'can', 'dog', 'white', 'wrong', 'accident', 'apple', 'bird', 'change', 'color', 'corn', 'cow', 'dance', 'dark', 'doctor']\n",
    "# Actions that we try to detect 只需要在这里加action即可 参考路径 data\\WLASL_train下的文件名\n",
    "actions = np.array(sorted(wlasl[0:10]))\n",
    "\n",
    "# Thirty videos worth of data\n",
    "#no_sequences = 40\n",
    "\n",
    "# Videos are going to be 30 frames in length\n",
    "sequence_length = 30\n",
    "print(len(sorted(wlasl[0:20])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4001a4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 获取视频数据集中每条视频帧的数量，i.e.,no_fps 并保存到 fps_list\n",
    "for action in actions:\n",
    "    fps_list = []\n",
    "    for root, dirs, files in os.walk(r\"rawdata\\train\\{}\".format(action)):  # 这里就填文件夹目录就可以了\n",
    "        for file in files:\n",
    "            # 获取文件路径\n",
    "            if ('.mp4' in file):\n",
    "                path = os.path.join(root, file)\n",
    "                video = cv2.VideoCapture(path)\n",
    "                no_fps = video.get(7)\n",
    "                # video_fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "                fps_list.append(no_fps)\n",
    "        print(action, \"'s # of videos: \", len(files)) # 把这个数 可以作为no_sequences 视频数量 ！！注意必须与此Cell中#2 for 循环一起组合使用，否则len（files）数量不正确。原因是得不到正确的遍历，值只为最后一个动作的文件数总和\n",
    "        print(\"The frames that each video contains: \", fps_list,'\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff7e948b",
   "metadata": {},
   "source": [
    "## Preprocess Data and Create Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056be4cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:06:02.288957Z",
     "start_time": "2023-01-15T09:05:47.251110Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9c196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data(base_data_path, actions, sequence_length):\n",
    "    label_map = {label: num for num, label in enumerate(actions)}\n",
    "    sequences, labels = [], []\n",
    "    for action in actions:\n",
    "        source_folder = os.path.join(base_data_path, action)\n",
    "        leng = len(os.listdir(source_folder))\n",
    "        for sequence in range(leng):\n",
    "            window = []\n",
    "            for frame_num in range(sequence_length):\n",
    "                frame_path = os.path.join(source_folder, str(sequence), \"{}.npy\".format(frame_num))\n",
    "                res = np.load(frame_path)\n",
    "                window.append(res)\n",
    "            sequences.append(window)\n",
    "            labels.append(label_map[action])\n",
    "    print(label_map)\n",
    "    return sequences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee5288",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"data/train\"\n",
    "val_data_path = \"data/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a04c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences, train_labels = label_data(train_data_path, actions, sequence_length)\n",
    "val_sequences, val_labels = label_data(val_data_path, actions, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4577a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to_categorical(labels).astype(int) on labels\n",
    "train_labels_categorical = to_categorical(train_labels).astype(int)\n",
    "val_labels_categorical = to_categorical(val_labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e3c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(train_sequences),train_labels_categorical\n",
    "X_val, y_val = np.array(val_sequences), val_labels_categorical"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7b73198",
   "metadata": {},
   "source": [
    "## 7. Build and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35120426",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:07:04.827943Z",
     "start_time": "2023-01-15T09:07:04.814988Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Model # allow us to build a sequential neural network\n",
    "from tensorflow.python.keras.layers import LSTM, Dense, Input # LSTM: temoporal component, Dense: a normal fully connected layer\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint # allow us to perform some logging inside, trace and monitor our model as its training\n",
    "import datetime\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648111ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:07:06.339016Z",
     "start_time": "2023-01-15T09:07:06.239069Z"
    }
   },
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "log_dir = os.path.join('Logs', now.strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "print(now.strftime(\"%Y-%m-%d-%H-%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53395f4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:07:10.431039Z",
     "start_time": "2023-01-15T09:07:09.499971Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def create_model(input_shape, num_heads):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    attention = tf.keras.layers.MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=input_shape[1]\n",
    "    )(inputs, inputs, inputs)\n",
    "    avg_pool = tf.keras.layers.GlobalAveragePooling1D()(attention)\n",
    "    dense = Dense(64, activation=\"relu\")(avg_pool)\n",
    "    outputs = Dense(len(actions), activation=\"softmax\")(dense)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2410581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992d06ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T08:07:07.457203Z",
     "start_time": "2023-01-12T08:07:07.445242Z"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = (sequence_length, train_sequences[0][0].shape[0])\n",
    "num_heads = 8\n",
    "# Create the model\n",
    "model = create_model(input_shape, num_heads)\n",
    "plot_model(model, to_file=\"model.png\", show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accc22f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:07:20.027889Z",
     "start_time": "2023-01-15T09:07:19.994002Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bb5588",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:15:36.389020Z",
     "start_time": "2023-01-15T09:07:28.159038Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set up the ModelCheckpoint callback\n",
    "checkpoint_filepath = (\"models/best_model_weights.h5\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab299f12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T08:51:58.867225Z",
     "start_time": "2023-01-12T08:51:58.857258Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=2000,\n",
    "    batch_size=32,\n",
    "    callbacks=[checkpoint_callback, tb_callback]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61474e21",
   "metadata": {},
   "source": [
    "## Save Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f76ac20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T08:58:39.742207Z",
     "start_time": "2023-01-12T08:58:39.736226Z"
    }
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f68c5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T08:59:30.091317Z",
     "start_time": "2023-01-12T08:59:30.064297Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the best model weights\n",
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6589a532",
   "metadata": {},
   "source": [
    "## 10. Evaluation using Confusion Matrix and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b75086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the H5 file\n",
    "model_path = \"models/best_model_weights_ten.h5\"\n",
    "model = model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2f925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .npy data\n",
    "def load_data(base_data_path, actions, sequence_length):\n",
    "    label_map = {label: num for num, label in enumerate(actions)}\n",
    "    sequences, labels = [], []\n",
    "    for action in actions:\n",
    "        source_folder = os.path.join(base_data_path, action)\n",
    "        leng = len(os.listdir(source_folder))\n",
    "        for sequence in range(leng):\n",
    "            window = []\n",
    "            for frame_num in range(sequence_length):\n",
    "                frame_path = os.path.join(source_folder, str(sequence), \"{}.npy\".format(frame_num))\n",
    "                res = np.load(frame_path)\n",
    "                window.append(res)\n",
    "            sequences.append(window)\n",
    "            labels.append(label_map[action])\n",
    "    return sequences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde64f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths to your test data and actions\n",
    "test_data_path = \"data/test\"\n",
    "actions = np.array(['book', 'drink', 'computer', 'before', 'chair', 'go', 'clothes', 'who', 'candy', 'cousin'])  # Update this list with your action names\n",
    "sequence_length = 30  # Update this with your sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef328b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data and convert the labels to categorical\n",
    "test_sequences, test_labels = load_data(test_data_path, actions, sequence_length)\n",
    "test_labels_categorical = to_categorical(test_labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae30307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the sequences and labels to NumPy arrays\n",
    "X_test, y_test = np.array(test_sequences), test_labels_categorical\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Get the predicted class indices\n",
    "predicted_class_indices = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(test_labels, predicted_class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4396148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=actions, yticklabels=actions)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c90091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(test_labels, predicted_class_indices)\n",
    "print(\"Test accuracy: {:.4f}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp-tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "249.797px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
