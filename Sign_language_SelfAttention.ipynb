{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d00ef8b",
   "metadata": {},
   "source": [
    "## 1. Import and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026a05f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T04:08:25.323067Z",
     "start_time": "2023-01-12T04:08:24.567024Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pip install --user tensorflow==2.6.0 tensorflow-gpu==2.6.0 opencv-python mediapipe sklearn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8bc7e92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T08:53:52.807044Z",
     "start_time": "2023-01-15T08:53:51.645005Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from keras_self_attention import SeqSelfAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a61cdf6",
   "metadata": {},
   "source": [
    "## 2. Keypoints using Mediapipe Holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5dd32af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T08:53:53.744988Z",
     "start_time": "2023-01-15T08:53:53.739007Z"
    }
   },
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic #Holistic model 整体模型mp\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities 绘图工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da11ddb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T08:53:54.398998Z",
     "start_time": "2023-01-15T08:53:54.388036Z"
    }
   },
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR Conversion BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                  # Image is now writeable\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR Conversion RGB 2  BGR\n",
    "    return image, results\n",
    "\n",
    "def draw_styled_landmarks(image, results):\n",
    "    \n",
    "     # 轮廓线 Draw face connection\n",
    "    #mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS,\n",
    "                             #mp_drawing.DrawingSpec(color=(80,110,10), thickness = 1, circle_radius = 1),\n",
    "                             #mp_drawing.DrawingSpec(color=(80,256,121), thickness = 1, circle_radius = 1))\n",
    "    \n",
    "     # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness = 2, circle_radius = 4),\n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness = 2, circle_radius = 2)) \n",
    "    \n",
    "    # draw left hand connections,\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness = 2, circle_radius = 4),\n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness = 2, circle_radius = 2))\n",
    "    \n",
    "    # draw right hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness = 2, circle_radius = 4),\n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness = 2, circle_radius = 2))\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    #如果frame中没有左手关键点就会抛出错误 注意左右手没有 res.visibility参数\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)# 压平 33 * 4\n",
    "    #face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose,face,lh,rh])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd8b2d3",
   "metadata": {},
   "source": [
    "## 4. Setup folders for collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1ce4d55b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T08:54:37.196994Z",
     "start_time": "2023-01-15T08:54:37.188023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# Path for exported data, numpy arrays 制作关键点数据集文件夹\n",
    "DATA_PATH = os.path.join('data/train') \n",
    "wlasl = ['book', 'drink', 'computer', 'before', 'chair', 'go', 'clothes', 'who', 'candy', 'cousin','deaf', 'fine', 'help', 'no', 'thin', 'walk', 'year', 'yes', 'all', 'black', 'cool', 'finish', 'hot', 'like', 'many', 'mother', 'now', 'orange', 'table', 'thanksgiving', 'what', 'woman', 'bed', 'blue', 'bowling', 'can', 'dog', 'white', 'wrong', 'accident', 'apple', 'bird', 'change', 'color', 'corn', 'cow', 'dance', 'dark', 'doctor']\n",
    "# Actions that we try to detect 只需要在这里加action即可 参考路径 data\\WLASL_train下的文件名\n",
    "actions = np.array(sorted(wlasl[0:10]))\n",
    "\n",
    "# Thirty videos worth of data\n",
    "#no_sequences = 40\n",
    "\n",
    "# Videos are going to be 30 frames in length\n",
    "sequence_length = 30\n",
    "print(len(sorted(wlasl[0:20])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4001a4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 获取视频数据集中每条视频帧的数量，i.e.,no_fps 并保存到 fps_list\n",
    "for action in actions:\n",
    "    fps_list = []\n",
    "    for root, dirs, files in os.walk(r\"rawdata\\train\\{}\".format(action)):  # 这里就填文件夹目录就可以了\n",
    "        for file in files:\n",
    "            # 获取文件路径\n",
    "            if ('.mp4' in file):\n",
    "                path = os.path.join(root, file)\n",
    "                video = cv2.VideoCapture(path)\n",
    "                no_fps = video.get(7)\n",
    "                # video_fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "                fps_list.append(no_fps)\n",
    "        print(action, \"'s # of videos: \", len(files)) # 把这个数 可以作为no_sequences 视频数量 ！！注意必须与此Cell中#2 for 循环一起组合使用，否则len（files）数量不正确。原因是得不到正确的遍历，值只为最后一个动作的文件数总和\n",
    "        print(\"The frames that each video contains: \", fps_list,'\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff7e948b",
   "metadata": {},
   "source": [
    "## Preprocess Data and Create Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "056be4cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:06:02.288957Z",
     "start_time": "2023-01-15T09:05:47.251110Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2a9c196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data(base_data_path, actions, sequence_length):\n",
    "    label_map = {label: num for num, label in enumerate(actions)}\n",
    "    sequences, labels = [], []\n",
    "    for action in actions:\n",
    "        source_folder = os.path.join(base_data_path, action)\n",
    "        leng = len(os.listdir(source_folder))\n",
    "        for sequence in range(leng):\n",
    "            window = []\n",
    "            for frame_num in range(sequence_length):\n",
    "                frame_path = os.path.join(source_folder, str(sequence), \"{}.npy\".format(frame_num))\n",
    "                res = np.load(frame_path)\n",
    "                window.append(res)\n",
    "            sequences.append(window)\n",
    "            labels.append(label_map[action])\n",
    "    print(label_map)\n",
    "    return sequences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eaee5288",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"data/train\"\n",
    "val_data_path = \"data/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "92a04c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'before': 0, 'book': 1, 'candy': 2, 'chair': 3, 'clothes': 4, 'computer': 5, 'cousin': 6, 'drink': 7, 'go': 8, 'who': 9}\n",
      "{'before': 0, 'book': 1, 'candy': 2, 'chair': 3, 'clothes': 4, 'computer': 5, 'cousin': 6, 'drink': 7, 'go': 8, 'who': 9}\n"
     ]
    }
   ],
   "source": [
    "train_sequences, train_labels = label_data(train_data_path, actions, sequence_length)\n",
    "val_sequences, val_labels = label_data(val_data_path, actions, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4577a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to_categorical(labels).astype(int) on labels\n",
    "train_labels_categorical = to_categorical(train_labels).astype(int)\n",
    "val_labels_categorical = to_categorical(val_labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "20e3c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(train_sequences),train_labels_categorical\n",
    "X_val, y_val = np.array(val_sequences), val_labels_categorical"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7b73198",
   "metadata": {},
   "source": [
    "## 7. Build and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "35120426",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:07:04.827943Z",
     "start_time": "2023-01-15T09:07:04.814988Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Model # allow us to build a sequential neural network\n",
    "from tensorflow.python.keras.layers import LSTM, Dense, Input # LSTM: temoporal component, Dense: a normal fully connected layer\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint # allow us to perform some logging inside, trace and monitor our model as its training\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "648111ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:07:06.339016Z",
     "start_time": "2023-01-15T09:07:06.239069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-10-12-08\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "log_dir = os.path.join('Logs', now.strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "print(now.strftime(\"%Y-%m-%d-%H-%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "53395f4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:07:10.431039Z",
     "start_time": "2023-01-15T09:07:09.499971Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def create_model(input_shape, num_heads):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    attention = tf.keras.layers.MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=input_shape[1]\n",
    "    )(inputs, inputs, inputs)\n",
    "    avg_pool = tf.keras.layers.GlobalAveragePooling1D()(attention)\n",
    "    dense = Dense(64, activation=\"relu\")(avg_pool)\n",
    "    outputs = Dense(len(actions), activation=\"softmax\")(dense)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2410581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992d06ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T08:07:07.457203Z",
     "start_time": "2023-01-12T08:07:07.445242Z"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = (sequence_length, train_sequences[0][0].shape[0])\n",
    "num_heads = 8\n",
    "# Create the model\n",
    "model = create_model(input_shape, num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "accc22f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:07:20.027889Z",
     "start_time": "2023-01-15T09:07:19.994002Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "23bb5588",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:15:36.389020Z",
     "start_time": "2023-01-15T09:07:28.159038Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set up the ModelCheckpoint callback\n",
    "checkpoint_filepath = (\"models/best_model_weights.h5\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ab299f12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T08:51:58.867225Z",
     "start_time": "2023-01-12T08:51:58.857258Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer tf.__operators__.add_24 was passed non-JSON-serializable arguments. Arguments had types: {'y': <class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>, 'name': <class 'NoneType'>}. They cannot be serialized out when saving the model.\n",
      "Epoch 1/2000\n",
      "6/6 [==============================] - 1s 58ms/step - loss: 2.3077 - accuracy: 0.1053 - val_loss: 2.3013 - val_accuracy: 0.1316\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.30127, saving model to models\\best_model_weights.h5\n",
      "Epoch 2/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.2940 - accuracy: 0.1111 - val_loss: 2.2976 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.30127 to 2.29763, saving model to models\\best_model_weights.h5\n",
      "Epoch 3/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.2857 - accuracy: 0.1637 - val_loss: 2.2953 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.29763 to 2.29535, saving model to models\\best_model_weights.h5\n",
      "Epoch 4/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.2792 - accuracy: 0.1462 - val_loss: 2.2929 - val_accuracy: 0.1316\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.29535 to 2.29290, saving model to models\\best_model_weights.h5\n",
      "Epoch 5/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.2730 - accuracy: 0.1462 - val_loss: 2.2902 - val_accuracy: 0.1316\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.29290 to 2.29021, saving model to models\\best_model_weights.h5\n",
      "Epoch 6/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.2655 - accuracy: 0.1696 - val_loss: 2.2863 - val_accuracy: 0.1316\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.29021 to 2.28628, saving model to models\\best_model_weights.h5\n",
      "Epoch 7/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.2599 - accuracy: 0.2164 - val_loss: 2.2829 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.28628 to 2.28290, saving model to models\\best_model_weights.h5\n",
      "Epoch 8/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2520 - accuracy: 0.2573 - val_loss: 2.2789 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.28290 to 2.27887, saving model to models\\best_model_weights.h5\n",
      "Epoch 9/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.2446 - accuracy: 0.2632 - val_loss: 2.2727 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.27887 to 2.27271, saving model to models\\best_model_weights.h5\n",
      "Epoch 10/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.2374 - accuracy: 0.2690 - val_loss: 2.2667 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.27271 to 2.26673, saving model to models\\best_model_weights.h5\n",
      "Epoch 11/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2299 - accuracy: 0.2690 - val_loss: 2.2611 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.26673 to 2.26110, saving model to models\\best_model_weights.h5\n",
      "Epoch 12/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.2208 - accuracy: 0.2690 - val_loss: 2.2544 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.26110 to 2.25437, saving model to models\\best_model_weights.h5\n",
      "Epoch 13/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.2117 - accuracy: 0.2690 - val_loss: 2.2474 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.25437 to 2.24740, saving model to models\\best_model_weights.h5\n",
      "Epoch 14/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.2024 - accuracy: 0.2749 - val_loss: 2.2414 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.24740 to 2.24144, saving model to models\\best_model_weights.h5\n",
      "Epoch 15/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.1931 - accuracy: 0.2749 - val_loss: 2.2353 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.24144 to 2.23532, saving model to models\\best_model_weights.h5\n",
      "Epoch 16/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.1830 - accuracy: 0.2749 - val_loss: 2.2290 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.23532 to 2.22902, saving model to models\\best_model_weights.h5\n",
      "Epoch 17/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1704 - accuracy: 0.2749 - val_loss: 2.2216 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.22902 to 2.22156, saving model to models\\best_model_weights.h5\n",
      "Epoch 18/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1602 - accuracy: 0.2749 - val_loss: 2.2147 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.22156 to 2.21468, saving model to models\\best_model_weights.h5\n",
      "Epoch 19/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.1484 - accuracy: 0.2749 - val_loss: 2.2078 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.21468 to 2.20781, saving model to models\\best_model_weights.h5\n",
      "Epoch 20/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.1370 - accuracy: 0.2749 - val_loss: 2.1989 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.20781 to 2.19894, saving model to models\\best_model_weights.h5\n",
      "Epoch 21/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1258 - accuracy: 0.2749 - val_loss: 2.1917 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.19894 to 2.19175, saving model to models\\best_model_weights.h5\n",
      "Epoch 22/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.1128 - accuracy: 0.2749 - val_loss: 2.1836 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.19175 to 2.18362, saving model to models\\best_model_weights.h5\n",
      "Epoch 23/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.1009 - accuracy: 0.2749 - val_loss: 2.1745 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.18362 to 2.17453, saving model to models\\best_model_weights.h5\n",
      "Epoch 24/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.0891 - accuracy: 0.2749 - val_loss: 2.1665 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.17453 to 2.16649, saving model to models\\best_model_weights.h5\n",
      "Epoch 25/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.0773 - accuracy: 0.2749 - val_loss: 2.1584 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.16649 to 2.15837, saving model to models\\best_model_weights.h5\n",
      "Epoch 26/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.0653 - accuracy: 0.2749 - val_loss: 2.1484 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.15837 to 2.14841, saving model to models\\best_model_weights.h5\n",
      "Epoch 27/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.0533 - accuracy: 0.2749 - val_loss: 2.1403 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.14841 to 2.14033, saving model to models\\best_model_weights.h5\n",
      "Epoch 28/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.0433 - accuracy: 0.2749 - val_loss: 2.1336 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.14033 to 2.13357, saving model to models\\best_model_weights.h5\n",
      "Epoch 29/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.0313 - accuracy: 0.2749 - val_loss: 2.1255 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.13357 to 2.12550, saving model to models\\best_model_weights.h5\n",
      "Epoch 30/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.0202 - accuracy: 0.2749 - val_loss: 2.1188 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.12550 to 2.11875, saving model to models\\best_model_weights.h5\n",
      "Epoch 31/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.0103 - accuracy: 0.2749 - val_loss: 2.1125 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.11875 to 2.11255, saving model to models\\best_model_weights.h5\n",
      "Epoch 32/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9999 - accuracy: 0.2749 - val_loss: 2.1087 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.11255 to 2.10868, saving model to models\\best_model_weights.h5\n",
      "Epoch 33/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.9905 - accuracy: 0.2749 - val_loss: 2.1029 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.10868 to 2.10293, saving model to models\\best_model_weights.h5\n",
      "Epoch 34/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.9810 - accuracy: 0.2749 - val_loss: 2.0979 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.10293 to 2.09786, saving model to models\\best_model_weights.h5\n",
      "Epoch 35/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.9729 - accuracy: 0.2749 - val_loss: 2.0907 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.09786 to 2.09065, saving model to models\\best_model_weights.h5\n",
      "Epoch 36/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9646 - accuracy: 0.2749 - val_loss: 2.0856 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.09065 to 2.08557, saving model to models\\best_model_weights.h5\n",
      "Epoch 37/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.9572 - accuracy: 0.2749 - val_loss: 2.0800 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00037: val_loss improved from 2.08557 to 2.08004, saving model to models\\best_model_weights.h5\n",
      "Epoch 38/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.9499 - accuracy: 0.2749 - val_loss: 2.0768 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00038: val_loss improved from 2.08004 to 2.07679, saving model to models\\best_model_weights.h5\n",
      "Epoch 39/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.9430 - accuracy: 0.2749 - val_loss: 2.0728 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00039: val_loss improved from 2.07679 to 2.07275, saving model to models\\best_model_weights.h5\n",
      "Epoch 40/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.9360 - accuracy: 0.2749 - val_loss: 2.0676 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00040: val_loss improved from 2.07275 to 2.06755, saving model to models\\best_model_weights.h5\n",
      "Epoch 41/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.9292 - accuracy: 0.2807 - val_loss: 2.0635 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00041: val_loss improved from 2.06755 to 2.06350, saving model to models\\best_model_weights.h5\n",
      "Epoch 42/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.9239 - accuracy: 0.2807 - val_loss: 2.0610 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00042: val_loss improved from 2.06350 to 2.06102, saving model to models\\best_model_weights.h5\n",
      "Epoch 43/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.9181 - accuracy: 0.2749 - val_loss: 2.0566 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00043: val_loss improved from 2.06102 to 2.05661, saving model to models\\best_model_weights.h5\n",
      "Epoch 44/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.9129 - accuracy: 0.2749 - val_loss: 2.0547 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00044: val_loss improved from 2.05661 to 2.05473, saving model to models\\best_model_weights.h5\n",
      "Epoch 45/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.9078 - accuracy: 0.2807 - val_loss: 2.0541 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00045: val_loss improved from 2.05473 to 2.05411, saving model to models\\best_model_weights.h5\n",
      "Epoch 46/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.9031 - accuracy: 0.2807 - val_loss: 2.0505 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00046: val_loss improved from 2.05411 to 2.05048, saving model to models\\best_model_weights.h5\n",
      "Epoch 47/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8989 - accuracy: 0.2807 - val_loss: 2.0467 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00047: val_loss improved from 2.05048 to 2.04672, saving model to models\\best_model_weights.h5\n",
      "Epoch 48/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.8945 - accuracy: 0.2807 - val_loss: 2.0449 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00048: val_loss improved from 2.04672 to 2.04490, saving model to models\\best_model_weights.h5\n",
      "Epoch 49/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8902 - accuracy: 0.2865 - val_loss: 2.0405 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00049: val_loss improved from 2.04490 to 2.04054, saving model to models\\best_model_weights.h5\n",
      "Epoch 50/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.8868 - accuracy: 0.2865 - val_loss: 2.0374 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00050: val_loss improved from 2.04054 to 2.03736, saving model to models\\best_model_weights.h5\n",
      "Epoch 51/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8835 - accuracy: 0.2865 - val_loss: 2.0350 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00051: val_loss improved from 2.03736 to 2.03497, saving model to models\\best_model_weights.h5\n",
      "Epoch 52/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8799 - accuracy: 0.2865 - val_loss: 2.0323 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00052: val_loss improved from 2.03497 to 2.03234, saving model to models\\best_model_weights.h5\n",
      "Epoch 53/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8760 - accuracy: 0.2865 - val_loss: 2.0309 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00053: val_loss improved from 2.03234 to 2.03093, saving model to models\\best_model_weights.h5\n",
      "Epoch 54/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8736 - accuracy: 0.2865 - val_loss: 2.0305 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00054: val_loss improved from 2.03093 to 2.03053, saving model to models\\best_model_weights.h5\n",
      "Epoch 55/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8696 - accuracy: 0.2865 - val_loss: 2.0288 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00055: val_loss improved from 2.03053 to 2.02884, saving model to models\\best_model_weights.h5\n",
      "Epoch 56/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.8662 - accuracy: 0.2865 - val_loss: 2.0281 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00056: val_loss improved from 2.02884 to 2.02811, saving model to models\\best_model_weights.h5\n",
      "Epoch 57/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8634 - accuracy: 0.2865 - val_loss: 2.0235 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00057: val_loss improved from 2.02811 to 2.02347, saving model to models\\best_model_weights.h5\n",
      "Epoch 58/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.8599 - accuracy: 0.2865 - val_loss: 2.0192 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00058: val_loss improved from 2.02347 to 2.01920, saving model to models\\best_model_weights.h5\n",
      "Epoch 59/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8572 - accuracy: 0.2865 - val_loss: 2.0172 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00059: val_loss improved from 2.01920 to 2.01716, saving model to models\\best_model_weights.h5\n",
      "Epoch 60/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8542 - accuracy: 0.2865 - val_loss: 2.0137 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00060: val_loss improved from 2.01716 to 2.01366, saving model to models\\best_model_weights.h5\n",
      "Epoch 61/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.8516 - accuracy: 0.2865 - val_loss: 2.0139 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 2.01366\n",
      "Epoch 62/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.8498 - accuracy: 0.2924 - val_loss: 2.0132 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00062: val_loss improved from 2.01366 to 2.01324, saving model to models\\best_model_weights.h5\n",
      "Epoch 63/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8480 - accuracy: 0.2924 - val_loss: 2.0144 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 2.01324\n",
      "Epoch 64/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.8455 - accuracy: 0.2807 - val_loss: 2.0137 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 2.01324\n",
      "Epoch 65/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.8436 - accuracy: 0.2807 - val_loss: 2.0121 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00065: val_loss improved from 2.01324 to 2.01208, saving model to models\\best_model_weights.h5\n",
      "Epoch 66/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8419 - accuracy: 0.2807 - val_loss: 2.0144 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 2.01208\n",
      "Epoch 67/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.8393 - accuracy: 0.2865 - val_loss: 2.0145 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 2.01208\n",
      "Epoch 68/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8363 - accuracy: 0.2865 - val_loss: 2.0116 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00068: val_loss improved from 2.01208 to 2.01155, saving model to models\\best_model_weights.h5\n",
      "Epoch 69/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.8345 - accuracy: 0.2865 - val_loss: 2.0098 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00069: val_loss improved from 2.01155 to 2.00985, saving model to models\\best_model_weights.h5\n",
      "Epoch 70/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.8327 - accuracy: 0.2807 - val_loss: 2.0090 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00070: val_loss improved from 2.00985 to 2.00901, saving model to models\\best_model_weights.h5\n",
      "Epoch 71/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8301 - accuracy: 0.2807 - val_loss: 2.0081 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00071: val_loss improved from 2.00901 to 2.00812, saving model to models\\best_model_weights.h5\n",
      "Epoch 72/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.8299 - accuracy: 0.2807 - val_loss: 2.0067 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00072: val_loss improved from 2.00812 to 2.00668, saving model to models\\best_model_weights.h5\n",
      "Epoch 73/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.8260 - accuracy: 0.2807 - val_loss: 2.0032 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00073: val_loss improved from 2.00668 to 2.00321, saving model to models\\best_model_weights.h5\n",
      "Epoch 74/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8244 - accuracy: 0.2807 - val_loss: 2.0014 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00074: val_loss improved from 2.00321 to 2.00142, saving model to models\\best_model_weights.h5\n",
      "Epoch 75/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8238 - accuracy: 0.2865 - val_loss: 2.0013 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00075: val_loss improved from 2.00142 to 2.00125, saving model to models\\best_model_weights.h5\n",
      "Epoch 76/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.8217 - accuracy: 0.2749 - val_loss: 2.0000 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00076: val_loss improved from 2.00125 to 2.00004, saving model to models\\best_model_weights.h5\n",
      "Epoch 77/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.8198 - accuracy: 0.2749 - val_loss: 2.0002 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 2.00004\n",
      "Epoch 78/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.8188 - accuracy: 0.2749 - val_loss: 2.0011 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 2.00004\n",
      "Epoch 79/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.8176 - accuracy: 0.2865 - val_loss: 1.9998 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00079: val_loss improved from 2.00004 to 1.99978, saving model to models\\best_model_weights.h5\n",
      "Epoch 80/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.8151 - accuracy: 0.2807 - val_loss: 1.9992 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00080: val_loss improved from 1.99978 to 1.99920, saving model to models\\best_model_weights.h5\n",
      "Epoch 81/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8140 - accuracy: 0.2749 - val_loss: 1.9970 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00081: val_loss improved from 1.99920 to 1.99702, saving model to models\\best_model_weights.h5\n",
      "Epoch 82/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.8112 - accuracy: 0.2865 - val_loss: 1.9982 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.99702\n",
      "Epoch 83/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8102 - accuracy: 0.2865 - val_loss: 2.0006 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.99702\n",
      "Epoch 84/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8084 - accuracy: 0.2865 - val_loss: 1.9987 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.99702\n",
      "Epoch 85/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8055 - accuracy: 0.2807 - val_loss: 1.9972 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.99702\n",
      "Epoch 86/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8055 - accuracy: 0.2690 - val_loss: 1.9974 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.99702\n",
      "Epoch 87/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.8026 - accuracy: 0.2690 - val_loss: 1.9946 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00087: val_loss improved from 1.99702 to 1.99462, saving model to models\\best_model_weights.h5\n",
      "Epoch 88/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.8013 - accuracy: 0.2749 - val_loss: 1.9909 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00088: val_loss improved from 1.99462 to 1.99087, saving model to models\\best_model_weights.h5\n",
      "Epoch 89/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.8000 - accuracy: 0.2749 - val_loss: 1.9898 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00089: val_loss improved from 1.99087 to 1.98976, saving model to models\\best_model_weights.h5\n",
      "Epoch 90/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7991 - accuracy: 0.2807 - val_loss: 1.9917 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.98976\n",
      "Epoch 91/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.7984 - accuracy: 0.2807 - val_loss: 1.9936 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.98976\n",
      "Epoch 92/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7970 - accuracy: 0.2749 - val_loss: 1.9909 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.98976\n",
      "Epoch 93/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.7940 - accuracy: 0.2749 - val_loss: 1.9898 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.98976\n",
      "Epoch 94/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7933 - accuracy: 0.2749 - val_loss: 1.9904 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.98976\n",
      "Epoch 95/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.7921 - accuracy: 0.2807 - val_loss: 1.9874 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00095: val_loss improved from 1.98976 to 1.98745, saving model to models\\best_model_weights.h5\n",
      "Epoch 96/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.7910 - accuracy: 0.2924 - val_loss: 1.9850 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00096: val_loss improved from 1.98745 to 1.98495, saving model to models\\best_model_weights.h5\n",
      "Epoch 97/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.7887 - accuracy: 0.2807 - val_loss: 1.9865 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.98495\n",
      "Epoch 98/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7873 - accuracy: 0.2749 - val_loss: 1.9877 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.98495\n",
      "Epoch 99/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7875 - accuracy: 0.2690 - val_loss: 1.9896 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.98495\n",
      "Epoch 100/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.7856 - accuracy: 0.2690 - val_loss: 1.9856 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.98495\n",
      "Epoch 101/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7830 - accuracy: 0.2749 - val_loss: 1.9845 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00101: val_loss improved from 1.98495 to 1.98450, saving model to models\\best_model_weights.h5\n",
      "Epoch 102/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7813 - accuracy: 0.2924 - val_loss: 1.9845 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00102: val_loss improved from 1.98450 to 1.98448, saving model to models\\best_model_weights.h5\n",
      "Epoch 103/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.7799 - accuracy: 0.2865 - val_loss: 1.9860 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1.98448\n",
      "Epoch 104/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7786 - accuracy: 0.2865 - val_loss: 1.9850 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1.98448\n",
      "Epoch 105/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.7784 - accuracy: 0.2865 - val_loss: 1.9852 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1.98448\n",
      "Epoch 106/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7764 - accuracy: 0.2924 - val_loss: 1.9853 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1.98448\n",
      "Epoch 107/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7752 - accuracy: 0.2982 - val_loss: 1.9858 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1.98448\n",
      "Epoch 108/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7735 - accuracy: 0.2924 - val_loss: 1.9854 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1.98448\n",
      "Epoch 109/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7730 - accuracy: 0.2924 - val_loss: 1.9866 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1.98448\n",
      "Epoch 110/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7715 - accuracy: 0.2924 - val_loss: 1.9835 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00110: val_loss improved from 1.98448 to 1.98349, saving model to models\\best_model_weights.h5\n",
      "Epoch 111/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7692 - accuracy: 0.2924 - val_loss: 1.9801 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00111: val_loss improved from 1.98349 to 1.98012, saving model to models\\best_model_weights.h5\n",
      "Epoch 112/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.7687 - accuracy: 0.2924 - val_loss: 1.9763 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00112: val_loss improved from 1.98012 to 1.97631, saving model to models\\best_model_weights.h5\n",
      "Epoch 113/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.7678 - accuracy: 0.3041 - val_loss: 1.9775 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1.97631\n",
      "Epoch 114/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7658 - accuracy: 0.3041 - val_loss: 1.9761 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00114: val_loss improved from 1.97631 to 1.97614, saving model to models\\best_model_weights.h5\n",
      "Epoch 115/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.7638 - accuracy: 0.3099 - val_loss: 1.9752 - val_accuracy: 0.1316\n",
      "\n",
      "Epoch 00115: val_loss improved from 1.97614 to 1.97520, saving model to models\\best_model_weights.h5\n",
      "Epoch 116/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7630 - accuracy: 0.3216 - val_loss: 1.9736 - val_accuracy: 0.1316\n",
      "\n",
      "Epoch 00116: val_loss improved from 1.97520 to 1.97361, saving model to models\\best_model_weights.h5\n",
      "Epoch 117/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.7612 - accuracy: 0.3216 - val_loss: 1.9763 - val_accuracy: 0.1316\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1.97361\n",
      "Epoch 118/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7602 - accuracy: 0.3099 - val_loss: 1.9782 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1.97361\n",
      "Epoch 119/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7615 - accuracy: 0.3041 - val_loss: 1.9785 - val_accuracy: 0.1316\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1.97361\n",
      "Epoch 120/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7580 - accuracy: 0.2982 - val_loss: 1.9771 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1.97361\n",
      "Epoch 121/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7564 - accuracy: 0.3099 - val_loss: 1.9709 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00121: val_loss improved from 1.97361 to 1.97087, saving model to models\\best_model_weights.h5\n",
      "Epoch 122/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.7549 - accuracy: 0.3333 - val_loss: 1.9688 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00122: val_loss improved from 1.97087 to 1.96881, saving model to models\\best_model_weights.h5\n",
      "Epoch 123/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7545 - accuracy: 0.3333 - val_loss: 1.9685 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00123: val_loss improved from 1.96881 to 1.96847, saving model to models\\best_model_weights.h5\n",
      "Epoch 124/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7527 - accuracy: 0.3216 - val_loss: 1.9728 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1.96847\n",
      "Epoch 125/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7527 - accuracy: 0.3158 - val_loss: 1.9737 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1.96847\n",
      "Epoch 126/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7491 - accuracy: 0.3216 - val_loss: 1.9746 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1.96847\n",
      "Epoch 127/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7479 - accuracy: 0.3216 - val_loss: 1.9754 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1.96847\n",
      "Epoch 128/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.7464 - accuracy: 0.3216 - val_loss: 1.9738 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1.96847\n",
      "Epoch 129/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.7446 - accuracy: 0.3275 - val_loss: 1.9691 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1.96847\n",
      "Epoch 130/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7445 - accuracy: 0.3216 - val_loss: 1.9666 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00130: val_loss improved from 1.96847 to 1.96663, saving model to models\\best_model_weights.h5\n",
      "Epoch 131/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.7430 - accuracy: 0.3333 - val_loss: 1.9658 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00131: val_loss improved from 1.96663 to 1.96579, saving model to models\\best_model_weights.h5\n",
      "Epoch 132/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7417 - accuracy: 0.3333 - val_loss: 1.9657 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00132: val_loss improved from 1.96579 to 1.96573, saving model to models\\best_model_weights.h5\n",
      "Epoch 133/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7410 - accuracy: 0.3216 - val_loss: 1.9667 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1.96573\n",
      "Epoch 134/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7382 - accuracy: 0.3158 - val_loss: 1.9644 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00134: val_loss improved from 1.96573 to 1.96437, saving model to models\\best_model_weights.h5\n",
      "Epoch 135/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.7375 - accuracy: 0.3216 - val_loss: 1.9623 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00135: val_loss improved from 1.96437 to 1.96229, saving model to models\\best_model_weights.h5\n",
      "Epoch 136/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.7367 - accuracy: 0.3275 - val_loss: 1.9651 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1.96229\n",
      "Epoch 137/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7339 - accuracy: 0.3333 - val_loss: 1.9656 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1.96229\n",
      "Epoch 138/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7345 - accuracy: 0.3275 - val_loss: 1.9627 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1.96229\n",
      "Epoch 139/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.7333 - accuracy: 0.3333 - val_loss: 1.9580 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00139: val_loss improved from 1.96229 to 1.95799, saving model to models\\best_model_weights.h5\n",
      "Epoch 140/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.7315 - accuracy: 0.3509 - val_loss: 1.9588 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 1.95799\n",
      "Epoch 141/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7293 - accuracy: 0.3450 - val_loss: 1.9590 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1.95799\n",
      "Epoch 142/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.7277 - accuracy: 0.3392 - val_loss: 1.9601 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1.95799\n",
      "Epoch 143/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.7268 - accuracy: 0.3275 - val_loss: 1.9606 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1.95799\n",
      "Epoch 144/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.7252 - accuracy: 0.3333 - val_loss: 1.9573 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00144: val_loss improved from 1.95799 to 1.95728, saving model to models\\best_model_weights.h5\n",
      "Epoch 145/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.7243 - accuracy: 0.3509 - val_loss: 1.9564 - val_accuracy: 0.1316\n",
      "\n",
      "Epoch 00145: val_loss improved from 1.95728 to 1.95643, saving model to models\\best_model_weights.h5\n",
      "Epoch 146/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.7227 - accuracy: 0.3333 - val_loss: 1.9587 - val_accuracy: 0.1316\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 1.95643\n",
      "Epoch 147/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.7217 - accuracy: 0.3275 - val_loss: 1.9610 - val_accuracy: 0.1316\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 1.95643\n",
      "Epoch 148/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.7189 - accuracy: 0.3333 - val_loss: 1.9622 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 1.95643\n",
      "Epoch 149/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.7198 - accuracy: 0.3333 - val_loss: 1.9635 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 1.95643\n",
      "Epoch 150/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7186 - accuracy: 0.3275 - val_loss: 1.9588 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 1.95643\n",
      "Epoch 151/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7161 - accuracy: 0.3275 - val_loss: 1.9558 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00151: val_loss improved from 1.95643 to 1.95579, saving model to models\\best_model_weights.h5\n",
      "Epoch 152/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.7151 - accuracy: 0.3333 - val_loss: 1.9551 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00152: val_loss improved from 1.95579 to 1.95515, saving model to models\\best_model_weights.h5\n",
      "Epoch 153/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7137 - accuracy: 0.3275 - val_loss: 1.9537 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00153: val_loss improved from 1.95515 to 1.95370, saving model to models\\best_model_weights.h5\n",
      "Epoch 154/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7120 - accuracy: 0.3450 - val_loss: 1.9481 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00154: val_loss improved from 1.95370 to 1.94810, saving model to models\\best_model_weights.h5\n",
      "Epoch 155/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.7102 - accuracy: 0.3450 - val_loss: 1.9472 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00155: val_loss improved from 1.94810 to 1.94717, saving model to models\\best_model_weights.h5\n",
      "Epoch 156/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7082 - accuracy: 0.3450 - val_loss: 1.9472 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 1.94717\n",
      "Epoch 157/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7071 - accuracy: 0.3450 - val_loss: 1.9496 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 1.94717\n",
      "Epoch 158/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7056 - accuracy: 0.3509 - val_loss: 1.9510 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 1.94717\n",
      "Epoch 159/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7056 - accuracy: 0.3450 - val_loss: 1.9514 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 1.94717\n",
      "Epoch 160/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7044 - accuracy: 0.3450 - val_loss: 1.9507 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 1.94717\n",
      "Epoch 161/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7028 - accuracy: 0.3450 - val_loss: 1.9518 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 1.94717\n",
      "Epoch 162/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7005 - accuracy: 0.3509 - val_loss: 1.9528 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 1.94717\n",
      "Epoch 163/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6995 - accuracy: 0.3509 - val_loss: 1.9529 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 1.94717\n",
      "Epoch 164/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.6972 - accuracy: 0.3509 - val_loss: 1.9534 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 1.94717\n",
      "Epoch 165/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6969 - accuracy: 0.3450 - val_loss: 1.9477 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 1.94717\n",
      "Epoch 166/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.6967 - accuracy: 0.3450 - val_loss: 1.9431 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00166: val_loss improved from 1.94717 to 1.94306, saving model to models\\best_model_weights.h5\n",
      "Epoch 167/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6956 - accuracy: 0.3450 - val_loss: 1.9418 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00167: val_loss improved from 1.94306 to 1.94177, saving model to models\\best_model_weights.h5\n",
      "Epoch 168/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6918 - accuracy: 0.3509 - val_loss: 1.9441 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 1.94177\n",
      "Epoch 169/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6907 - accuracy: 0.3567 - val_loss: 1.9413 - val_accuracy: 0.1316\n",
      "\n",
      "Epoch 00169: val_loss improved from 1.94177 to 1.94133, saving model to models\\best_model_weights.h5\n",
      "Epoch 170/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6896 - accuracy: 0.3743 - val_loss: 1.9386 - val_accuracy: 0.1316\n",
      "\n",
      "Epoch 00170: val_loss improved from 1.94133 to 1.93862, saving model to models\\best_model_weights.h5\n",
      "Epoch 171/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6886 - accuracy: 0.3801 - val_loss: 1.9370 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00171: val_loss improved from 1.93862 to 1.93697, saving model to models\\best_model_weights.h5\n",
      "Epoch 172/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.6888 - accuracy: 0.3684 - val_loss: 1.9378 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 1.93697\n",
      "Epoch 173/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.6857 - accuracy: 0.3801 - val_loss: 1.9375 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 1.93697\n",
      "Epoch 174/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6846 - accuracy: 0.3684 - val_loss: 1.9393 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 1.93697\n",
      "Epoch 175/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6840 - accuracy: 0.3684 - val_loss: 1.9363 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00175: val_loss improved from 1.93697 to 1.93631, saving model to models\\best_model_weights.h5\n",
      "Epoch 176/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6806 - accuracy: 0.3801 - val_loss: 1.9406 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 1.93631\n",
      "Epoch 177/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.6792 - accuracy: 0.3626 - val_loss: 1.9429 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 1.93631\n",
      "Epoch 178/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6783 - accuracy: 0.3684 - val_loss: 1.9400 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 1.93631\n",
      "Epoch 179/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6763 - accuracy: 0.3684 - val_loss: 1.9434 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 1.93631\n",
      "Epoch 180/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6754 - accuracy: 0.3626 - val_loss: 1.9454 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 1.93631\n",
      "Epoch 181/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.6745 - accuracy: 0.3743 - val_loss: 1.9445 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 1.93631\n",
      "Epoch 182/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.6726 - accuracy: 0.3684 - val_loss: 1.9402 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 1.93631\n",
      "Epoch 183/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6724 - accuracy: 0.3743 - val_loss: 1.9389 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 1.93631\n",
      "Epoch 184/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6691 - accuracy: 0.3743 - val_loss: 1.9362 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00184: val_loss improved from 1.93631 to 1.93615, saving model to models\\best_model_weights.h5\n",
      "Epoch 185/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6682 - accuracy: 0.3801 - val_loss: 1.9342 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00185: val_loss improved from 1.93615 to 1.93422, saving model to models\\best_model_weights.h5\n",
      "Epoch 186/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6662 - accuracy: 0.3977 - val_loss: 1.9327 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00186: val_loss improved from 1.93422 to 1.93266, saving model to models\\best_model_weights.h5\n",
      "Epoch 187/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.6653 - accuracy: 0.4035 - val_loss: 1.9301 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00187: val_loss improved from 1.93266 to 1.93005, saving model to models\\best_model_weights.h5\n",
      "Epoch 188/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6633 - accuracy: 0.4152 - val_loss: 1.9353 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 1.93005\n",
      "Epoch 189/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6626 - accuracy: 0.4035 - val_loss: 1.9371 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 1.93005\n",
      "Epoch 190/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6614 - accuracy: 0.3743 - val_loss: 1.9377 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 1.93005\n",
      "Epoch 191/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6596 - accuracy: 0.3801 - val_loss: 1.9351 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 1.93005\n",
      "Epoch 192/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6591 - accuracy: 0.3977 - val_loss: 1.9360 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 1.93005\n",
      "Epoch 193/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6568 - accuracy: 0.4094 - val_loss: 1.9310 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 1.93005\n",
      "Epoch 194/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6563 - accuracy: 0.4269 - val_loss: 1.9202 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00194: val_loss improved from 1.93005 to 1.92023, saving model to models\\best_model_weights.h5\n",
      "Epoch 195/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6547 - accuracy: 0.4152 - val_loss: 1.9209 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 1.92023\n",
      "Epoch 196/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6525 - accuracy: 0.4035 - val_loss: 1.9194 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00196: val_loss improved from 1.92023 to 1.91935, saving model to models\\best_model_weights.h5\n",
      "Epoch 197/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.6510 - accuracy: 0.4152 - val_loss: 1.9168 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00197: val_loss improved from 1.91935 to 1.91675, saving model to models\\best_model_weights.h5\n",
      "Epoch 198/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6496 - accuracy: 0.4152 - val_loss: 1.9160 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00198: val_loss improved from 1.91675 to 1.91603, saving model to models\\best_model_weights.h5\n",
      "Epoch 199/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6492 - accuracy: 0.4094 - val_loss: 1.9124 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00199: val_loss improved from 1.91603 to 1.91242, saving model to models\\best_model_weights.h5\n",
      "Epoch 200/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6470 - accuracy: 0.4094 - val_loss: 1.9134 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 1.91242\n",
      "Epoch 201/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6438 - accuracy: 0.4035 - val_loss: 1.9109 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00201: val_loss improved from 1.91242 to 1.91092, saving model to models\\best_model_weights.h5\n",
      "Epoch 202/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6458 - accuracy: 0.4094 - val_loss: 1.9091 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00202: val_loss improved from 1.91092 to 1.90913, saving model to models\\best_model_weights.h5\n",
      "Epoch 203/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6442 - accuracy: 0.3977 - val_loss: 1.9100 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 1.90913\n",
      "Epoch 204/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6421 - accuracy: 0.3860 - val_loss: 1.9117 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 1.90913\n",
      "Epoch 205/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6393 - accuracy: 0.3860 - val_loss: 1.9148 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 1.90913\n",
      "Epoch 206/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.6372 - accuracy: 0.3977 - val_loss: 1.9113 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 1.90913\n",
      "Epoch 207/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.6363 - accuracy: 0.3977 - val_loss: 1.9138 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 1.90913\n",
      "Epoch 208/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6353 - accuracy: 0.3918 - val_loss: 1.9129 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 1.90913\n",
      "Epoch 209/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6331 - accuracy: 0.3918 - val_loss: 1.9122 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 1.90913\n",
      "Epoch 210/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.6327 - accuracy: 0.3918 - val_loss: 1.9106 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 1.90913\n",
      "Epoch 211/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6325 - accuracy: 0.4094 - val_loss: 1.9099 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 1.90913\n",
      "Epoch 212/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.6290 - accuracy: 0.4152 - val_loss: 1.9084 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00212: val_loss improved from 1.90913 to 1.90840, saving model to models\\best_model_weights.h5\n",
      "Epoch 213/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6273 - accuracy: 0.4152 - val_loss: 1.9061 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00213: val_loss improved from 1.90840 to 1.90606, saving model to models\\best_model_weights.h5\n",
      "Epoch 214/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6261 - accuracy: 0.4211 - val_loss: 1.9020 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00214: val_loss improved from 1.90606 to 1.90198, saving model to models\\best_model_weights.h5\n",
      "Epoch 215/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6240 - accuracy: 0.4152 - val_loss: 1.9048 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 1.90198\n",
      "Epoch 216/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.6252 - accuracy: 0.4152 - val_loss: 1.9070 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 1.90198\n",
      "Epoch 217/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6210 - accuracy: 0.4211 - val_loss: 1.9057 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 1.90198\n",
      "Epoch 218/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6196 - accuracy: 0.4152 - val_loss: 1.9024 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 1.90198\n",
      "Epoch 219/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6177 - accuracy: 0.4152 - val_loss: 1.9024 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 1.90198\n",
      "Epoch 220/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.6166 - accuracy: 0.4094 - val_loss: 1.9005 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00220: val_loss improved from 1.90198 to 1.90047, saving model to models\\best_model_weights.h5\n",
      "Epoch 221/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6179 - accuracy: 0.4152 - val_loss: 1.9001 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00221: val_loss improved from 1.90047 to 1.90010, saving model to models\\best_model_weights.h5\n",
      "Epoch 222/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6134 - accuracy: 0.4152 - val_loss: 1.9027 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 1.90010\n",
      "Epoch 223/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.6126 - accuracy: 0.4211 - val_loss: 1.9008 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 1.90010\n",
      "Epoch 224/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6114 - accuracy: 0.3977 - val_loss: 1.9007 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 1.90010\n",
      "Epoch 225/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6121 - accuracy: 0.4094 - val_loss: 1.8999 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00225: val_loss improved from 1.90010 to 1.89986, saving model to models\\best_model_weights.h5\n",
      "Epoch 226/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6066 - accuracy: 0.4269 - val_loss: 1.8944 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00226: val_loss improved from 1.89986 to 1.89441, saving model to models\\best_model_weights.h5\n",
      "Epoch 227/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.6065 - accuracy: 0.4211 - val_loss: 1.8946 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 1.89441\n",
      "Epoch 228/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6058 - accuracy: 0.4152 - val_loss: 1.8919 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00228: val_loss improved from 1.89441 to 1.89187, saving model to models\\best_model_weights.h5\n",
      "Epoch 229/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6029 - accuracy: 0.4152 - val_loss: 1.8932 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 1.89187\n",
      "Epoch 230/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6020 - accuracy: 0.4269 - val_loss: 1.8952 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 1.89187\n",
      "Epoch 231/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6018 - accuracy: 0.4327 - val_loss: 1.8995 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 1.89187\n",
      "Epoch 232/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5994 - accuracy: 0.4211 - val_loss: 1.8977 - val_accuracy: 0.1579\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 1.89187\n",
      "Epoch 233/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5992 - accuracy: 0.4269 - val_loss: 1.8982 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 1.89187\n",
      "Epoch 234/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5981 - accuracy: 0.4211 - val_loss: 1.8911 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00234: val_loss improved from 1.89187 to 1.89106, saving model to models\\best_model_weights.h5\n",
      "Epoch 235/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5965 - accuracy: 0.4211 - val_loss: 1.8839 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00235: val_loss improved from 1.89106 to 1.88395, saving model to models\\best_model_weights.h5\n",
      "Epoch 236/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5939 - accuracy: 0.4211 - val_loss: 1.8819 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00236: val_loss improved from 1.88395 to 1.88193, saving model to models\\best_model_weights.h5\n",
      "Epoch 237/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5925 - accuracy: 0.4386 - val_loss: 1.8844 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 1.88193\n",
      "Epoch 238/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5905 - accuracy: 0.4444 - val_loss: 1.8869 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 1.88193\n",
      "Epoch 239/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5901 - accuracy: 0.4386 - val_loss: 1.8811 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00239: val_loss improved from 1.88193 to 1.88106, saving model to models\\best_model_weights.h5\n",
      "Epoch 240/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5870 - accuracy: 0.4211 - val_loss: 1.8772 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00240: val_loss improved from 1.88106 to 1.87719, saving model to models\\best_model_weights.h5\n",
      "Epoch 241/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5860 - accuracy: 0.4269 - val_loss: 1.8767 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00241: val_loss improved from 1.87719 to 1.87675, saving model to models\\best_model_weights.h5\n",
      "Epoch 242/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5852 - accuracy: 0.4211 - val_loss: 1.8749 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00242: val_loss improved from 1.87675 to 1.87490, saving model to models\\best_model_weights.h5\n",
      "Epoch 243/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5838 - accuracy: 0.4152 - val_loss: 1.8747 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00243: val_loss improved from 1.87490 to 1.87471, saving model to models\\best_model_weights.h5\n",
      "Epoch 244/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5829 - accuracy: 0.4094 - val_loss: 1.8738 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00244: val_loss improved from 1.87471 to 1.87381, saving model to models\\best_model_weights.h5\n",
      "Epoch 245/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5815 - accuracy: 0.4152 - val_loss: 1.8770 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 1.87381\n",
      "Epoch 246/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5789 - accuracy: 0.4386 - val_loss: 1.8822 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 1.87381\n",
      "Epoch 247/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.5782 - accuracy: 0.4444 - val_loss: 1.8838 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 1.87381\n",
      "Epoch 248/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5762 - accuracy: 0.4444 - val_loss: 1.8821 - val_accuracy: 0.1842\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 1.87381\n",
      "Epoch 249/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5750 - accuracy: 0.4386 - val_loss: 1.8747 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 1.87381\n",
      "Epoch 250/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5748 - accuracy: 0.4386 - val_loss: 1.8684 - val_accuracy: 0.2368\n",
      "\n",
      "Epoch 00250: val_loss improved from 1.87381 to 1.86842, saving model to models\\best_model_weights.h5\n",
      "Epoch 251/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5740 - accuracy: 0.4386 - val_loss: 1.8669 - val_accuracy: 0.2368\n",
      "\n",
      "Epoch 00251: val_loss improved from 1.86842 to 1.86694, saving model to models\\best_model_weights.h5\n",
      "Epoch 252/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5704 - accuracy: 0.4327 - val_loss: 1.8649 - val_accuracy: 0.2368\n",
      "\n",
      "Epoch 00252: val_loss improved from 1.86694 to 1.86494, saving model to models\\best_model_weights.h5\n",
      "Epoch 253/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5700 - accuracy: 0.4269 - val_loss: 1.8678 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 1.86494\n",
      "Epoch 254/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5659 - accuracy: 0.4386 - val_loss: 1.8682 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 1.86494\n",
      "Epoch 255/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5649 - accuracy: 0.4444 - val_loss: 1.8677 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 1.86494\n",
      "Epoch 256/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5667 - accuracy: 0.4386 - val_loss: 1.8647 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00256: val_loss improved from 1.86494 to 1.86471, saving model to models\\best_model_weights.h5\n",
      "Epoch 257/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5629 - accuracy: 0.4503 - val_loss: 1.8624 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00257: val_loss improved from 1.86471 to 1.86237, saving model to models\\best_model_weights.h5\n",
      "Epoch 258/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5628 - accuracy: 0.4561 - val_loss: 1.8583 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00258: val_loss improved from 1.86237 to 1.85828, saving model to models\\best_model_weights.h5\n",
      "Epoch 259/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5617 - accuracy: 0.4503 - val_loss: 1.8585 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 1.85828\n",
      "Epoch 260/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.5599 - accuracy: 0.4444 - val_loss: 1.8591 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 1.85828\n",
      "Epoch 261/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5555 - accuracy: 0.4327 - val_loss: 1.8601 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 1.85828\n",
      "Epoch 262/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5548 - accuracy: 0.4327 - val_loss: 1.8632 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 1.85828\n",
      "Epoch 263/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5540 - accuracy: 0.4386 - val_loss: 1.8662 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 1.85828\n",
      "Epoch 264/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5534 - accuracy: 0.4327 - val_loss: 1.8634 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 1.85828\n",
      "Epoch 265/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5542 - accuracy: 0.4444 - val_loss: 1.8544 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00265: val_loss improved from 1.85828 to 1.85437, saving model to models\\best_model_weights.h5\n",
      "Epoch 266/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5496 - accuracy: 0.4678 - val_loss: 1.8541 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00266: val_loss improved from 1.85437 to 1.85412, saving model to models\\best_model_weights.h5\n",
      "Epoch 267/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5474 - accuracy: 0.4444 - val_loss: 1.8537 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00267: val_loss improved from 1.85412 to 1.85367, saving model to models\\best_model_weights.h5\n",
      "Epoch 268/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5458 - accuracy: 0.4269 - val_loss: 1.8576 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 1.85367\n",
      "Epoch 269/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.5461 - accuracy: 0.4269 - val_loss: 1.8599 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 1.85367\n",
      "Epoch 270/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5470 - accuracy: 0.4211 - val_loss: 1.8544 - val_accuracy: 0.2368\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 1.85367\n",
      "Epoch 271/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5433 - accuracy: 0.4386 - val_loss: 1.8495 - val_accuracy: 0.2632\n",
      "\n",
      "Epoch 00271: val_loss improved from 1.85367 to 1.84955, saving model to models\\best_model_weights.h5\n",
      "Epoch 272/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5441 - accuracy: 0.4386 - val_loss: 1.8506 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 1.84955\n",
      "Epoch 273/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5412 - accuracy: 0.4386 - val_loss: 1.8485 - val_accuracy: 0.2368\n",
      "\n",
      "Epoch 00273: val_loss improved from 1.84955 to 1.84848, saving model to models\\best_model_weights.h5\n",
      "Epoch 274/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.5376 - accuracy: 0.4327 - val_loss: 1.8425 - val_accuracy: 0.2368\n",
      "\n",
      "Epoch 00274: val_loss improved from 1.84848 to 1.84246, saving model to models\\best_model_weights.h5\n",
      "Epoch 275/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5355 - accuracy: 0.4386 - val_loss: 1.8408 - val_accuracy: 0.2368\n",
      "\n",
      "Epoch 00275: val_loss improved from 1.84246 to 1.84082, saving model to models\\best_model_weights.h5\n",
      "Epoch 276/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5369 - accuracy: 0.4561 - val_loss: 1.8429 - val_accuracy: 0.2632\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 1.84082\n",
      "Epoch 277/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5347 - accuracy: 0.4561 - val_loss: 1.8467 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 1.84082\n",
      "Epoch 278/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5327 - accuracy: 0.4561 - val_loss: 1.8436 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 1.84082\n",
      "Epoch 279/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5318 - accuracy: 0.4561 - val_loss: 1.8442 - val_accuracy: 0.2368\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 1.84082\n",
      "Epoch 280/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5322 - accuracy: 0.4737 - val_loss: 1.8414 - val_accuracy: 0.2368\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 1.84082\n",
      "Epoch 281/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5278 - accuracy: 0.4737 - val_loss: 1.8379 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00281: val_loss improved from 1.84082 to 1.83794, saving model to models\\best_model_weights.h5\n",
      "Epoch 282/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5267 - accuracy: 0.4503 - val_loss: 1.8421 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 1.83794\n",
      "Epoch 283/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5248 - accuracy: 0.4620 - val_loss: 1.8398 - val_accuracy: 0.2368\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 1.83794\n",
      "Epoch 284/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5239 - accuracy: 0.4561 - val_loss: 1.8348 - val_accuracy: 0.2368\n",
      "\n",
      "Epoch 00284: val_loss improved from 1.83794 to 1.83476, saving model to models\\best_model_weights.h5\n",
      "Epoch 285/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5250 - accuracy: 0.4503 - val_loss: 1.8307 - val_accuracy: 0.2632\n",
      "\n",
      "Epoch 00285: val_loss improved from 1.83476 to 1.83066, saving model to models\\best_model_weights.h5\n",
      "Epoch 286/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5225 - accuracy: 0.4327 - val_loss: 1.8392 - val_accuracy: 0.2105\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 1.83066\n",
      "Epoch 287/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5215 - accuracy: 0.4444 - val_loss: 1.8373 - val_accuracy: 0.2632\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 1.83066\n",
      "Epoch 288/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.5191 - accuracy: 0.4444 - val_loss: 1.8355 - val_accuracy: 0.2632\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 1.83066\n",
      "Epoch 289/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5182 - accuracy: 0.4386 - val_loss: 1.8338 - val_accuracy: 0.2632\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 1.83066\n",
      "Epoch 290/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5175 - accuracy: 0.4386 - val_loss: 1.8286 - val_accuracy: 0.2368\n",
      "\n",
      "Epoch 00290: val_loss improved from 1.83066 to 1.82863, saving model to models\\best_model_weights.h5\n",
      "Epoch 291/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5149 - accuracy: 0.4561 - val_loss: 1.8304 - val_accuracy: 0.2368\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 1.82863\n",
      "Epoch 292/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.5125 - accuracy: 0.4620 - val_loss: 1.8320 - val_accuracy: 0.2368\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 1.82863\n",
      "Epoch 293/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5119 - accuracy: 0.4561 - val_loss: 1.8304 - val_accuracy: 0.2368\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 1.82863\n",
      "Epoch 294/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5097 - accuracy: 0.4444 - val_loss: 1.8294 - val_accuracy: 0.2368\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 1.82863\n",
      "Epoch 295/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5082 - accuracy: 0.4386 - val_loss: 1.8298 - val_accuracy: 0.2368\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 1.82863\n",
      "Epoch 296/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5090 - accuracy: 0.4561 - val_loss: 1.8249 - val_accuracy: 0.2632\n",
      "\n",
      "Epoch 00296: val_loss improved from 1.82863 to 1.82490, saving model to models\\best_model_weights.h5\n",
      "Epoch 297/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5063 - accuracy: 0.4737 - val_loss: 1.8244 - val_accuracy: 0.2632\n",
      "\n",
      "Epoch 00297: val_loss improved from 1.82490 to 1.82443, saving model to models\\best_model_weights.h5\n",
      "Epoch 298/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5050 - accuracy: 0.4620 - val_loss: 1.8256 - val_accuracy: 0.2632\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 1.82443\n",
      "Epoch 299/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5038 - accuracy: 0.4620 - val_loss: 1.8266 - val_accuracy: 0.2632\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 1.82443\n",
      "Epoch 300/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5029 - accuracy: 0.4503 - val_loss: 1.8253 - val_accuracy: 0.2632\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 1.82443\n",
      "Epoch 301/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.5008 - accuracy: 0.4561 - val_loss: 1.8225 - val_accuracy: 0.2632\n",
      "\n",
      "Epoch 00301: val_loss improved from 1.82443 to 1.82249, saving model to models\\best_model_weights.h5\n",
      "Epoch 302/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4995 - accuracy: 0.4678 - val_loss: 1.8194 - val_accuracy: 0.2632\n",
      "\n",
      "Epoch 00302: val_loss improved from 1.82249 to 1.81942, saving model to models\\best_model_weights.h5\n",
      "Epoch 303/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.5000 - accuracy: 0.4678 - val_loss: 1.8207 - val_accuracy: 0.2632\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 1.81942\n",
      "Epoch 304/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4971 - accuracy: 0.4620 - val_loss: 1.8224 - val_accuracy: 0.2632\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 1.81942\n",
      "Epoch 305/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.4965 - accuracy: 0.4678 - val_loss: 1.8220 - val_accuracy: 0.2632\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 1.81942\n",
      "Epoch 306/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4957 - accuracy: 0.4678 - val_loss: 1.8206 - val_accuracy: 0.2632\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 1.81942\n",
      "Epoch 307/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4933 - accuracy: 0.4737 - val_loss: 1.8133 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00307: val_loss improved from 1.81942 to 1.81327, saving model to models\\best_model_weights.h5\n",
      "Epoch 308/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4914 - accuracy: 0.4795 - val_loss: 1.8115 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00308: val_loss improved from 1.81327 to 1.81147, saving model to models\\best_model_weights.h5\n",
      "Epoch 309/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.4900 - accuracy: 0.4854 - val_loss: 1.8085 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00309: val_loss improved from 1.81147 to 1.80850, saving model to models\\best_model_weights.h5\n",
      "Epoch 310/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4902 - accuracy: 0.4854 - val_loss: 1.8082 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00310: val_loss improved from 1.80850 to 1.80822, saving model to models\\best_model_weights.h5\n",
      "Epoch 311/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.4879 - accuracy: 0.4737 - val_loss: 1.8107 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 1.80822\n",
      "Epoch 312/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4871 - accuracy: 0.4678 - val_loss: 1.8142 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 1.80822\n",
      "Epoch 313/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4867 - accuracy: 0.4737 - val_loss: 1.8166 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 1.80822\n",
      "Epoch 314/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4838 - accuracy: 0.4795 - val_loss: 1.8103 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 1.80822\n",
      "Epoch 315/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.4831 - accuracy: 0.4678 - val_loss: 1.8093 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 1.80822\n",
      "Epoch 316/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4825 - accuracy: 0.4737 - val_loss: 1.8046 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00316: val_loss improved from 1.80822 to 1.80459, saving model to models\\best_model_weights.h5\n",
      "Epoch 317/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4803 - accuracy: 0.4795 - val_loss: 1.8030 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00317: val_loss improved from 1.80459 to 1.80302, saving model to models\\best_model_weights.h5\n",
      "Epoch 318/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4792 - accuracy: 0.4912 - val_loss: 1.8004 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00318: val_loss improved from 1.80302 to 1.80044, saving model to models\\best_model_weights.h5\n",
      "Epoch 319/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4781 - accuracy: 0.5146 - val_loss: 1.7990 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00319: val_loss improved from 1.80044 to 1.79899, saving model to models\\best_model_weights.h5\n",
      "Epoch 320/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4765 - accuracy: 0.5088 - val_loss: 1.8028 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 1.79899\n",
      "Epoch 321/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4746 - accuracy: 0.4854 - val_loss: 1.8068 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 1.79899\n",
      "Epoch 322/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.4724 - accuracy: 0.4854 - val_loss: 1.8049 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 1.79899\n",
      "Epoch 323/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.4715 - accuracy: 0.4912 - val_loss: 1.8081 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 1.79899\n",
      "Epoch 324/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4721 - accuracy: 0.4971 - val_loss: 1.8094 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 1.79899\n",
      "Epoch 325/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4708 - accuracy: 0.4854 - val_loss: 1.8115 - val_accuracy: 0.2632\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 1.79899\n",
      "Epoch 326/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.4692 - accuracy: 0.4971 - val_loss: 1.8075 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 1.79899\n",
      "Epoch 327/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4666 - accuracy: 0.4971 - val_loss: 1.8053 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 1.79899\n",
      "Epoch 328/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4650 - accuracy: 0.5088 - val_loss: 1.7998 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 1.79899\n",
      "Epoch 329/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4654 - accuracy: 0.4854 - val_loss: 1.8030 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 1.79899\n",
      "Epoch 330/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4649 - accuracy: 0.4854 - val_loss: 1.8053 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 1.79899\n",
      "Epoch 331/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4658 - accuracy: 0.4971 - val_loss: 1.8056 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 1.79899\n",
      "Epoch 332/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4631 - accuracy: 0.4912 - val_loss: 1.8056 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 1.79899\n",
      "Epoch 333/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4609 - accuracy: 0.4971 - val_loss: 1.8046 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 1.79899\n",
      "Epoch 334/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.4603 - accuracy: 0.5029 - val_loss: 1.8026 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 1.79899\n",
      "Epoch 335/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.4602 - accuracy: 0.4854 - val_loss: 1.8001 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 1.79899\n",
      "Epoch 336/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4567 - accuracy: 0.4795 - val_loss: 1.8013 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 1.79899\n",
      "Epoch 337/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4556 - accuracy: 0.4795 - val_loss: 1.8039 - val_accuracy: 0.2632\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 1.79899\n",
      "Epoch 338/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.4526 - accuracy: 0.4854 - val_loss: 1.7953 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00338: val_loss improved from 1.79899 to 1.79534, saving model to models\\best_model_weights.h5\n",
      "Epoch 339/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.4523 - accuracy: 0.4971 - val_loss: 1.7859 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00339: val_loss improved from 1.79534 to 1.78588, saving model to models\\best_model_weights.h5\n",
      "Epoch 340/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4525 - accuracy: 0.5029 - val_loss: 1.7891 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 1.78588\n",
      "Epoch 341/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4494 - accuracy: 0.4971 - val_loss: 1.7906 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 1.78588\n",
      "Epoch 342/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.4500 - accuracy: 0.4620 - val_loss: 1.8014 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 1.78588\n",
      "Epoch 343/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4506 - accuracy: 0.4854 - val_loss: 1.8007 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 1.78588\n",
      "Epoch 344/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4514 - accuracy: 0.4971 - val_loss: 1.7940 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 1.78588\n",
      "Epoch 345/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4447 - accuracy: 0.4971 - val_loss: 1.7922 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 1.78588\n",
      "Epoch 346/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.4441 - accuracy: 0.5146 - val_loss: 1.7960 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 1.78588\n",
      "Epoch 347/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4422 - accuracy: 0.5205 - val_loss: 1.7994 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 1.78588\n",
      "Epoch 348/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4400 - accuracy: 0.5146 - val_loss: 1.7968 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 1.78588\n",
      "Epoch 349/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.4382 - accuracy: 0.5205 - val_loss: 1.7924 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 1.78588\n",
      "Epoch 350/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4383 - accuracy: 0.4912 - val_loss: 1.7893 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 1.78588\n",
      "Epoch 351/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.4380 - accuracy: 0.4795 - val_loss: 1.7940 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 1.78588\n",
      "Epoch 352/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4376 - accuracy: 0.4795 - val_loss: 1.7919 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 1.78588\n",
      "Epoch 353/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4350 - accuracy: 0.4737 - val_loss: 1.7866 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 1.78588\n",
      "Epoch 354/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.4354 - accuracy: 0.4912 - val_loss: 1.7826 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00354: val_loss improved from 1.78588 to 1.78260, saving model to models\\best_model_weights.h5\n",
      "Epoch 355/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.4342 - accuracy: 0.4971 - val_loss: 1.7808 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00355: val_loss improved from 1.78260 to 1.78082, saving model to models\\best_model_weights.h5\n",
      "Epoch 356/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4309 - accuracy: 0.5029 - val_loss: 1.7874 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 1.78082\n",
      "Epoch 357/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.4311 - accuracy: 0.5029 - val_loss: 1.7925 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 1.78082\n",
      "Epoch 358/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4292 - accuracy: 0.4912 - val_loss: 1.7839 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 1.78082\n",
      "Epoch 359/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.4276 - accuracy: 0.4854 - val_loss: 1.7795 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00359: val_loss improved from 1.78082 to 1.77954, saving model to models\\best_model_weights.h5\n",
      "Epoch 360/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4271 - accuracy: 0.4854 - val_loss: 1.7773 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00360: val_loss improved from 1.77954 to 1.77729, saving model to models\\best_model_weights.h5\n",
      "Epoch 361/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.4259 - accuracy: 0.5029 - val_loss: 1.7744 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00361: val_loss improved from 1.77729 to 1.77442, saving model to models\\best_model_weights.h5\n",
      "Epoch 362/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4230 - accuracy: 0.5029 - val_loss: 1.7775 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 1.77442\n",
      "Epoch 363/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4240 - accuracy: 0.4971 - val_loss: 1.7787 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 1.77442\n",
      "Epoch 364/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.4228 - accuracy: 0.4912 - val_loss: 1.7784 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 1.77442\n",
      "Epoch 365/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4196 - accuracy: 0.4912 - val_loss: 1.7691 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00365: val_loss improved from 1.77442 to 1.76908, saving model to models\\best_model_weights.h5\n",
      "Epoch 366/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4182 - accuracy: 0.4971 - val_loss: 1.7627 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00366: val_loss improved from 1.76908 to 1.76268, saving model to models\\best_model_weights.h5\n",
      "Epoch 367/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.4183 - accuracy: 0.5088 - val_loss: 1.7602 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00367: val_loss improved from 1.76268 to 1.76022, saving model to models\\best_model_weights.h5\n",
      "Epoch 368/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.4174 - accuracy: 0.4971 - val_loss: 1.7643 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 1.76022\n",
      "Epoch 369/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.4156 - accuracy: 0.5088 - val_loss: 1.7751 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 1.76022\n",
      "Epoch 370/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4144 - accuracy: 0.5146 - val_loss: 1.7732 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 1.76022\n",
      "Epoch 371/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.4137 - accuracy: 0.5029 - val_loss: 1.7715 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 1.76022\n",
      "Epoch 372/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4134 - accuracy: 0.4912 - val_loss: 1.7680 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 1.76022\n",
      "Epoch 373/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4130 - accuracy: 0.4971 - val_loss: 1.7616 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 1.76022\n",
      "Epoch 374/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.4119 - accuracy: 0.5088 - val_loss: 1.7620 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 1.76022\n",
      "Epoch 375/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.4106 - accuracy: 0.5029 - val_loss: 1.7704 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 1.76022\n",
      "Epoch 376/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.4080 - accuracy: 0.5088 - val_loss: 1.7668 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 1.76022\n",
      "Epoch 377/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4070 - accuracy: 0.5205 - val_loss: 1.7678 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 1.76022\n",
      "Epoch 378/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4057 - accuracy: 0.5205 - val_loss: 1.7721 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 1.76022\n",
      "Epoch 379/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.4044 - accuracy: 0.5205 - val_loss: 1.7671 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 1.76022\n",
      "Epoch 380/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4031 - accuracy: 0.5088 - val_loss: 1.7591 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00380: val_loss improved from 1.76022 to 1.75910, saving model to models\\best_model_weights.h5\n",
      "Epoch 381/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.4019 - accuracy: 0.5029 - val_loss: 1.7581 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00381: val_loss improved from 1.75910 to 1.75805, saving model to models\\best_model_weights.h5\n",
      "Epoch 382/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.4012 - accuracy: 0.5205 - val_loss: 1.7578 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00382: val_loss improved from 1.75805 to 1.75784, saving model to models\\best_model_weights.h5\n",
      "Epoch 383/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3997 - accuracy: 0.5263 - val_loss: 1.7599 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 1.75784\n",
      "Epoch 384/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.3999 - accuracy: 0.5205 - val_loss: 1.7599 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 1.75784\n",
      "Epoch 385/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3969 - accuracy: 0.5205 - val_loss: 1.7577 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00385: val_loss improved from 1.75784 to 1.75767, saving model to models\\best_model_weights.h5\n",
      "Epoch 386/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3970 - accuracy: 0.5205 - val_loss: 1.7558 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00386: val_loss improved from 1.75767 to 1.75581, saving model to models\\best_model_weights.h5\n",
      "Epoch 387/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3945 - accuracy: 0.5146 - val_loss: 1.7593 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 1.75581\n",
      "Epoch 388/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.3959 - accuracy: 0.5088 - val_loss: 1.7579 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 1.75581\n",
      "Epoch 389/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3956 - accuracy: 0.5263 - val_loss: 1.7635 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 1.75581\n",
      "Epoch 390/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3951 - accuracy: 0.5205 - val_loss: 1.7643 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 1.75581\n",
      "Epoch 391/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3922 - accuracy: 0.5263 - val_loss: 1.7566 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 1.75581\n",
      "Epoch 392/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3896 - accuracy: 0.5205 - val_loss: 1.7497 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00392: val_loss improved from 1.75581 to 1.74974, saving model to models\\best_model_weights.h5\n",
      "Epoch 393/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3898 - accuracy: 0.5146 - val_loss: 1.7478 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00393: val_loss improved from 1.74974 to 1.74777, saving model to models\\best_model_weights.h5\n",
      "Epoch 394/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3879 - accuracy: 0.5380 - val_loss: 1.7483 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 1.74777\n",
      "Epoch 395/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3894 - accuracy: 0.5263 - val_loss: 1.7540 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 1.74777\n",
      "Epoch 396/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.3890 - accuracy: 0.5205 - val_loss: 1.7509 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 1.74777\n",
      "Epoch 397/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3830 - accuracy: 0.5088 - val_loss: 1.7497 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 1.74777\n",
      "Epoch 398/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.3844 - accuracy: 0.5088 - val_loss: 1.7479 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 1.74777\n",
      "Epoch 399/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3812 - accuracy: 0.5263 - val_loss: 1.7440 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00399: val_loss improved from 1.74777 to 1.74401, saving model to models\\best_model_weights.h5\n",
      "Epoch 400/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3807 - accuracy: 0.5322 - val_loss: 1.7472 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 1.74401\n",
      "Epoch 401/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3800 - accuracy: 0.5322 - val_loss: 1.7520 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 1.74401\n",
      "Epoch 402/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3783 - accuracy: 0.5322 - val_loss: 1.7529 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 1.74401\n",
      "Epoch 403/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3781 - accuracy: 0.5322 - val_loss: 1.7551 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 1.74401\n",
      "Epoch 404/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3765 - accuracy: 0.5146 - val_loss: 1.7579 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 1.74401\n",
      "Epoch 405/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3739 - accuracy: 0.5322 - val_loss: 1.7595 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 1.74401\n",
      "Epoch 406/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3751 - accuracy: 0.5205 - val_loss: 1.7575 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 1.74401\n",
      "Epoch 407/2000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.3735 - accuracy: 0.5380 - val_loss: 1.7533 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 1.74401\n",
      "Epoch 408/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3725 - accuracy: 0.5263 - val_loss: 1.7494 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 1.74401\n",
      "Epoch 409/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3719 - accuracy: 0.4971 - val_loss: 1.7488 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 1.74401\n",
      "Epoch 410/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3716 - accuracy: 0.4912 - val_loss: 1.7436 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00410: val_loss improved from 1.74401 to 1.74360, saving model to models\\best_model_weights.h5\n",
      "Epoch 411/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3682 - accuracy: 0.5029 - val_loss: 1.7442 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 1.74360\n",
      "Epoch 412/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3701 - accuracy: 0.5205 - val_loss: 1.7462 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 1.74360\n",
      "Epoch 413/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3682 - accuracy: 0.5263 - val_loss: 1.7446 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 1.74360\n",
      "Epoch 414/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.3665 - accuracy: 0.5322 - val_loss: 1.7463 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 1.74360\n",
      "Epoch 415/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3641 - accuracy: 0.5263 - val_loss: 1.7442 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 1.74360\n",
      "Epoch 416/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.3649 - accuracy: 0.5380 - val_loss: 1.7392 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00416: val_loss improved from 1.74360 to 1.73921, saving model to models\\best_model_weights.h5\n",
      "Epoch 417/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3649 - accuracy: 0.5205 - val_loss: 1.7438 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 1.73921\n",
      "Epoch 418/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3617 - accuracy: 0.5146 - val_loss: 1.7426 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 1.73921\n",
      "Epoch 419/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3618 - accuracy: 0.5380 - val_loss: 1.7477 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 1.73921\n",
      "Epoch 420/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3602 - accuracy: 0.5497 - val_loss: 1.7479 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 1.73921\n",
      "Epoch 421/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.3606 - accuracy: 0.5263 - val_loss: 1.7437 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 1.73921\n",
      "Epoch 422/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.3574 - accuracy: 0.5263 - val_loss: 1.7339 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00422: val_loss improved from 1.73921 to 1.73387, saving model to models\\best_model_weights.h5\n",
      "Epoch 423/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3571 - accuracy: 0.5263 - val_loss: 1.7253 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00423: val_loss improved from 1.73387 to 1.72532, saving model to models\\best_model_weights.h5\n",
      "Epoch 424/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3554 - accuracy: 0.5205 - val_loss: 1.7267 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 1.72532\n",
      "Epoch 425/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3550 - accuracy: 0.5263 - val_loss: 1.7263 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 1.72532\n",
      "Epoch 426/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.3535 - accuracy: 0.5263 - val_loss: 1.7271 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 1.72532\n",
      "Epoch 427/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.3521 - accuracy: 0.5380 - val_loss: 1.7328 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 1.72532\n",
      "Epoch 428/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3509 - accuracy: 0.5263 - val_loss: 1.7296 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 1.72532\n",
      "Epoch 429/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.3514 - accuracy: 0.5439 - val_loss: 1.7316 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 1.72532\n",
      "Epoch 430/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.3518 - accuracy: 0.5322 - val_loss: 1.7312 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 1.72532\n",
      "Epoch 431/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3466 - accuracy: 0.5263 - val_loss: 1.7302 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 1.72532\n",
      "Epoch 432/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3470 - accuracy: 0.5322 - val_loss: 1.7302 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 1.72532\n",
      "Epoch 433/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3464 - accuracy: 0.5322 - val_loss: 1.7301 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 1.72532\n",
      "Epoch 434/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3459 - accuracy: 0.5322 - val_loss: 1.7343 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 1.72532\n",
      "Epoch 435/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3444 - accuracy: 0.5380 - val_loss: 1.7319 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 1.72532\n",
      "Epoch 436/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3426 - accuracy: 0.5380 - val_loss: 1.7300 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 1.72532\n",
      "Epoch 437/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3417 - accuracy: 0.5497 - val_loss: 1.7274 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 1.72532\n",
      "Epoch 438/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3416 - accuracy: 0.5614 - val_loss: 1.7290 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 1.72532\n",
      "Epoch 439/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3399 - accuracy: 0.5556 - val_loss: 1.7216 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00439: val_loss improved from 1.72532 to 1.72163, saving model to models\\best_model_weights.h5\n",
      "Epoch 440/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3414 - accuracy: 0.5497 - val_loss: 1.7193 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00440: val_loss improved from 1.72163 to 1.71933, saving model to models\\best_model_weights.h5\n",
      "Epoch 441/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3377 - accuracy: 0.5439 - val_loss: 1.7195 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 1.71933\n",
      "Epoch 442/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3367 - accuracy: 0.5322 - val_loss: 1.7245 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 1.71933\n",
      "Epoch 443/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3369 - accuracy: 0.5205 - val_loss: 1.7316 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 1.71933\n",
      "Epoch 444/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.3360 - accuracy: 0.5205 - val_loss: 1.7286 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 1.71933\n",
      "Epoch 445/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3355 - accuracy: 0.5380 - val_loss: 1.7221 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 1.71933\n",
      "Epoch 446/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3345 - accuracy: 0.5439 - val_loss: 1.7180 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00446: val_loss improved from 1.71933 to 1.71804, saving model to models\\best_model_weights.h5\n",
      "Epoch 447/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3320 - accuracy: 0.5263 - val_loss: 1.7255 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 1.71804\n",
      "Epoch 448/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3318 - accuracy: 0.5322 - val_loss: 1.7264 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 1.71804\n",
      "Epoch 449/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.3308 - accuracy: 0.5380 - val_loss: 1.7254 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 1.71804\n",
      "Epoch 450/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3287 - accuracy: 0.5263 - val_loss: 1.7250 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 1.71804\n",
      "Epoch 451/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3280 - accuracy: 0.5439 - val_loss: 1.7184 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 1.71804\n",
      "Epoch 452/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3272 - accuracy: 0.5497 - val_loss: 1.7129 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00452: val_loss improved from 1.71804 to 1.71293, saving model to models\\best_model_weights.h5\n",
      "Epoch 453/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3254 - accuracy: 0.5380 - val_loss: 1.7179 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 1.71293\n",
      "Epoch 454/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3280 - accuracy: 0.5497 - val_loss: 1.7319 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 1.71293\n",
      "Epoch 455/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3243 - accuracy: 0.5497 - val_loss: 1.7281 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 1.71293\n",
      "Epoch 456/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3242 - accuracy: 0.5556 - val_loss: 1.7224 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 1.71293\n",
      "Epoch 457/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3221 - accuracy: 0.5556 - val_loss: 1.7237 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 1.71293\n",
      "Epoch 458/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.3209 - accuracy: 0.5497 - val_loss: 1.7290 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 1.71293\n",
      "Epoch 459/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3226 - accuracy: 0.5439 - val_loss: 1.7272 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 1.71293\n",
      "Epoch 460/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3202 - accuracy: 0.5556 - val_loss: 1.7164 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 1.71293\n",
      "Epoch 461/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3183 - accuracy: 0.5380 - val_loss: 1.7069 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00461: val_loss improved from 1.71293 to 1.70686, saving model to models\\best_model_weights.h5\n",
      "Epoch 462/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3178 - accuracy: 0.5380 - val_loss: 1.7103 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 1.70686\n",
      "Epoch 463/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3176 - accuracy: 0.5380 - val_loss: 1.7201 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 1.70686\n",
      "Epoch 464/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.3157 - accuracy: 0.5497 - val_loss: 1.7119 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 1.70686\n",
      "Epoch 465/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3143 - accuracy: 0.5497 - val_loss: 1.7102 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 1.70686\n",
      "Epoch 466/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3135 - accuracy: 0.5439 - val_loss: 1.7084 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 1.70686\n",
      "Epoch 467/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.3138 - accuracy: 0.5673 - val_loss: 1.7081 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 1.70686\n",
      "Epoch 468/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3136 - accuracy: 0.5614 - val_loss: 1.7124 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 1.70686\n",
      "Epoch 469/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3125 - accuracy: 0.5673 - val_loss: 1.7181 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 1.70686\n",
      "Epoch 470/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3110 - accuracy: 0.5556 - val_loss: 1.7185 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 1.70686\n",
      "Epoch 471/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3079 - accuracy: 0.5556 - val_loss: 1.7230 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 1.70686\n",
      "Epoch 472/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3078 - accuracy: 0.5380 - val_loss: 1.7227 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 1.70686\n",
      "Epoch 473/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3083 - accuracy: 0.5322 - val_loss: 1.7186 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 1.70686\n",
      "Epoch 474/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3063 - accuracy: 0.5322 - val_loss: 1.7146 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 1.70686\n",
      "Epoch 475/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3058 - accuracy: 0.5497 - val_loss: 1.7215 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 1.70686\n",
      "Epoch 476/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3046 - accuracy: 0.5614 - val_loss: 1.7230 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 1.70686\n",
      "Epoch 477/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3033 - accuracy: 0.5614 - val_loss: 1.7280 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 1.70686\n",
      "Epoch 478/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.3050 - accuracy: 0.5673 - val_loss: 1.7324 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 1.70686\n",
      "Epoch 479/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3014 - accuracy: 0.5673 - val_loss: 1.7277 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 1.70686\n",
      "Epoch 480/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3004 - accuracy: 0.5614 - val_loss: 1.7191 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 1.70686\n",
      "Epoch 481/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3025 - accuracy: 0.5497 - val_loss: 1.7122 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 1.70686\n",
      "Epoch 482/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3007 - accuracy: 0.5556 - val_loss: 1.7128 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 1.70686\n",
      "Epoch 483/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2974 - accuracy: 0.5556 - val_loss: 1.7121 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 1.70686\n",
      "Epoch 484/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2980 - accuracy: 0.5556 - val_loss: 1.7174 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 1.70686\n",
      "Epoch 485/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.2960 - accuracy: 0.5556 - val_loss: 1.7139 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 1.70686\n",
      "Epoch 486/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.2966 - accuracy: 0.5614 - val_loss: 1.7114 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 1.70686\n",
      "Epoch 487/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.2952 - accuracy: 0.5614 - val_loss: 1.7152 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 1.70686\n",
      "Epoch 488/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2938 - accuracy: 0.5439 - val_loss: 1.7088 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 1.70686\n",
      "Epoch 489/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2925 - accuracy: 0.5556 - val_loss: 1.7119 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 1.70686\n",
      "Epoch 490/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2917 - accuracy: 0.5556 - val_loss: 1.7095 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 1.70686\n",
      "Epoch 491/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2900 - accuracy: 0.5614 - val_loss: 1.7076 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 1.70686\n",
      "Epoch 492/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2890 - accuracy: 0.5497 - val_loss: 1.7065 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00492: val_loss improved from 1.70686 to 1.70654, saving model to models\\best_model_weights.h5\n",
      "Epoch 493/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2885 - accuracy: 0.5614 - val_loss: 1.7058 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00493: val_loss improved from 1.70654 to 1.70577, saving model to models\\best_model_weights.h5\n",
      "Epoch 494/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2877 - accuracy: 0.5556 - val_loss: 1.7167 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 1.70577\n",
      "Epoch 495/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2864 - accuracy: 0.5614 - val_loss: 1.7133 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 1.70577\n",
      "Epoch 496/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2855 - accuracy: 0.5673 - val_loss: 1.7096 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 1.70577\n",
      "Epoch 497/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2856 - accuracy: 0.5731 - val_loss: 1.7136 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 1.70577\n",
      "Epoch 498/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2839 - accuracy: 0.5906 - val_loss: 1.7140 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 1.70577\n",
      "Epoch 499/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2826 - accuracy: 0.5789 - val_loss: 1.7131 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 1.70577\n",
      "Epoch 500/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2825 - accuracy: 0.5614 - val_loss: 1.7126 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 1.70577\n",
      "Epoch 501/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.2818 - accuracy: 0.5614 - val_loss: 1.7060 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 1.70577\n",
      "Epoch 502/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2813 - accuracy: 0.5556 - val_loss: 1.7016 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00502: val_loss improved from 1.70577 to 1.70161, saving model to models\\best_model_weights.h5\n",
      "Epoch 503/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.2803 - accuracy: 0.5439 - val_loss: 1.7026 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 1.70161\n",
      "Epoch 504/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2774 - accuracy: 0.5439 - val_loss: 1.7069 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 1.70161\n",
      "Epoch 505/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2781 - accuracy: 0.5673 - val_loss: 1.7087 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 1.70161\n",
      "Epoch 506/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2782 - accuracy: 0.5848 - val_loss: 1.7220 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 1.70161\n",
      "Epoch 507/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2779 - accuracy: 0.5848 - val_loss: 1.7158 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 1.70161\n",
      "Epoch 508/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2762 - accuracy: 0.5731 - val_loss: 1.7146 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 1.70161\n",
      "Epoch 509/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2738 - accuracy: 0.5731 - val_loss: 1.7099 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 1.70161\n",
      "Epoch 510/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2737 - accuracy: 0.5731 - val_loss: 1.7038 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 1.70161\n",
      "Epoch 511/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2723 - accuracy: 0.5848 - val_loss: 1.7042 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 1.70161\n",
      "Epoch 512/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2731 - accuracy: 0.5848 - val_loss: 1.7077 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 1.70161\n",
      "Epoch 513/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.2710 - accuracy: 0.5789 - val_loss: 1.6980 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00513: val_loss improved from 1.70161 to 1.69802, saving model to models\\best_model_weights.h5\n",
      "Epoch 514/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2699 - accuracy: 0.5906 - val_loss: 1.6996 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 1.69802\n",
      "Epoch 515/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2696 - accuracy: 0.5965 - val_loss: 1.6978 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00515: val_loss improved from 1.69802 to 1.69780, saving model to models\\best_model_weights.h5\n",
      "Epoch 516/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.2687 - accuracy: 0.6023 - val_loss: 1.6907 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00516: val_loss improved from 1.69780 to 1.69068, saving model to models\\best_model_weights.h5\n",
      "Epoch 517/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2694 - accuracy: 0.5906 - val_loss: 1.6961 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 1.69068\n",
      "Epoch 518/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2655 - accuracy: 0.5789 - val_loss: 1.6999 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 1.69068\n",
      "Epoch 519/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2648 - accuracy: 0.5614 - val_loss: 1.7045 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 1.69068\n",
      "Epoch 520/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2667 - accuracy: 0.5731 - val_loss: 1.7007 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 1.69068\n",
      "Epoch 521/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2630 - accuracy: 0.5673 - val_loss: 1.6951 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 1.69068\n",
      "Epoch 522/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2635 - accuracy: 0.5556 - val_loss: 1.6929 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 1.69068\n",
      "Epoch 523/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.2632 - accuracy: 0.5556 - val_loss: 1.6898 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00523: val_loss improved from 1.69068 to 1.68981, saving model to models\\best_model_weights.h5\n",
      "Epoch 524/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2613 - accuracy: 0.5673 - val_loss: 1.7025 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 1.68981\n",
      "Epoch 525/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2602 - accuracy: 0.5848 - val_loss: 1.7020 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 1.68981\n",
      "Epoch 526/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2592 - accuracy: 0.5789 - val_loss: 1.7039 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 1.68981\n",
      "Epoch 527/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2579 - accuracy: 0.5965 - val_loss: 1.6978 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 1.68981\n",
      "Epoch 528/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.2570 - accuracy: 0.6023 - val_loss: 1.7017 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 1.68981\n",
      "Epoch 529/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2581 - accuracy: 0.5789 - val_loss: 1.6983 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 1.68981\n",
      "Epoch 530/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2586 - accuracy: 0.5848 - val_loss: 1.6918 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 1.68981\n",
      "Epoch 531/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2557 - accuracy: 0.5906 - val_loss: 1.6934 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 1.68981\n",
      "Epoch 532/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2533 - accuracy: 0.5789 - val_loss: 1.6993 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 1.68981\n",
      "Epoch 533/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2529 - accuracy: 0.5731 - val_loss: 1.6966 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 1.68981\n",
      "Epoch 534/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.2501 - accuracy: 0.6023 - val_loss: 1.6934 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 1.68981\n",
      "Epoch 535/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.2503 - accuracy: 0.5965 - val_loss: 1.6978 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 1.68981\n",
      "Epoch 536/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2500 - accuracy: 0.5965 - val_loss: 1.7083 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 1.68981\n",
      "Epoch 537/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2497 - accuracy: 0.5965 - val_loss: 1.7055 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 1.68981\n",
      "Epoch 538/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2504 - accuracy: 0.6023 - val_loss: 1.6981 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 1.68981\n",
      "Epoch 539/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2487 - accuracy: 0.5965 - val_loss: 1.6977 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 1.68981\n",
      "Epoch 540/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2473 - accuracy: 0.5906 - val_loss: 1.7011 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 1.68981\n",
      "Epoch 541/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2455 - accuracy: 0.5906 - val_loss: 1.6960 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 1.68981\n",
      "Epoch 542/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2438 - accuracy: 0.5789 - val_loss: 1.6958 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 1.68981\n",
      "Epoch 543/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2443 - accuracy: 0.5848 - val_loss: 1.7053 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 1.68981\n",
      "Epoch 544/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.2433 - accuracy: 0.6023 - val_loss: 1.7119 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 1.68981\n",
      "Epoch 545/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2436 - accuracy: 0.5848 - val_loss: 1.7116 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 1.68981\n",
      "Epoch 546/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2415 - accuracy: 0.5965 - val_loss: 1.7059 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 1.68981\n",
      "Epoch 547/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2413 - accuracy: 0.6023 - val_loss: 1.6969 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 1.68981\n",
      "Epoch 548/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.2405 - accuracy: 0.6023 - val_loss: 1.7000 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 1.68981\n",
      "Epoch 549/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.2410 - accuracy: 0.5906 - val_loss: 1.7072 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 1.68981\n",
      "Epoch 550/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2416 - accuracy: 0.5906 - val_loss: 1.7043 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 1.68981\n",
      "Epoch 551/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2372 - accuracy: 0.5673 - val_loss: 1.6922 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 1.68981\n",
      "Epoch 552/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2400 - accuracy: 0.5673 - val_loss: 1.6878 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00552: val_loss improved from 1.68981 to 1.68784, saving model to models\\best_model_weights.h5\n",
      "Epoch 553/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2365 - accuracy: 0.5789 - val_loss: 1.6873 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00553: val_loss improved from 1.68784 to 1.68725, saving model to models\\best_model_weights.h5\n",
      "Epoch 554/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2358 - accuracy: 0.5848 - val_loss: 1.6905 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 1.68725\n",
      "Epoch 555/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2328 - accuracy: 0.6023 - val_loss: 1.6969 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 1.68725\n",
      "Epoch 556/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2345 - accuracy: 0.5848 - val_loss: 1.7118 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 1.68725\n",
      "Epoch 557/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2343 - accuracy: 0.5789 - val_loss: 1.7048 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 1.68725\n",
      "Epoch 558/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2328 - accuracy: 0.5965 - val_loss: 1.6961 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 1.68725\n",
      "Epoch 559/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2320 - accuracy: 0.6023 - val_loss: 1.6905 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 1.68725\n",
      "Epoch 560/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2298 - accuracy: 0.6082 - val_loss: 1.6932 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 1.68725\n",
      "Epoch 561/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2284 - accuracy: 0.5965 - val_loss: 1.7051 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 1.68725\n",
      "Epoch 562/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2289 - accuracy: 0.5848 - val_loss: 1.7045 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 1.68725\n",
      "Epoch 563/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2297 - accuracy: 0.5789 - val_loss: 1.7063 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 1.68725\n",
      "Epoch 564/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2275 - accuracy: 0.5906 - val_loss: 1.6932 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 1.68725\n",
      "Epoch 565/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2289 - accuracy: 0.6023 - val_loss: 1.6833 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00565: val_loss improved from 1.68725 to 1.68332, saving model to models\\best_model_weights.h5\n",
      "Epoch 566/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2278 - accuracy: 0.6140 - val_loss: 1.6916 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 1.68332\n",
      "Epoch 567/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.2254 - accuracy: 0.6023 - val_loss: 1.6944 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 1.68332\n",
      "Epoch 568/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2230 - accuracy: 0.6199 - val_loss: 1.6978 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 1.68332\n",
      "Epoch 569/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.2220 - accuracy: 0.6082 - val_loss: 1.6993 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 1.68332\n",
      "Epoch 570/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2206 - accuracy: 0.5965 - val_loss: 1.6945 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 1.68332\n",
      "Epoch 571/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2216 - accuracy: 0.5906 - val_loss: 1.6959 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 1.68332\n",
      "Epoch 572/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2220 - accuracy: 0.5965 - val_loss: 1.6980 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 1.68332\n",
      "Epoch 573/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.2223 - accuracy: 0.5965 - val_loss: 1.6956 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 1.68332\n",
      "Epoch 574/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2187 - accuracy: 0.6082 - val_loss: 1.6915 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 1.68332\n",
      "Epoch 575/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2177 - accuracy: 0.6140 - val_loss: 1.6954 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 1.68332\n",
      "Epoch 576/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2178 - accuracy: 0.6082 - val_loss: 1.6993 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 1.68332\n",
      "Epoch 577/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.2168 - accuracy: 0.6023 - val_loss: 1.6981 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 1.68332\n",
      "Epoch 578/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2157 - accuracy: 0.6140 - val_loss: 1.6871 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 1.68332\n",
      "Epoch 579/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2143 - accuracy: 0.6140 - val_loss: 1.6842 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 1.68332\n",
      "Epoch 580/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.2149 - accuracy: 0.5965 - val_loss: 1.6930 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 1.68332\n",
      "Epoch 581/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2132 - accuracy: 0.5906 - val_loss: 1.6887 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 1.68332\n",
      "Epoch 582/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.2155 - accuracy: 0.6140 - val_loss: 1.6973 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 1.68332\n",
      "Epoch 583/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.2128 - accuracy: 0.6140 - val_loss: 1.7011 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 1.68332\n",
      "Epoch 584/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2120 - accuracy: 0.6023 - val_loss: 1.7040 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 1.68332\n",
      "Epoch 585/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2096 - accuracy: 0.6082 - val_loss: 1.6988 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 1.68332\n",
      "Epoch 586/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2094 - accuracy: 0.6082 - val_loss: 1.6966 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 1.68332\n",
      "Epoch 587/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.2100 - accuracy: 0.6023 - val_loss: 1.6881 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 1.68332\n",
      "Epoch 588/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2072 - accuracy: 0.6140 - val_loss: 1.6833 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00588: val_loss improved from 1.68332 to 1.68328, saving model to models\\best_model_weights.h5\n",
      "Epoch 589/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2063 - accuracy: 0.6082 - val_loss: 1.6887 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 1.68328\n",
      "Epoch 590/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2050 - accuracy: 0.6082 - val_loss: 1.6994 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 1.68328\n",
      "Epoch 591/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2047 - accuracy: 0.5906 - val_loss: 1.7037 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 1.68328\n",
      "Epoch 592/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.2064 - accuracy: 0.5965 - val_loss: 1.6998 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 1.68328\n",
      "Epoch 593/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.2044 - accuracy: 0.5965 - val_loss: 1.6918 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 1.68328\n",
      "Epoch 594/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2022 - accuracy: 0.6140 - val_loss: 1.6877 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 1.68328\n",
      "Epoch 595/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2015 - accuracy: 0.6140 - val_loss: 1.6834 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 1.68328\n",
      "Epoch 596/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1998 - accuracy: 0.6082 - val_loss: 1.6864 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 1.68328\n",
      "Epoch 597/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1982 - accuracy: 0.6140 - val_loss: 1.6900 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 1.68328\n",
      "Epoch 598/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1998 - accuracy: 0.6023 - val_loss: 1.6979 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 1.68328\n",
      "Epoch 599/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1971 - accuracy: 0.6082 - val_loss: 1.6885 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 1.68328\n",
      "Epoch 600/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1977 - accuracy: 0.6023 - val_loss: 1.6787 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00600: val_loss improved from 1.68328 to 1.67873, saving model to models\\best_model_weights.h5\n",
      "Epoch 601/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1972 - accuracy: 0.6257 - val_loss: 1.6769 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00601: val_loss improved from 1.67873 to 1.67694, saving model to models\\best_model_weights.h5\n",
      "Epoch 602/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1974 - accuracy: 0.6140 - val_loss: 1.6842 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 1.67694\n",
      "Epoch 603/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1948 - accuracy: 0.6140 - val_loss: 1.6847 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 1.67694\n",
      "Epoch 604/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1948 - accuracy: 0.6199 - val_loss: 1.6842 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 1.67694\n",
      "Epoch 605/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1926 - accuracy: 0.6257 - val_loss: 1.6879 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 1.67694\n",
      "Epoch 606/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1938 - accuracy: 0.6082 - val_loss: 1.6876 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 1.67694\n",
      "Epoch 607/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1903 - accuracy: 0.6199 - val_loss: 1.6853 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 1.67694\n",
      "Epoch 608/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1916 - accuracy: 0.6199 - val_loss: 1.6875 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 1.67694\n",
      "Epoch 609/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1915 - accuracy: 0.6082 - val_loss: 1.6981 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 1.67694\n",
      "Epoch 610/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1908 - accuracy: 0.6082 - val_loss: 1.6993 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 1.67694\n",
      "Epoch 611/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1896 - accuracy: 0.6140 - val_loss: 1.6981 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 1.67694\n",
      "Epoch 612/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1897 - accuracy: 0.5965 - val_loss: 1.7027 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 1.67694\n",
      "Epoch 613/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1874 - accuracy: 0.6082 - val_loss: 1.6998 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 1.67694\n",
      "Epoch 614/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1873 - accuracy: 0.6023 - val_loss: 1.6908 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 1.67694\n",
      "Epoch 615/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1878 - accuracy: 0.5965 - val_loss: 1.6874 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 1.67694\n",
      "Epoch 616/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1860 - accuracy: 0.6199 - val_loss: 1.6931 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 1.67694\n",
      "Epoch 617/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.1873 - accuracy: 0.6199 - val_loss: 1.6847 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 1.67694\n",
      "Epoch 618/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.1835 - accuracy: 0.6199 - val_loss: 1.6921 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 1.67694\n",
      "Epoch 619/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1857 - accuracy: 0.6082 - val_loss: 1.7057 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 1.67694\n",
      "Epoch 620/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1829 - accuracy: 0.6140 - val_loss: 1.7019 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 1.67694\n",
      "Epoch 621/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1828 - accuracy: 0.6257 - val_loss: 1.6901 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 1.67694\n",
      "Epoch 622/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1795 - accuracy: 0.6257 - val_loss: 1.6948 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 1.67694\n",
      "Epoch 623/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1807 - accuracy: 0.6257 - val_loss: 1.6898 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 1.67694\n",
      "Epoch 624/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1784 - accuracy: 0.6199 - val_loss: 1.6823 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 1.67694\n",
      "Epoch 625/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1781 - accuracy: 0.6257 - val_loss: 1.6771 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 1.67694\n",
      "Epoch 626/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1765 - accuracy: 0.6140 - val_loss: 1.6832 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 1.67694\n",
      "Epoch 627/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1743 - accuracy: 0.6199 - val_loss: 1.6830 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 1.67694\n",
      "Epoch 628/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1769 - accuracy: 0.6082 - val_loss: 1.6799 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 1.67694\n",
      "Epoch 629/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1772 - accuracy: 0.6140 - val_loss: 1.6813 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 1.67694\n",
      "Epoch 630/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1766 - accuracy: 0.6082 - val_loss: 1.6894 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 1.67694\n",
      "Epoch 631/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1752 - accuracy: 0.6082 - val_loss: 1.6840 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 1.67694\n",
      "Epoch 632/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1717 - accuracy: 0.6082 - val_loss: 1.6801 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 1.67694\n",
      "Epoch 633/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1709 - accuracy: 0.6199 - val_loss: 1.6775 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 1.67694\n",
      "Epoch 634/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1745 - accuracy: 0.6257 - val_loss: 1.6858 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 1.67694\n",
      "Epoch 635/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1705 - accuracy: 0.6257 - val_loss: 1.6831 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 1.67694\n",
      "Epoch 636/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1678 - accuracy: 0.6257 - val_loss: 1.6870 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 1.67694\n",
      "Epoch 637/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1740 - accuracy: 0.6082 - val_loss: 1.6972 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 1.67694\n",
      "Epoch 638/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1708 - accuracy: 0.6082 - val_loss: 1.6917 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 1.67694\n",
      "Epoch 639/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1654 - accuracy: 0.6257 - val_loss: 1.6940 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 1.67694\n",
      "Epoch 640/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1677 - accuracy: 0.6082 - val_loss: 1.6924 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 1.67694\n",
      "Epoch 641/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1671 - accuracy: 0.5906 - val_loss: 1.6825 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 1.67694\n",
      "Epoch 642/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1656 - accuracy: 0.6082 - val_loss: 1.6767 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00642: val_loss improved from 1.67694 to 1.67670, saving model to models\\best_model_weights.h5\n",
      "Epoch 643/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1670 - accuracy: 0.6082 - val_loss: 1.6714 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00643: val_loss improved from 1.67670 to 1.67144, saving model to models\\best_model_weights.h5\n",
      "Epoch 644/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1649 - accuracy: 0.6199 - val_loss: 1.6757 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 1.67144\n",
      "Epoch 645/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1645 - accuracy: 0.6199 - val_loss: 1.6803 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 1.67144\n",
      "Epoch 646/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1624 - accuracy: 0.6257 - val_loss: 1.6851 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 1.67144\n",
      "Epoch 647/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1607 - accuracy: 0.6374 - val_loss: 1.6885 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 1.67144\n",
      "Epoch 648/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1607 - accuracy: 0.6316 - val_loss: 1.6927 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 1.67144\n",
      "Epoch 649/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1591 - accuracy: 0.6316 - val_loss: 1.6902 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 1.67144\n",
      "Epoch 650/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1580 - accuracy: 0.6316 - val_loss: 1.6835 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 1.67144\n",
      "Epoch 651/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.1586 - accuracy: 0.6316 - val_loss: 1.6775 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 1.67144\n",
      "Epoch 652/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1582 - accuracy: 0.6199 - val_loss: 1.6758 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 1.67144\n",
      "Epoch 653/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1570 - accuracy: 0.6199 - val_loss: 1.6762 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 1.67144\n",
      "Epoch 654/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1563 - accuracy: 0.6316 - val_loss: 1.6794 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 1.67144\n",
      "Epoch 655/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1558 - accuracy: 0.6316 - val_loss: 1.6822 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 1.67144\n",
      "Epoch 656/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1534 - accuracy: 0.6374 - val_loss: 1.6823 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 1.67144\n",
      "Epoch 657/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1572 - accuracy: 0.6140 - val_loss: 1.6831 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 1.67144\n",
      "Epoch 658/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1561 - accuracy: 0.6082 - val_loss: 1.6745 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 1.67144\n",
      "Epoch 659/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1529 - accuracy: 0.6316 - val_loss: 1.6712 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00659: val_loss improved from 1.67144 to 1.67116, saving model to models\\best_model_weights.h5\n",
      "Epoch 660/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1507 - accuracy: 0.6433 - val_loss: 1.6784 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 1.67116\n",
      "Epoch 661/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1521 - accuracy: 0.6257 - val_loss: 1.6884 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 1.67116\n",
      "Epoch 662/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1508 - accuracy: 0.6199 - val_loss: 1.6932 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 1.67116\n",
      "Epoch 663/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1514 - accuracy: 0.6257 - val_loss: 1.6838 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 1.67116\n",
      "Epoch 664/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1479 - accuracy: 0.6316 - val_loss: 1.6737 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 1.67116\n",
      "Epoch 665/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1487 - accuracy: 0.6257 - val_loss: 1.6740 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 1.67116\n",
      "Epoch 666/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1490 - accuracy: 0.6433 - val_loss: 1.6713 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 1.67116\n",
      "Epoch 667/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1472 - accuracy: 0.6374 - val_loss: 1.6770 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 1.67116\n",
      "Epoch 668/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1466 - accuracy: 0.6374 - val_loss: 1.6751 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 1.67116\n",
      "Epoch 669/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1465 - accuracy: 0.6316 - val_loss: 1.6660 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00669: val_loss improved from 1.67116 to 1.66604, saving model to models\\best_model_weights.h5\n",
      "Epoch 670/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.1455 - accuracy: 0.6374 - val_loss: 1.6644 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00670: val_loss improved from 1.66604 to 1.66438, saving model to models\\best_model_weights.h5\n",
      "Epoch 671/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1435 - accuracy: 0.6433 - val_loss: 1.6633 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00671: val_loss improved from 1.66438 to 1.66333, saving model to models\\best_model_weights.h5\n",
      "Epoch 672/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1426 - accuracy: 0.6491 - val_loss: 1.6643 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 1.66333\n",
      "Epoch 673/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1433 - accuracy: 0.6608 - val_loss: 1.6623 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00673: val_loss improved from 1.66333 to 1.66229, saving model to models\\best_model_weights.h5\n",
      "Epoch 674/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1422 - accuracy: 0.6550 - val_loss: 1.6642 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 1.66229\n",
      "Epoch 675/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1410 - accuracy: 0.6491 - val_loss: 1.6642 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 1.66229\n",
      "Epoch 676/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1417 - accuracy: 0.6433 - val_loss: 1.6697 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 1.66229\n",
      "Epoch 677/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1386 - accuracy: 0.6491 - val_loss: 1.6728 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 1.66229\n",
      "Epoch 678/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1396 - accuracy: 0.6550 - val_loss: 1.6727 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 1.66229\n",
      "Epoch 679/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1391 - accuracy: 0.6374 - val_loss: 1.6760 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 1.66229\n",
      "Epoch 680/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1393 - accuracy: 0.6316 - val_loss: 1.6816 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 1.66229\n",
      "Epoch 681/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1376 - accuracy: 0.6316 - val_loss: 1.6897 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 1.66229\n",
      "Epoch 682/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1375 - accuracy: 0.6374 - val_loss: 1.6860 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 1.66229\n",
      "Epoch 683/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1349 - accuracy: 0.6374 - val_loss: 1.6761 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 1.66229\n",
      "Epoch 684/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1334 - accuracy: 0.6316 - val_loss: 1.6690 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 1.66229\n",
      "Epoch 685/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1346 - accuracy: 0.6257 - val_loss: 1.6701 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 1.66229\n",
      "Epoch 686/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1350 - accuracy: 0.6257 - val_loss: 1.6771 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 1.66229\n",
      "Epoch 687/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1328 - accuracy: 0.6257 - val_loss: 1.6796 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 1.66229\n",
      "Epoch 688/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1311 - accuracy: 0.6316 - val_loss: 1.6792 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 1.66229\n",
      "Epoch 689/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1324 - accuracy: 0.6491 - val_loss: 1.6763 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 1.66229\n",
      "Epoch 690/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1307 - accuracy: 0.6433 - val_loss: 1.6686 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 1.66229\n",
      "Epoch 691/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1300 - accuracy: 0.6374 - val_loss: 1.6607 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00691: val_loss improved from 1.66229 to 1.66069, saving model to models\\best_model_weights.h5\n",
      "Epoch 692/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1319 - accuracy: 0.6491 - val_loss: 1.6666 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 1.66069\n",
      "Epoch 693/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1299 - accuracy: 0.6316 - val_loss: 1.6714 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 1.66069\n",
      "Epoch 694/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1305 - accuracy: 0.6374 - val_loss: 1.6810 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 1.66069\n",
      "Epoch 695/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1274 - accuracy: 0.6433 - val_loss: 1.6806 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 1.66069\n",
      "Epoch 696/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1282 - accuracy: 0.6374 - val_loss: 1.6685 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 1.66069\n",
      "Epoch 697/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1241 - accuracy: 0.6491 - val_loss: 1.6742 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 1.66069\n",
      "Epoch 698/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1250 - accuracy: 0.6433 - val_loss: 1.6803 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 1.66069\n",
      "Epoch 699/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1224 - accuracy: 0.6433 - val_loss: 1.6735 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 1.66069\n",
      "Epoch 700/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1237 - accuracy: 0.6433 - val_loss: 1.6738 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 1.66069\n",
      "Epoch 701/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1226 - accuracy: 0.6374 - val_loss: 1.6677 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 1.66069\n",
      "Epoch 702/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.1238 - accuracy: 0.6433 - val_loss: 1.6727 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 1.66069\n",
      "Epoch 703/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1219 - accuracy: 0.6491 - val_loss: 1.6632 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 1.66069\n",
      "Epoch 704/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1195 - accuracy: 0.6491 - val_loss: 1.6575 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00704: val_loss improved from 1.66069 to 1.65750, saving model to models\\best_model_weights.h5\n",
      "Epoch 705/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1180 - accuracy: 0.6550 - val_loss: 1.6562 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00705: val_loss improved from 1.65750 to 1.65618, saving model to models\\best_model_weights.h5\n",
      "Epoch 706/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1209 - accuracy: 0.6433 - val_loss: 1.6695 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 1.65618\n",
      "Epoch 707/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1190 - accuracy: 0.6491 - val_loss: 1.6705 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 1.65618\n",
      "Epoch 708/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1176 - accuracy: 0.6491 - val_loss: 1.6695 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 1.65618\n",
      "Epoch 709/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1159 - accuracy: 0.6491 - val_loss: 1.6692 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 1.65618\n",
      "Epoch 710/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1152 - accuracy: 0.6491 - val_loss: 1.6726 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 1.65618\n",
      "Epoch 711/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1157 - accuracy: 0.6433 - val_loss: 1.6771 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 1.65618\n",
      "Epoch 712/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1133 - accuracy: 0.6374 - val_loss: 1.6750 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 1.65618\n",
      "Epoch 713/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1121 - accuracy: 0.6374 - val_loss: 1.6787 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 1.65618\n",
      "Epoch 714/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1125 - accuracy: 0.6316 - val_loss: 1.6826 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 1.65618\n",
      "Epoch 715/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1131 - accuracy: 0.6433 - val_loss: 1.6808 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 1.65618\n",
      "Epoch 716/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1100 - accuracy: 0.6374 - val_loss: 1.6744 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 1.65618\n",
      "Epoch 717/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1105 - accuracy: 0.6491 - val_loss: 1.6820 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 1.65618\n",
      "Epoch 718/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1101 - accuracy: 0.6550 - val_loss: 1.6888 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 1.65618\n",
      "Epoch 719/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1105 - accuracy: 0.6491 - val_loss: 1.6774 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 1.65618\n",
      "Epoch 720/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.1078 - accuracy: 0.6491 - val_loss: 1.6841 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 1.65618\n",
      "Epoch 721/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1075 - accuracy: 0.6433 - val_loss: 1.6826 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 1.65618\n",
      "Epoch 722/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1066 - accuracy: 0.6433 - val_loss: 1.6805 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 1.65618\n",
      "Epoch 723/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1047 - accuracy: 0.6491 - val_loss: 1.6864 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 1.65618\n",
      "Epoch 724/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1055 - accuracy: 0.6491 - val_loss: 1.6824 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 1.65618\n",
      "Epoch 725/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1084 - accuracy: 0.6433 - val_loss: 1.6854 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 1.65618\n",
      "Epoch 726/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1056 - accuracy: 0.6550 - val_loss: 1.6796 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 1.65618\n",
      "Epoch 727/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1043 - accuracy: 0.6433 - val_loss: 1.6804 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 1.65618\n",
      "Epoch 728/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1033 - accuracy: 0.6374 - val_loss: 1.6813 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 1.65618\n",
      "Epoch 729/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1032 - accuracy: 0.6433 - val_loss: 1.6788 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 1.65618\n",
      "Epoch 730/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1013 - accuracy: 0.6550 - val_loss: 1.6847 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 1.65618\n",
      "Epoch 731/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1006 - accuracy: 0.6608 - val_loss: 1.6845 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 1.65618\n",
      "Epoch 732/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0990 - accuracy: 0.6550 - val_loss: 1.6785 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 1.65618\n",
      "Epoch 733/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.0998 - accuracy: 0.6550 - val_loss: 1.6737 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 1.65618\n",
      "Epoch 734/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1009 - accuracy: 0.6491 - val_loss: 1.6711 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 1.65618\n",
      "Epoch 735/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0988 - accuracy: 0.6491 - val_loss: 1.6800 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 1.65618\n",
      "Epoch 736/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0985 - accuracy: 0.6433 - val_loss: 1.6939 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 1.65618\n",
      "Epoch 737/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0976 - accuracy: 0.6433 - val_loss: 1.6850 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 1.65618\n",
      "Epoch 738/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0978 - accuracy: 0.6550 - val_loss: 1.6821 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 1.65618\n",
      "Epoch 739/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.0954 - accuracy: 0.6433 - val_loss: 1.6671 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 1.65618\n",
      "Epoch 740/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0939 - accuracy: 0.6491 - val_loss: 1.6629 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 1.65618\n",
      "Epoch 741/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0944 - accuracy: 0.6550 - val_loss: 1.6640 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 1.65618\n",
      "Epoch 742/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0921 - accuracy: 0.6608 - val_loss: 1.6726 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 1.65618\n",
      "Epoch 743/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0935 - accuracy: 0.6550 - val_loss: 1.6796 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 1.65618\n",
      "Epoch 744/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0936 - accuracy: 0.6491 - val_loss: 1.6821 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 1.65618\n",
      "Epoch 745/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0916 - accuracy: 0.6550 - val_loss: 1.6773 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 1.65618\n",
      "Epoch 746/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0913 - accuracy: 0.6550 - val_loss: 1.6687 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 1.65618\n",
      "Epoch 747/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.0903 - accuracy: 0.6550 - val_loss: 1.6643 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 1.65618\n",
      "Epoch 748/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0901 - accuracy: 0.6550 - val_loss: 1.6648 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 1.65618\n",
      "Epoch 749/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0894 - accuracy: 0.6608 - val_loss: 1.6682 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 1.65618\n",
      "Epoch 750/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0885 - accuracy: 0.6491 - val_loss: 1.6730 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 1.65618\n",
      "Epoch 751/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.0862 - accuracy: 0.6433 - val_loss: 1.6690 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 1.65618\n",
      "Epoch 752/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0878 - accuracy: 0.6550 - val_loss: 1.6679 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 1.65618\n",
      "Epoch 753/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0860 - accuracy: 0.6608 - val_loss: 1.6646 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 1.65618\n",
      "Epoch 754/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0842 - accuracy: 0.6608 - val_loss: 1.6710 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 1.65618\n",
      "Epoch 755/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0847 - accuracy: 0.6667 - val_loss: 1.6764 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 1.65618\n",
      "Epoch 756/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0838 - accuracy: 0.6608 - val_loss: 1.6783 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 1.65618\n",
      "Epoch 757/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0825 - accuracy: 0.6491 - val_loss: 1.6712 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 1.65618\n",
      "Epoch 758/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0829 - accuracy: 0.6491 - val_loss: 1.6589 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 1.65618\n",
      "Epoch 759/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0817 - accuracy: 0.6667 - val_loss: 1.6639 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 1.65618\n",
      "Epoch 760/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0799 - accuracy: 0.6550 - val_loss: 1.6683 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 1.65618\n",
      "Epoch 761/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0801 - accuracy: 0.6550 - val_loss: 1.6681 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 1.65618\n",
      "Epoch 762/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0818 - accuracy: 0.6667 - val_loss: 1.6674 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 1.65618\n",
      "Epoch 763/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.0789 - accuracy: 0.6608 - val_loss: 1.6787 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 1.65618\n",
      "Epoch 764/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0773 - accuracy: 0.6433 - val_loss: 1.6780 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00764: val_loss did not improve from 1.65618\n",
      "Epoch 765/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0768 - accuracy: 0.6550 - val_loss: 1.6780 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00765: val_loss did not improve from 1.65618\n",
      "Epoch 766/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0750 - accuracy: 0.6667 - val_loss: 1.6709 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00766: val_loss did not improve from 1.65618\n",
      "Epoch 767/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0756 - accuracy: 0.6667 - val_loss: 1.6684 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00767: val_loss did not improve from 1.65618\n",
      "Epoch 768/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0761 - accuracy: 0.6608 - val_loss: 1.6689 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 1.65618\n",
      "Epoch 769/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0736 - accuracy: 0.6550 - val_loss: 1.6708 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 1.65618\n",
      "Epoch 770/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0717 - accuracy: 0.6491 - val_loss: 1.6667 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 1.65618\n",
      "Epoch 771/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0732 - accuracy: 0.6608 - val_loss: 1.6588 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 1.65618\n",
      "Epoch 772/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0742 - accuracy: 0.6725 - val_loss: 1.6646 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 1.65618\n",
      "Epoch 773/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0726 - accuracy: 0.6784 - val_loss: 1.6686 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00773: val_loss did not improve from 1.65618\n",
      "Epoch 774/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0706 - accuracy: 0.6784 - val_loss: 1.6643 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 1.65618\n",
      "Epoch 775/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0710 - accuracy: 0.6784 - val_loss: 1.6653 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 1.65618\n",
      "Epoch 776/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0713 - accuracy: 0.6725 - val_loss: 1.6605 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 1.65618\n",
      "Epoch 777/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.0702 - accuracy: 0.6667 - val_loss: 1.6593 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 1.65618\n",
      "Epoch 778/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0685 - accuracy: 0.6667 - val_loss: 1.6684 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 1.65618\n",
      "Epoch 779/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0693 - accuracy: 0.6608 - val_loss: 1.6652 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 1.65618\n",
      "Epoch 780/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0674 - accuracy: 0.6667 - val_loss: 1.6598 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 1.65618\n",
      "Epoch 781/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0659 - accuracy: 0.6725 - val_loss: 1.6581 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00781: val_loss did not improve from 1.65618\n",
      "Epoch 782/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0663 - accuracy: 0.6667 - val_loss: 1.6551 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00782: val_loss improved from 1.65618 to 1.65507, saving model to models\\best_model_weights.h5\n",
      "Epoch 783/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0676 - accuracy: 0.6667 - val_loss: 1.6560 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 1.65507\n",
      "Epoch 784/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0646 - accuracy: 0.6608 - val_loss: 1.6607 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 1.65507\n",
      "Epoch 785/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0643 - accuracy: 0.6608 - val_loss: 1.6655 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 1.65507\n",
      "Epoch 786/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0648 - accuracy: 0.6550 - val_loss: 1.6707 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00786: val_loss did not improve from 1.65507\n",
      "Epoch 787/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0617 - accuracy: 0.6667 - val_loss: 1.6623 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00787: val_loss did not improve from 1.65507\n",
      "Epoch 788/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0603 - accuracy: 0.6491 - val_loss: 1.6541 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00788: val_loss improved from 1.65507 to 1.65406, saving model to models\\best_model_weights.h5\n",
      "Epoch 789/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0621 - accuracy: 0.6667 - val_loss: 1.6527 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00789: val_loss improved from 1.65406 to 1.65267, saving model to models\\best_model_weights.h5\n",
      "Epoch 790/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0614 - accuracy: 0.6725 - val_loss: 1.6616 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00790: val_loss did not improve from 1.65267\n",
      "Epoch 791/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0589 - accuracy: 0.6608 - val_loss: 1.6697 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00791: val_loss did not improve from 1.65267\n",
      "Epoch 792/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.0576 - accuracy: 0.6667 - val_loss: 1.6727 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00792: val_loss did not improve from 1.65267\n",
      "Epoch 793/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0576 - accuracy: 0.6725 - val_loss: 1.6654 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00793: val_loss did not improve from 1.65267\n",
      "Epoch 794/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0570 - accuracy: 0.6608 - val_loss: 1.6621 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00794: val_loss did not improve from 1.65267\n",
      "Epoch 795/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0564 - accuracy: 0.6608 - val_loss: 1.6552 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00795: val_loss did not improve from 1.65267\n",
      "Epoch 796/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0574 - accuracy: 0.6608 - val_loss: 1.6499 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00796: val_loss improved from 1.65267 to 1.64995, saving model to models\\best_model_weights.h5\n",
      "Epoch 797/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0566 - accuracy: 0.6725 - val_loss: 1.6623 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00797: val_loss did not improve from 1.64995\n",
      "Epoch 798/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0534 - accuracy: 0.6667 - val_loss: 1.6693 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00798: val_loss did not improve from 1.64995\n",
      "Epoch 799/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0542 - accuracy: 0.6608 - val_loss: 1.6738 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00799: val_loss did not improve from 1.64995\n",
      "Epoch 800/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0535 - accuracy: 0.6608 - val_loss: 1.6676 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00800: val_loss did not improve from 1.64995\n",
      "Epoch 801/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0518 - accuracy: 0.6608 - val_loss: 1.6642 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00801: val_loss did not improve from 1.64995\n",
      "Epoch 802/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0519 - accuracy: 0.6667 - val_loss: 1.6616 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00802: val_loss did not improve from 1.64995\n",
      "Epoch 803/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0520 - accuracy: 0.6784 - val_loss: 1.6638 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00803: val_loss did not improve from 1.64995\n",
      "Epoch 804/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0502 - accuracy: 0.6667 - val_loss: 1.6642 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00804: val_loss did not improve from 1.64995\n",
      "Epoch 805/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0489 - accuracy: 0.6725 - val_loss: 1.6683 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00805: val_loss did not improve from 1.64995\n",
      "Epoch 806/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0488 - accuracy: 0.6550 - val_loss: 1.6561 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00806: val_loss did not improve from 1.64995\n",
      "Epoch 807/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.0457 - accuracy: 0.6667 - val_loss: 1.6499 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00807: val_loss improved from 1.64995 to 1.64986, saving model to models\\best_model_weights.h5\n",
      "Epoch 808/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0462 - accuracy: 0.6550 - val_loss: 1.6472 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00808: val_loss improved from 1.64986 to 1.64724, saving model to models\\best_model_weights.h5\n",
      "Epoch 809/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0487 - accuracy: 0.6550 - val_loss: 1.6511 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00809: val_loss did not improve from 1.64724\n",
      "Epoch 810/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0451 - accuracy: 0.6550 - val_loss: 1.6662 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00810: val_loss did not improve from 1.64724\n",
      "Epoch 811/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0463 - accuracy: 0.6725 - val_loss: 1.6665 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00811: val_loss did not improve from 1.64724\n",
      "Epoch 812/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0437 - accuracy: 0.6784 - val_loss: 1.6720 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00812: val_loss did not improve from 1.64724\n",
      "Epoch 813/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0426 - accuracy: 0.6725 - val_loss: 1.6610 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00813: val_loss did not improve from 1.64724\n",
      "Epoch 814/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0444 - accuracy: 0.6667 - val_loss: 1.6542 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00814: val_loss did not improve from 1.64724\n",
      "Epoch 815/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0464 - accuracy: 0.6725 - val_loss: 1.6484 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00815: val_loss did not improve from 1.64724\n",
      "Epoch 816/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0403 - accuracy: 0.6784 - val_loss: 1.6558 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00816: val_loss did not improve from 1.64724\n",
      "Epoch 817/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0403 - accuracy: 0.6784 - val_loss: 1.6545 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00817: val_loss did not improve from 1.64724\n",
      "Epoch 818/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0412 - accuracy: 0.6784 - val_loss: 1.6620 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00818: val_loss did not improve from 1.64724\n",
      "Epoch 819/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0392 - accuracy: 0.6784 - val_loss: 1.6564 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00819: val_loss did not improve from 1.64724\n",
      "Epoch 820/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0388 - accuracy: 0.6550 - val_loss: 1.6565 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00820: val_loss did not improve from 1.64724\n",
      "Epoch 821/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.0383 - accuracy: 0.6667 - val_loss: 1.6663 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00821: val_loss did not improve from 1.64724\n",
      "Epoch 822/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0376 - accuracy: 0.6667 - val_loss: 1.6611 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00822: val_loss did not improve from 1.64724\n",
      "Epoch 823/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0363 - accuracy: 0.6667 - val_loss: 1.6614 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00823: val_loss did not improve from 1.64724\n",
      "Epoch 824/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0369 - accuracy: 0.6784 - val_loss: 1.6536 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00824: val_loss did not improve from 1.64724\n",
      "Epoch 825/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0357 - accuracy: 0.6784 - val_loss: 1.6505 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00825: val_loss did not improve from 1.64724\n",
      "Epoch 826/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0355 - accuracy: 0.6608 - val_loss: 1.6494 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00826: val_loss did not improve from 1.64724\n",
      "Epoch 827/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0390 - accuracy: 0.6608 - val_loss: 1.6595 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00827: val_loss did not improve from 1.64724\n",
      "Epoch 828/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0325 - accuracy: 0.6784 - val_loss: 1.6460 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00828: val_loss improved from 1.64724 to 1.64601, saving model to models\\best_model_weights.h5\n",
      "Epoch 829/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0330 - accuracy: 0.6667 - val_loss: 1.6397 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00829: val_loss improved from 1.64601 to 1.63974, saving model to models\\best_model_weights.h5\n",
      "Epoch 830/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0307 - accuracy: 0.6725 - val_loss: 1.6419 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00830: val_loss did not improve from 1.63974\n",
      "Epoch 831/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0324 - accuracy: 0.6784 - val_loss: 1.6489 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00831: val_loss did not improve from 1.63974\n",
      "Epoch 832/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0310 - accuracy: 0.6784 - val_loss: 1.6534 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00832: val_loss did not improve from 1.63974\n",
      "Epoch 833/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0299 - accuracy: 0.6784 - val_loss: 1.6577 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00833: val_loss did not improve from 1.63974\n",
      "Epoch 834/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0289 - accuracy: 0.6725 - val_loss: 1.6585 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00834: val_loss did not improve from 1.63974\n",
      "Epoch 835/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0311 - accuracy: 0.6784 - val_loss: 1.6590 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00835: val_loss did not improve from 1.63974\n",
      "Epoch 836/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0276 - accuracy: 0.6725 - val_loss: 1.6561 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00836: val_loss did not improve from 1.63974\n",
      "Epoch 837/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0267 - accuracy: 0.6667 - val_loss: 1.6652 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00837: val_loss did not improve from 1.63974\n",
      "Epoch 838/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0261 - accuracy: 0.6784 - val_loss: 1.6642 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00838: val_loss did not improve from 1.63974\n",
      "Epoch 839/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0261 - accuracy: 0.6725 - val_loss: 1.6596 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00839: val_loss did not improve from 1.63974\n",
      "Epoch 840/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0254 - accuracy: 0.6725 - val_loss: 1.6484 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00840: val_loss did not improve from 1.63974\n",
      "Epoch 841/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0245 - accuracy: 0.6608 - val_loss: 1.6465 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00841: val_loss did not improve from 1.63974\n",
      "Epoch 842/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0234 - accuracy: 0.6608 - val_loss: 1.6501 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00842: val_loss did not improve from 1.63974\n",
      "Epoch 843/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0242 - accuracy: 0.6842 - val_loss: 1.6477 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00843: val_loss did not improve from 1.63974\n",
      "Epoch 844/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0215 - accuracy: 0.6842 - val_loss: 1.6483 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00844: val_loss did not improve from 1.63974\n",
      "Epoch 845/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0217 - accuracy: 0.6901 - val_loss: 1.6539 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00845: val_loss did not improve from 1.63974\n",
      "Epoch 846/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0222 - accuracy: 0.6784 - val_loss: 1.6580 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00846: val_loss did not improve from 1.63974\n",
      "Epoch 847/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0219 - accuracy: 0.6784 - val_loss: 1.6539 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00847: val_loss did not improve from 1.63974\n",
      "Epoch 848/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0188 - accuracy: 0.6725 - val_loss: 1.6571 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00848: val_loss did not improve from 1.63974\n",
      "Epoch 849/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.0187 - accuracy: 0.6667 - val_loss: 1.6544 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00849: val_loss did not improve from 1.63974\n",
      "Epoch 850/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0200 - accuracy: 0.6725 - val_loss: 1.6532 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00850: val_loss did not improve from 1.63974\n",
      "Epoch 851/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0175 - accuracy: 0.6784 - val_loss: 1.6514 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00851: val_loss did not improve from 1.63974\n",
      "Epoch 852/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0158 - accuracy: 0.6901 - val_loss: 1.6505 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00852: val_loss did not improve from 1.63974\n",
      "Epoch 853/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0157 - accuracy: 0.6959 - val_loss: 1.6479 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00853: val_loss did not improve from 1.63974\n",
      "Epoch 854/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0148 - accuracy: 0.6901 - val_loss: 1.6554 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00854: val_loss did not improve from 1.63974\n",
      "Epoch 855/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0152 - accuracy: 0.6842 - val_loss: 1.6661 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00855: val_loss did not improve from 1.63974\n",
      "Epoch 856/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0132 - accuracy: 0.6959 - val_loss: 1.6652 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00856: val_loss did not improve from 1.63974\n",
      "Epoch 857/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0141 - accuracy: 0.6959 - val_loss: 1.6616 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00857: val_loss did not improve from 1.63974\n",
      "Epoch 858/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0118 - accuracy: 0.6842 - val_loss: 1.6577 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00858: val_loss did not improve from 1.63974\n",
      "Epoch 859/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0123 - accuracy: 0.6725 - val_loss: 1.6653 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00859: val_loss did not improve from 1.63974\n",
      "Epoch 860/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0112 - accuracy: 0.6842 - val_loss: 1.6683 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00860: val_loss did not improve from 1.63974\n",
      "Epoch 861/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0110 - accuracy: 0.6842 - val_loss: 1.6666 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00861: val_loss did not improve from 1.63974\n",
      "Epoch 862/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0095 - accuracy: 0.6842 - val_loss: 1.6724 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00862: val_loss did not improve from 1.63974\n",
      "Epoch 863/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0104 - accuracy: 0.6784 - val_loss: 1.6617 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00863: val_loss did not improve from 1.63974\n",
      "Epoch 864/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0085 - accuracy: 0.6784 - val_loss: 1.6507 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00864: val_loss did not improve from 1.63974\n",
      "Epoch 865/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0086 - accuracy: 0.6959 - val_loss: 1.6429 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00865: val_loss did not improve from 1.63974\n",
      "Epoch 866/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.0075 - accuracy: 0.6842 - val_loss: 1.6395 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00866: val_loss improved from 1.63974 to 1.63953, saving model to models\\best_model_weights.h5\n",
      "Epoch 867/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.0075 - accuracy: 0.6784 - val_loss: 1.6386 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00867: val_loss improved from 1.63953 to 1.63864, saving model to models\\best_model_weights.h5\n",
      "Epoch 868/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0061 - accuracy: 0.6901 - val_loss: 1.6448 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00868: val_loss did not improve from 1.63864\n",
      "Epoch 869/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.0047 - accuracy: 0.6901 - val_loss: 1.6630 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00869: val_loss did not improve from 1.63864\n",
      "Epoch 870/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0039 - accuracy: 0.6959 - val_loss: 1.6619 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00870: val_loss did not improve from 1.63864\n",
      "Epoch 871/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0044 - accuracy: 0.6784 - val_loss: 1.6652 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00871: val_loss did not improve from 1.63864\n",
      "Epoch 872/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0037 - accuracy: 0.6725 - val_loss: 1.6655 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00872: val_loss did not improve from 1.63864\n",
      "Epoch 873/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0044 - accuracy: 0.6842 - val_loss: 1.6534 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00873: val_loss did not improve from 1.63864\n",
      "Epoch 874/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.0037 - accuracy: 0.6725 - val_loss: 1.6528 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00874: val_loss did not improve from 1.63864\n",
      "Epoch 875/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0021 - accuracy: 0.6901 - val_loss: 1.6555 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00875: val_loss did not improve from 1.63864\n",
      "Epoch 876/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0005 - accuracy: 0.7018 - val_loss: 1.6512 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00876: val_loss did not improve from 1.63864\n",
      "Epoch 877/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0008 - accuracy: 0.6901 - val_loss: 1.6488 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00877: val_loss did not improve from 1.63864\n",
      "Epoch 878/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9990 - accuracy: 0.6901 - val_loss: 1.6465 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00878: val_loss did not improve from 1.63864\n",
      "Epoch 879/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9971 - accuracy: 0.6725 - val_loss: 1.6583 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00879: val_loss did not improve from 1.63864\n",
      "Epoch 880/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.9974 - accuracy: 0.6784 - val_loss: 1.6567 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00880: val_loss did not improve from 1.63864\n",
      "Epoch 881/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9965 - accuracy: 0.6725 - val_loss: 1.6588 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00881: val_loss did not improve from 1.63864\n",
      "Epoch 882/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9972 - accuracy: 0.6725 - val_loss: 1.6696 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00882: val_loss did not improve from 1.63864\n",
      "Epoch 883/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9980 - accuracy: 0.6725 - val_loss: 1.6707 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00883: val_loss did not improve from 1.63864\n",
      "Epoch 884/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9951 - accuracy: 0.6842 - val_loss: 1.6703 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00884: val_loss did not improve from 1.63864\n",
      "Epoch 885/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9940 - accuracy: 0.6784 - val_loss: 1.6641 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00885: val_loss did not improve from 1.63864\n",
      "Epoch 886/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9943 - accuracy: 0.6901 - val_loss: 1.6564 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00886: val_loss did not improve from 1.63864\n",
      "Epoch 887/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9921 - accuracy: 0.6959 - val_loss: 1.6526 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00887: val_loss did not improve from 1.63864\n",
      "Epoch 888/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9929 - accuracy: 0.7076 - val_loss: 1.6500 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00888: val_loss did not improve from 1.63864\n",
      "Epoch 889/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9920 - accuracy: 0.6842 - val_loss: 1.6490 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00889: val_loss did not improve from 1.63864\n",
      "Epoch 890/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9934 - accuracy: 0.6842 - val_loss: 1.6490 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00890: val_loss did not improve from 1.63864\n",
      "Epoch 891/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9898 - accuracy: 0.6842 - val_loss: 1.6548 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00891: val_loss did not improve from 1.63864\n",
      "Epoch 892/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9887 - accuracy: 0.6725 - val_loss: 1.6640 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00892: val_loss did not improve from 1.63864\n",
      "Epoch 893/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9901 - accuracy: 0.6784 - val_loss: 1.6592 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00893: val_loss did not improve from 1.63864\n",
      "Epoch 894/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9885 - accuracy: 0.6959 - val_loss: 1.6460 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00894: val_loss did not improve from 1.63864\n",
      "Epoch 895/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9903 - accuracy: 0.6784 - val_loss: 1.6409 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00895: val_loss did not improve from 1.63864\n",
      "Epoch 896/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9890 - accuracy: 0.6784 - val_loss: 1.6366 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00896: val_loss improved from 1.63864 to 1.63664, saving model to models\\best_model_weights.h5\n",
      "Epoch 897/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9872 - accuracy: 0.6784 - val_loss: 1.6469 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00897: val_loss did not improve from 1.63664\n",
      "Epoch 898/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9855 - accuracy: 0.6901 - val_loss: 1.6634 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00898: val_loss did not improve from 1.63664\n",
      "Epoch 899/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9850 - accuracy: 0.6959 - val_loss: 1.6633 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00899: val_loss did not improve from 1.63664\n",
      "Epoch 900/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9850 - accuracy: 0.6901 - val_loss: 1.6650 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00900: val_loss did not improve from 1.63664\n",
      "Epoch 901/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9837 - accuracy: 0.6901 - val_loss: 1.6608 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00901: val_loss did not improve from 1.63664\n",
      "Epoch 902/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9835 - accuracy: 0.7018 - val_loss: 1.6534 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00902: val_loss did not improve from 1.63664\n",
      "Epoch 903/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9832 - accuracy: 0.6959 - val_loss: 1.6441 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00903: val_loss did not improve from 1.63664\n",
      "Epoch 904/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9812 - accuracy: 0.6901 - val_loss: 1.6493 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00904: val_loss did not improve from 1.63664\n",
      "Epoch 905/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9828 - accuracy: 0.6901 - val_loss: 1.6558 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00905: val_loss did not improve from 1.63664\n",
      "Epoch 906/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9823 - accuracy: 0.6784 - val_loss: 1.6534 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 00906: val_loss did not improve from 1.63664\n",
      "Epoch 907/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9810 - accuracy: 0.6842 - val_loss: 1.6506 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00907: val_loss did not improve from 1.63664\n",
      "Epoch 908/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9791 - accuracy: 0.6901 - val_loss: 1.6505 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00908: val_loss did not improve from 1.63664\n",
      "Epoch 909/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9769 - accuracy: 0.6959 - val_loss: 1.6502 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00909: val_loss did not improve from 1.63664\n",
      "Epoch 910/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9782 - accuracy: 0.6959 - val_loss: 1.6502 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00910: val_loss did not improve from 1.63664\n",
      "Epoch 911/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9780 - accuracy: 0.7076 - val_loss: 1.6560 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00911: val_loss did not improve from 1.63664\n",
      "Epoch 912/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.9761 - accuracy: 0.6901 - val_loss: 1.6575 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00912: val_loss did not improve from 1.63664\n",
      "Epoch 913/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9773 - accuracy: 0.6842 - val_loss: 1.6633 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00913: val_loss did not improve from 1.63664\n",
      "Epoch 914/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9788 - accuracy: 0.6784 - val_loss: 1.6743 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00914: val_loss did not improve from 1.63664\n",
      "Epoch 915/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9778 - accuracy: 0.6784 - val_loss: 1.6663 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00915: val_loss did not improve from 1.63664\n",
      "Epoch 916/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9771 - accuracy: 0.6901 - val_loss: 1.6622 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00916: val_loss did not improve from 1.63664\n",
      "Epoch 917/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9747 - accuracy: 0.6959 - val_loss: 1.6617 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00917: val_loss did not improve from 1.63664\n",
      "Epoch 918/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9741 - accuracy: 0.6959 - val_loss: 1.6543 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00918: val_loss did not improve from 1.63664\n",
      "Epoch 919/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9753 - accuracy: 0.6959 - val_loss: 1.6579 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00919: val_loss did not improve from 1.63664\n",
      "Epoch 920/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9732 - accuracy: 0.7018 - val_loss: 1.6606 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00920: val_loss did not improve from 1.63664\n",
      "Epoch 921/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9736 - accuracy: 0.7018 - val_loss: 1.6645 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00921: val_loss did not improve from 1.63664\n",
      "Epoch 922/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9705 - accuracy: 0.7076 - val_loss: 1.6669 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00922: val_loss did not improve from 1.63664\n",
      "Epoch 923/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9709 - accuracy: 0.7018 - val_loss: 1.6613 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00923: val_loss did not improve from 1.63664\n",
      "Epoch 924/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9700 - accuracy: 0.6901 - val_loss: 1.6468 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00924: val_loss did not improve from 1.63664\n",
      "Epoch 925/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.9712 - accuracy: 0.6842 - val_loss: 1.6424 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 00925: val_loss did not improve from 1.63664\n",
      "Epoch 926/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9709 - accuracy: 0.6784 - val_loss: 1.6538 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00926: val_loss did not improve from 1.63664\n",
      "Epoch 927/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9690 - accuracy: 0.6901 - val_loss: 1.6669 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00927: val_loss did not improve from 1.63664\n",
      "Epoch 928/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9673 - accuracy: 0.7076 - val_loss: 1.6625 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00928: val_loss did not improve from 1.63664\n",
      "Epoch 929/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9683 - accuracy: 0.6901 - val_loss: 1.6552 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00929: val_loss did not improve from 1.63664\n",
      "Epoch 930/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9648 - accuracy: 0.6959 - val_loss: 1.6603 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00930: val_loss did not improve from 1.63664\n",
      "Epoch 931/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9638 - accuracy: 0.7076 - val_loss: 1.6573 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00931: val_loss did not improve from 1.63664\n",
      "Epoch 932/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9653 - accuracy: 0.7018 - val_loss: 1.6627 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00932: val_loss did not improve from 1.63664\n",
      "Epoch 933/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9635 - accuracy: 0.7018 - val_loss: 1.6604 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00933: val_loss did not improve from 1.63664\n",
      "Epoch 934/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9636 - accuracy: 0.7018 - val_loss: 1.6632 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00934: val_loss did not improve from 1.63664\n",
      "Epoch 935/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9638 - accuracy: 0.7076 - val_loss: 1.6639 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00935: val_loss did not improve from 1.63664\n",
      "Epoch 936/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9632 - accuracy: 0.6959 - val_loss: 1.6637 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00936: val_loss did not improve from 1.63664\n",
      "Epoch 937/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9615 - accuracy: 0.6959 - val_loss: 1.6610 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00937: val_loss did not improve from 1.63664\n",
      "Epoch 938/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9590 - accuracy: 0.6901 - val_loss: 1.6693 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00938: val_loss did not improve from 1.63664\n",
      "Epoch 939/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9641 - accuracy: 0.6784 - val_loss: 1.6750 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 00939: val_loss did not improve from 1.63664\n",
      "Epoch 940/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9625 - accuracy: 0.6842 - val_loss: 1.6705 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 00940: val_loss did not improve from 1.63664\n",
      "Epoch 941/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9595 - accuracy: 0.6959 - val_loss: 1.6655 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00941: val_loss did not improve from 1.63664\n",
      "Epoch 942/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9605 - accuracy: 0.7193 - val_loss: 1.6712 - val_accuracy: 0.3421\n",
      "\n",
      "Epoch 00942: val_loss did not improve from 1.63664\n",
      "Epoch 943/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9577 - accuracy: 0.7076 - val_loss: 1.6710 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00943: val_loss did not improve from 1.63664\n",
      "Epoch 944/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9578 - accuracy: 0.6901 - val_loss: 1.6662 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00944: val_loss did not improve from 1.63664\n",
      "Epoch 945/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9582 - accuracy: 0.7018 - val_loss: 1.6670 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00945: val_loss did not improve from 1.63664\n",
      "Epoch 946/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9550 - accuracy: 0.6959 - val_loss: 1.6611 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00946: val_loss did not improve from 1.63664\n",
      "Epoch 947/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9548 - accuracy: 0.6959 - val_loss: 1.6465 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00947: val_loss did not improve from 1.63664\n",
      "Epoch 948/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9549 - accuracy: 0.7018 - val_loss: 1.6432 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00948: val_loss did not improve from 1.63664\n",
      "Epoch 949/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9531 - accuracy: 0.6959 - val_loss: 1.6539 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00949: val_loss did not improve from 1.63664\n",
      "Epoch 950/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9528 - accuracy: 0.7018 - val_loss: 1.6582 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00950: val_loss did not improve from 1.63664\n",
      "Epoch 951/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9514 - accuracy: 0.7018 - val_loss: 1.6684 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00951: val_loss did not improve from 1.63664\n",
      "Epoch 952/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9519 - accuracy: 0.7018 - val_loss: 1.6655 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00952: val_loss did not improve from 1.63664\n",
      "Epoch 953/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.9508 - accuracy: 0.7018 - val_loss: 1.6598 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00953: val_loss did not improve from 1.63664\n",
      "Epoch 954/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9502 - accuracy: 0.7018 - val_loss: 1.6518 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00954: val_loss did not improve from 1.63664\n",
      "Epoch 955/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.9507 - accuracy: 0.6959 - val_loss: 1.6544 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00955: val_loss did not improve from 1.63664\n",
      "Epoch 956/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9487 - accuracy: 0.7076 - val_loss: 1.6587 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00956: val_loss did not improve from 1.63664\n",
      "Epoch 957/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9505 - accuracy: 0.6959 - val_loss: 1.6627 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00957: val_loss did not improve from 1.63664\n",
      "Epoch 958/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9483 - accuracy: 0.6959 - val_loss: 1.6589 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00958: val_loss did not improve from 1.63664\n",
      "Epoch 959/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9470 - accuracy: 0.6901 - val_loss: 1.6616 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00959: val_loss did not improve from 1.63664\n",
      "Epoch 960/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9480 - accuracy: 0.6959 - val_loss: 1.6662 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 00960: val_loss did not improve from 1.63664\n",
      "Epoch 961/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9482 - accuracy: 0.7135 - val_loss: 1.6522 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 00961: val_loss did not improve from 1.63664\n",
      "Epoch 962/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9448 - accuracy: 0.7076 - val_loss: 1.6500 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00962: val_loss did not improve from 1.63664\n",
      "Epoch 963/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9459 - accuracy: 0.7018 - val_loss: 1.6518 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00963: val_loss did not improve from 1.63664\n",
      "Epoch 964/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9444 - accuracy: 0.7076 - val_loss: 1.6621 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00964: val_loss did not improve from 1.63664\n",
      "Epoch 965/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9439 - accuracy: 0.6959 - val_loss: 1.6605 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00965: val_loss did not improve from 1.63664\n",
      "Epoch 966/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9426 - accuracy: 0.7018 - val_loss: 1.6643 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00966: val_loss did not improve from 1.63664\n",
      "Epoch 967/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9409 - accuracy: 0.7076 - val_loss: 1.6611 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00967: val_loss did not improve from 1.63664\n",
      "Epoch 968/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9415 - accuracy: 0.6959 - val_loss: 1.6606 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00968: val_loss did not improve from 1.63664\n",
      "Epoch 969/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9408 - accuracy: 0.7076 - val_loss: 1.6470 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00969: val_loss did not improve from 1.63664\n",
      "Epoch 970/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9407 - accuracy: 0.7076 - val_loss: 1.6459 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00970: val_loss did not improve from 1.63664\n",
      "Epoch 971/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9381 - accuracy: 0.6959 - val_loss: 1.6499 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00971: val_loss did not improve from 1.63664\n",
      "Epoch 972/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9398 - accuracy: 0.7018 - val_loss: 1.6473 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00972: val_loss did not improve from 1.63664\n",
      "Epoch 973/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9404 - accuracy: 0.6959 - val_loss: 1.6444 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00973: val_loss did not improve from 1.63664\n",
      "Epoch 974/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9376 - accuracy: 0.7018 - val_loss: 1.6495 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00974: val_loss did not improve from 1.63664\n",
      "Epoch 975/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.9372 - accuracy: 0.7018 - val_loss: 1.6564 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00975: val_loss did not improve from 1.63664\n",
      "Epoch 976/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9369 - accuracy: 0.6959 - val_loss: 1.6566 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00976: val_loss did not improve from 1.63664\n",
      "Epoch 977/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9356 - accuracy: 0.6959 - val_loss: 1.6542 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00977: val_loss did not improve from 1.63664\n",
      "Epoch 978/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9367 - accuracy: 0.7076 - val_loss: 1.6535 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 00978: val_loss did not improve from 1.63664\n",
      "Epoch 979/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9354 - accuracy: 0.7018 - val_loss: 1.6494 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00979: val_loss did not improve from 1.63664\n",
      "Epoch 980/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.9340 - accuracy: 0.7076 - val_loss: 1.6520 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00980: val_loss did not improve from 1.63664\n",
      "Epoch 981/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9356 - accuracy: 0.7076 - val_loss: 1.6449 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00981: val_loss did not improve from 1.63664\n",
      "Epoch 982/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9332 - accuracy: 0.7018 - val_loss: 1.6564 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00982: val_loss did not improve from 1.63664\n",
      "Epoch 983/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9316 - accuracy: 0.7076 - val_loss: 1.6630 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00983: val_loss did not improve from 1.63664\n",
      "Epoch 984/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9304 - accuracy: 0.7135 - val_loss: 1.6505 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 00984: val_loss did not improve from 1.63664\n",
      "Epoch 985/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9300 - accuracy: 0.7135 - val_loss: 1.6419 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00985: val_loss did not improve from 1.63664\n",
      "Epoch 986/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9308 - accuracy: 0.7076 - val_loss: 1.6349 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00986: val_loss improved from 1.63664 to 1.63494, saving model to models\\best_model_weights.h5\n",
      "Epoch 987/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9310 - accuracy: 0.7018 - val_loss: 1.6426 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00987: val_loss did not improve from 1.63494\n",
      "Epoch 988/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9291 - accuracy: 0.7018 - val_loss: 1.6549 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00988: val_loss did not improve from 1.63494\n",
      "Epoch 989/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9288 - accuracy: 0.7018 - val_loss: 1.6570 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00989: val_loss did not improve from 1.63494\n",
      "Epoch 990/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9289 - accuracy: 0.7018 - val_loss: 1.6527 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 00990: val_loss did not improve from 1.63494\n",
      "Epoch 991/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9266 - accuracy: 0.7076 - val_loss: 1.6484 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00991: val_loss did not improve from 1.63494\n",
      "Epoch 992/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.9265 - accuracy: 0.6959 - val_loss: 1.6581 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00992: val_loss did not improve from 1.63494\n",
      "Epoch 993/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9263 - accuracy: 0.7018 - val_loss: 1.6570 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00993: val_loss did not improve from 1.63494\n",
      "Epoch 994/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9242 - accuracy: 0.7076 - val_loss: 1.6536 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00994: val_loss did not improve from 1.63494\n",
      "Epoch 995/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9258 - accuracy: 0.7076 - val_loss: 1.6522 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00995: val_loss did not improve from 1.63494\n",
      "Epoch 996/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9243 - accuracy: 0.7076 - val_loss: 1.6544 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00996: val_loss did not improve from 1.63494\n",
      "Epoch 997/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9235 - accuracy: 0.7135 - val_loss: 1.6588 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00997: val_loss did not improve from 1.63494\n",
      "Epoch 998/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9247 - accuracy: 0.7018 - val_loss: 1.6649 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00998: val_loss did not improve from 1.63494\n",
      "Epoch 999/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9226 - accuracy: 0.7076 - val_loss: 1.6614 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00999: val_loss did not improve from 1.63494\n",
      "Epoch 1000/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9244 - accuracy: 0.7076 - val_loss: 1.6538 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01000: val_loss did not improve from 1.63494\n",
      "Epoch 1001/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9222 - accuracy: 0.7135 - val_loss: 1.6537 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01001: val_loss did not improve from 1.63494\n",
      "Epoch 1002/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9205 - accuracy: 0.7135 - val_loss: 1.6568 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01002: val_loss did not improve from 1.63494\n",
      "Epoch 1003/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9195 - accuracy: 0.7076 - val_loss: 1.6501 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01003: val_loss did not improve from 1.63494\n",
      "Epoch 1004/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9193 - accuracy: 0.7076 - val_loss: 1.6481 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01004: val_loss did not improve from 1.63494\n",
      "Epoch 1005/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.9201 - accuracy: 0.7193 - val_loss: 1.6493 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01005: val_loss did not improve from 1.63494\n",
      "Epoch 1006/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9191 - accuracy: 0.7251 - val_loss: 1.6531 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01006: val_loss did not improve from 1.63494\n",
      "Epoch 1007/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9185 - accuracy: 0.7193 - val_loss: 1.6536 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01007: val_loss did not improve from 1.63494\n",
      "Epoch 1008/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9209 - accuracy: 0.7193 - val_loss: 1.6498 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01008: val_loss did not improve from 1.63494\n",
      "Epoch 1009/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9164 - accuracy: 0.7018 - val_loss: 1.6393 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01009: val_loss did not improve from 1.63494\n",
      "Epoch 1010/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9161 - accuracy: 0.7135 - val_loss: 1.6517 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01010: val_loss did not improve from 1.63494\n",
      "Epoch 1011/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9160 - accuracy: 0.7135 - val_loss: 1.6550 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01011: val_loss did not improve from 1.63494\n",
      "Epoch 1012/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9158 - accuracy: 0.7193 - val_loss: 1.6525 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01012: val_loss did not improve from 1.63494\n",
      "Epoch 1013/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9169 - accuracy: 0.7135 - val_loss: 1.6506 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01013: val_loss did not improve from 1.63494\n",
      "Epoch 1014/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9126 - accuracy: 0.7193 - val_loss: 1.6485 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01014: val_loss did not improve from 1.63494\n",
      "Epoch 1015/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9117 - accuracy: 0.7193 - val_loss: 1.6512 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01015: val_loss did not improve from 1.63494\n",
      "Epoch 1016/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9107 - accuracy: 0.7251 - val_loss: 1.6566 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01016: val_loss did not improve from 1.63494\n",
      "Epoch 1017/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9114 - accuracy: 0.7135 - val_loss: 1.6714 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01017: val_loss did not improve from 1.63494\n",
      "Epoch 1018/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9123 - accuracy: 0.7076 - val_loss: 1.6719 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01018: val_loss did not improve from 1.63494\n",
      "Epoch 1019/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9097 - accuracy: 0.7193 - val_loss: 1.6627 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01019: val_loss did not improve from 1.63494\n",
      "Epoch 1020/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9097 - accuracy: 0.7193 - val_loss: 1.6602 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01020: val_loss did not improve from 1.63494\n",
      "Epoch 1021/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9104 - accuracy: 0.7135 - val_loss: 1.6619 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01021: val_loss did not improve from 1.63494\n",
      "Epoch 1022/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9095 - accuracy: 0.6959 - val_loss: 1.6612 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01022: val_loss did not improve from 1.63494\n",
      "Epoch 1023/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9084 - accuracy: 0.7076 - val_loss: 1.6600 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01023: val_loss did not improve from 1.63494\n",
      "Epoch 1024/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9061 - accuracy: 0.7135 - val_loss: 1.6667 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01024: val_loss did not improve from 1.63494\n",
      "Epoch 1025/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9082 - accuracy: 0.7193 - val_loss: 1.6663 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01025: val_loss did not improve from 1.63494\n",
      "Epoch 1026/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9049 - accuracy: 0.7135 - val_loss: 1.6741 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01026: val_loss did not improve from 1.63494\n",
      "Epoch 1027/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9064 - accuracy: 0.7310 - val_loss: 1.6671 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01027: val_loss did not improve from 1.63494\n",
      "Epoch 1028/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9042 - accuracy: 0.7310 - val_loss: 1.6625 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01028: val_loss did not improve from 1.63494\n",
      "Epoch 1029/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9041 - accuracy: 0.7193 - val_loss: 1.6580 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01029: val_loss did not improve from 1.63494\n",
      "Epoch 1030/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9041 - accuracy: 0.7251 - val_loss: 1.6569 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01030: val_loss did not improve from 1.63494\n",
      "Epoch 1031/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9021 - accuracy: 0.7193 - val_loss: 1.6665 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01031: val_loss did not improve from 1.63494\n",
      "Epoch 1032/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9013 - accuracy: 0.7076 - val_loss: 1.6725 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01032: val_loss did not improve from 1.63494\n",
      "Epoch 1033/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9038 - accuracy: 0.7076 - val_loss: 1.6768 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01033: val_loss did not improve from 1.63494\n",
      "Epoch 1034/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9014 - accuracy: 0.7135 - val_loss: 1.6623 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01034: val_loss did not improve from 1.63494\n",
      "Epoch 1035/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9002 - accuracy: 0.7193 - val_loss: 1.6530 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01035: val_loss did not improve from 1.63494\n",
      "Epoch 1036/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9006 - accuracy: 0.7135 - val_loss: 1.6645 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01036: val_loss did not improve from 1.63494\n",
      "Epoch 1037/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8988 - accuracy: 0.7251 - val_loss: 1.6681 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01037: val_loss did not improve from 1.63494\n",
      "Epoch 1038/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8978 - accuracy: 0.7193 - val_loss: 1.6673 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01038: val_loss did not improve from 1.63494\n",
      "Epoch 1039/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8986 - accuracy: 0.7251 - val_loss: 1.6608 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01039: val_loss did not improve from 1.63494\n",
      "Epoch 1040/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8971 - accuracy: 0.7076 - val_loss: 1.6683 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01040: val_loss did not improve from 1.63494\n",
      "Epoch 1041/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8994 - accuracy: 0.7193 - val_loss: 1.6669 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01041: val_loss did not improve from 1.63494\n",
      "Epoch 1042/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8978 - accuracy: 0.7193 - val_loss: 1.6623 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01042: val_loss did not improve from 1.63494\n",
      "Epoch 1043/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.8941 - accuracy: 0.7135 - val_loss: 1.6582 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01043: val_loss did not improve from 1.63494\n",
      "Epoch 1044/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8942 - accuracy: 0.7135 - val_loss: 1.6592 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01044: val_loss did not improve from 1.63494\n",
      "Epoch 1045/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8954 - accuracy: 0.7193 - val_loss: 1.6610 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01045: val_loss did not improve from 1.63494\n",
      "Epoch 1046/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8926 - accuracy: 0.7193 - val_loss: 1.6630 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01046: val_loss did not improve from 1.63494\n",
      "Epoch 1047/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8930 - accuracy: 0.7135 - val_loss: 1.6615 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01047: val_loss did not improve from 1.63494\n",
      "Epoch 1048/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8923 - accuracy: 0.7193 - val_loss: 1.6604 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01048: val_loss did not improve from 1.63494\n",
      "Epoch 1049/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8913 - accuracy: 0.7251 - val_loss: 1.6709 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01049: val_loss did not improve from 1.63494\n",
      "Epoch 1050/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8912 - accuracy: 0.7135 - val_loss: 1.6785 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01050: val_loss did not improve from 1.63494\n",
      "Epoch 1051/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8915 - accuracy: 0.7076 - val_loss: 1.6684 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01051: val_loss did not improve from 1.63494\n",
      "Epoch 1052/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8899 - accuracy: 0.7251 - val_loss: 1.6704 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01052: val_loss did not improve from 1.63494\n",
      "Epoch 1053/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8895 - accuracy: 0.7310 - val_loss: 1.6735 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01053: val_loss did not improve from 1.63494\n",
      "Epoch 1054/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8879 - accuracy: 0.7193 - val_loss: 1.6762 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01054: val_loss did not improve from 1.63494\n",
      "Epoch 1055/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8875 - accuracy: 0.7193 - val_loss: 1.6644 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01055: val_loss did not improve from 1.63494\n",
      "Epoch 1056/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8884 - accuracy: 0.7193 - val_loss: 1.6614 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01056: val_loss did not improve from 1.63494\n",
      "Epoch 1057/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8888 - accuracy: 0.7251 - val_loss: 1.6591 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01057: val_loss did not improve from 1.63494\n",
      "Epoch 1058/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8875 - accuracy: 0.7251 - val_loss: 1.6669 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01058: val_loss did not improve from 1.63494\n",
      "Epoch 1059/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8867 - accuracy: 0.7251 - val_loss: 1.6653 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01059: val_loss did not improve from 1.63494\n",
      "Epoch 1060/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8861 - accuracy: 0.7251 - val_loss: 1.6728 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01060: val_loss did not improve from 1.63494\n",
      "Epoch 1061/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8866 - accuracy: 0.7251 - val_loss: 1.6596 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01061: val_loss did not improve from 1.63494\n",
      "Epoch 1062/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8852 - accuracy: 0.7251 - val_loss: 1.6720 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01062: val_loss did not improve from 1.63494\n",
      "Epoch 1063/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8867 - accuracy: 0.7193 - val_loss: 1.6776 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01063: val_loss did not improve from 1.63494\n",
      "Epoch 1064/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8837 - accuracy: 0.7251 - val_loss: 1.6681 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01064: val_loss did not improve from 1.63494\n",
      "Epoch 1065/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8828 - accuracy: 0.7193 - val_loss: 1.6613 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01065: val_loss did not improve from 1.63494\n",
      "Epoch 1066/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.8824 - accuracy: 0.7251 - val_loss: 1.6612 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01066: val_loss did not improve from 1.63494\n",
      "Epoch 1067/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8804 - accuracy: 0.7310 - val_loss: 1.6572 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01067: val_loss did not improve from 1.63494\n",
      "Epoch 1068/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8802 - accuracy: 0.7485 - val_loss: 1.6493 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01068: val_loss did not improve from 1.63494\n",
      "Epoch 1069/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8818 - accuracy: 0.7251 - val_loss: 1.6481 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01069: val_loss did not improve from 1.63494\n",
      "Epoch 1070/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8790 - accuracy: 0.7251 - val_loss: 1.6528 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01070: val_loss did not improve from 1.63494\n",
      "Epoch 1071/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8804 - accuracy: 0.7310 - val_loss: 1.6694 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01071: val_loss did not improve from 1.63494\n",
      "Epoch 1072/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8779 - accuracy: 0.7135 - val_loss: 1.6781 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01072: val_loss did not improve from 1.63494\n",
      "Epoch 1073/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8807 - accuracy: 0.7135 - val_loss: 1.6847 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01073: val_loss did not improve from 1.63494\n",
      "Epoch 1074/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8781 - accuracy: 0.7135 - val_loss: 1.6741 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01074: val_loss did not improve from 1.63494\n",
      "Epoch 1075/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8773 - accuracy: 0.7310 - val_loss: 1.6657 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01075: val_loss did not improve from 1.63494\n",
      "Epoch 1076/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8794 - accuracy: 0.7193 - val_loss: 1.6520 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01076: val_loss did not improve from 1.63494\n",
      "Epoch 1077/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8773 - accuracy: 0.7135 - val_loss: 1.6568 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01077: val_loss did not improve from 1.63494\n",
      "Epoch 1078/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8754 - accuracy: 0.7076 - val_loss: 1.6695 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01078: val_loss did not improve from 1.63494\n",
      "Epoch 1079/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8739 - accuracy: 0.7193 - val_loss: 1.6756 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01079: val_loss did not improve from 1.63494\n",
      "Epoch 1080/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8723 - accuracy: 0.7251 - val_loss: 1.6698 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01080: val_loss did not improve from 1.63494\n",
      "Epoch 1081/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8761 - accuracy: 0.7251 - val_loss: 1.6784 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01081: val_loss did not improve from 1.63494\n",
      "Epoch 1082/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8741 - accuracy: 0.7251 - val_loss: 1.6673 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01082: val_loss did not improve from 1.63494\n",
      "Epoch 1083/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8706 - accuracy: 0.7368 - val_loss: 1.6635 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01083: val_loss did not improve from 1.63494\n",
      "Epoch 1084/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8708 - accuracy: 0.7310 - val_loss: 1.6620 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01084: val_loss did not improve from 1.63494\n",
      "Epoch 1085/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8707 - accuracy: 0.7193 - val_loss: 1.6652 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01085: val_loss did not improve from 1.63494\n",
      "Epoch 1086/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8709 - accuracy: 0.7193 - val_loss: 1.6676 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01086: val_loss did not improve from 1.63494\n",
      "Epoch 1087/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8698 - accuracy: 0.7193 - val_loss: 1.6621 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01087: val_loss did not improve from 1.63494\n",
      "Epoch 1088/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8675 - accuracy: 0.7193 - val_loss: 1.6634 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01088: val_loss did not improve from 1.63494\n",
      "Epoch 1089/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8686 - accuracy: 0.7251 - val_loss: 1.6728 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01089: val_loss did not improve from 1.63494\n",
      "Epoch 1090/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8675 - accuracy: 0.7193 - val_loss: 1.6874 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01090: val_loss did not improve from 1.63494\n",
      "Epoch 1091/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8695 - accuracy: 0.7018 - val_loss: 1.6829 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01091: val_loss did not improve from 1.63494\n",
      "Epoch 1092/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8689 - accuracy: 0.7251 - val_loss: 1.6625 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01092: val_loss did not improve from 1.63494\n",
      "Epoch 1093/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8666 - accuracy: 0.7368 - val_loss: 1.6627 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01093: val_loss did not improve from 1.63494\n",
      "Epoch 1094/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8708 - accuracy: 0.7368 - val_loss: 1.6821 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01094: val_loss did not improve from 1.63494\n",
      "Epoch 1095/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8659 - accuracy: 0.7368 - val_loss: 1.6788 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01095: val_loss did not improve from 1.63494\n",
      "Epoch 1096/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8674 - accuracy: 0.7193 - val_loss: 1.6737 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01096: val_loss did not improve from 1.63494\n",
      "Epoch 1097/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8667 - accuracy: 0.7544 - val_loss: 1.6708 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01097: val_loss did not improve from 1.63494\n",
      "Epoch 1098/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8644 - accuracy: 0.7485 - val_loss: 1.6789 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01098: val_loss did not improve from 1.63494\n",
      "Epoch 1099/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8626 - accuracy: 0.7310 - val_loss: 1.6770 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01099: val_loss did not improve from 1.63494\n",
      "Epoch 1100/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8624 - accuracy: 0.7368 - val_loss: 1.6706 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01100: val_loss did not improve from 1.63494\n",
      "Epoch 1101/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8622 - accuracy: 0.7310 - val_loss: 1.6697 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01101: val_loss did not improve from 1.63494\n",
      "Epoch 1102/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8615 - accuracy: 0.7310 - val_loss: 1.6609 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01102: val_loss did not improve from 1.63494\n",
      "Epoch 1103/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8615 - accuracy: 0.7485 - val_loss: 1.6628 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01103: val_loss did not improve from 1.63494\n",
      "Epoch 1104/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8607 - accuracy: 0.7368 - val_loss: 1.6593 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01104: val_loss did not improve from 1.63494\n",
      "Epoch 1105/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8615 - accuracy: 0.7368 - val_loss: 1.6659 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01105: val_loss did not improve from 1.63494\n",
      "Epoch 1106/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8610 - accuracy: 0.7427 - val_loss: 1.6622 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01106: val_loss did not improve from 1.63494\n",
      "Epoch 1107/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8595 - accuracy: 0.7427 - val_loss: 1.6693 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01107: val_loss did not improve from 1.63494\n",
      "Epoch 1108/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8580 - accuracy: 0.7485 - val_loss: 1.6703 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01108: val_loss did not improve from 1.63494\n",
      "Epoch 1109/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8575 - accuracy: 0.7251 - val_loss: 1.6690 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01109: val_loss did not improve from 1.63494\n",
      "Epoch 1110/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8567 - accuracy: 0.7427 - val_loss: 1.6646 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01110: val_loss did not improve from 1.63494\n",
      "Epoch 1111/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8553 - accuracy: 0.7602 - val_loss: 1.6688 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01111: val_loss did not improve from 1.63494\n",
      "Epoch 1112/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8593 - accuracy: 0.7310 - val_loss: 1.6758 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01112: val_loss did not improve from 1.63494\n",
      "Epoch 1113/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8554 - accuracy: 0.7251 - val_loss: 1.6625 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01113: val_loss did not improve from 1.63494\n",
      "Epoch 1114/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8576 - accuracy: 0.7602 - val_loss: 1.6589 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01114: val_loss did not improve from 1.63494\n",
      "Epoch 1115/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8574 - accuracy: 0.7602 - val_loss: 1.6657 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01115: val_loss did not improve from 1.63494\n",
      "Epoch 1116/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8528 - accuracy: 0.7544 - val_loss: 1.6754 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01116: val_loss did not improve from 1.63494\n",
      "Epoch 1117/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8532 - accuracy: 0.7251 - val_loss: 1.6857 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01117: val_loss did not improve from 1.63494\n",
      "Epoch 1118/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8565 - accuracy: 0.7076 - val_loss: 1.6893 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01118: val_loss did not improve from 1.63494\n",
      "Epoch 1119/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8540 - accuracy: 0.7193 - val_loss: 1.6897 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01119: val_loss did not improve from 1.63494\n",
      "Epoch 1120/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8515 - accuracy: 0.7135 - val_loss: 1.6787 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01120: val_loss did not improve from 1.63494\n",
      "Epoch 1121/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8495 - accuracy: 0.7427 - val_loss: 1.6638 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01121: val_loss did not improve from 1.63494\n",
      "Epoch 1122/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8519 - accuracy: 0.7310 - val_loss: 1.6603 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01122: val_loss did not improve from 1.63494\n",
      "Epoch 1123/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8505 - accuracy: 0.7485 - val_loss: 1.6580 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01123: val_loss did not improve from 1.63494\n",
      "Epoch 1124/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8510 - accuracy: 0.7368 - val_loss: 1.6669 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01124: val_loss did not improve from 1.63494\n",
      "Epoch 1125/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8512 - accuracy: 0.7427 - val_loss: 1.6724 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01125: val_loss did not improve from 1.63494\n",
      "Epoch 1126/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8501 - accuracy: 0.7427 - val_loss: 1.6745 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01126: val_loss did not improve from 1.63494\n",
      "Epoch 1127/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8483 - accuracy: 0.7427 - val_loss: 1.6746 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01127: val_loss did not improve from 1.63494\n",
      "Epoch 1128/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8474 - accuracy: 0.7427 - val_loss: 1.6760 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01128: val_loss did not improve from 1.63494\n",
      "Epoch 1129/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8475 - accuracy: 0.7310 - val_loss: 1.6721 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01129: val_loss did not improve from 1.63494\n",
      "Epoch 1130/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8460 - accuracy: 0.7485 - val_loss: 1.6741 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01130: val_loss did not improve from 1.63494\n",
      "Epoch 1131/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8449 - accuracy: 0.7193 - val_loss: 1.6773 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01131: val_loss did not improve from 1.63494\n",
      "Epoch 1132/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8434 - accuracy: 0.7368 - val_loss: 1.6756 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01132: val_loss did not improve from 1.63494\n",
      "Epoch 1133/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.8459 - accuracy: 0.7427 - val_loss: 1.6628 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01133: val_loss did not improve from 1.63494\n",
      "Epoch 1134/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8448 - accuracy: 0.7427 - val_loss: 1.6605 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01134: val_loss did not improve from 1.63494\n",
      "Epoch 1135/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8448 - accuracy: 0.7368 - val_loss: 1.6652 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01135: val_loss did not improve from 1.63494\n",
      "Epoch 1136/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8415 - accuracy: 0.7427 - val_loss: 1.6772 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01136: val_loss did not improve from 1.63494\n",
      "Epoch 1137/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8421 - accuracy: 0.7485 - val_loss: 1.6897 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01137: val_loss did not improve from 1.63494\n",
      "Epoch 1138/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8421 - accuracy: 0.7485 - val_loss: 1.6782 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01138: val_loss did not improve from 1.63494\n",
      "Epoch 1139/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.8387 - accuracy: 0.7602 - val_loss: 1.6663 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01139: val_loss did not improve from 1.63494\n",
      "Epoch 1140/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8423 - accuracy: 0.7485 - val_loss: 1.6561 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01140: val_loss did not improve from 1.63494\n",
      "Epoch 1141/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8421 - accuracy: 0.7310 - val_loss: 1.6493 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01141: val_loss did not improve from 1.63494\n",
      "Epoch 1142/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8394 - accuracy: 0.7485 - val_loss: 1.6498 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01142: val_loss did not improve from 1.63494\n",
      "Epoch 1143/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8404 - accuracy: 0.7427 - val_loss: 1.6656 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01143: val_loss did not improve from 1.63494\n",
      "Epoch 1144/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8384 - accuracy: 0.7485 - val_loss: 1.6633 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01144: val_loss did not improve from 1.63494\n",
      "Epoch 1145/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8369 - accuracy: 0.7368 - val_loss: 1.6723 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01145: val_loss did not improve from 1.63494\n",
      "Epoch 1146/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8380 - accuracy: 0.7368 - val_loss: 1.6675 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01146: val_loss did not improve from 1.63494\n",
      "Epoch 1147/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8369 - accuracy: 0.7661 - val_loss: 1.6712 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01147: val_loss did not improve from 1.63494\n",
      "Epoch 1148/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8344 - accuracy: 0.7602 - val_loss: 1.6744 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01148: val_loss did not improve from 1.63494\n",
      "Epoch 1149/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8340 - accuracy: 0.7602 - val_loss: 1.6677 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01149: val_loss did not improve from 1.63494\n",
      "Epoch 1150/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.8366 - accuracy: 0.7602 - val_loss: 1.6625 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01150: val_loss did not improve from 1.63494\n",
      "Epoch 1151/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8352 - accuracy: 0.7485 - val_loss: 1.6683 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01151: val_loss did not improve from 1.63494\n",
      "Epoch 1152/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8348 - accuracy: 0.7719 - val_loss: 1.6666 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01152: val_loss did not improve from 1.63494\n",
      "Epoch 1153/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8311 - accuracy: 0.7602 - val_loss: 1.6670 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01153: val_loss did not improve from 1.63494\n",
      "Epoch 1154/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8323 - accuracy: 0.7602 - val_loss: 1.6635 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01154: val_loss did not improve from 1.63494\n",
      "Epoch 1155/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8322 - accuracy: 0.7544 - val_loss: 1.6699 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01155: val_loss did not improve from 1.63494\n",
      "Epoch 1156/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8300 - accuracy: 0.7661 - val_loss: 1.6740 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01156: val_loss did not improve from 1.63494\n",
      "Epoch 1157/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8350 - accuracy: 0.7427 - val_loss: 1.6705 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01157: val_loss did not improve from 1.63494\n",
      "Epoch 1158/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8325 - accuracy: 0.7368 - val_loss: 1.6705 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01158: val_loss did not improve from 1.63494\n",
      "Epoch 1159/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8290 - accuracy: 0.7544 - val_loss: 1.6735 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01159: val_loss did not improve from 1.63494\n",
      "Epoch 1160/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8288 - accuracy: 0.7544 - val_loss: 1.6733 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01160: val_loss did not improve from 1.63494\n",
      "Epoch 1161/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8298 - accuracy: 0.7661 - val_loss: 1.6647 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01161: val_loss did not improve from 1.63494\n",
      "Epoch 1162/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8275 - accuracy: 0.7544 - val_loss: 1.6617 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01162: val_loss did not improve from 1.63494\n",
      "Epoch 1163/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.8297 - accuracy: 0.7661 - val_loss: 1.6578 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01163: val_loss did not improve from 1.63494\n",
      "Epoch 1164/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8263 - accuracy: 0.7778 - val_loss: 1.6697 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01164: val_loss did not improve from 1.63494\n",
      "Epoch 1165/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8253 - accuracy: 0.7544 - val_loss: 1.6749 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01165: val_loss did not improve from 1.63494\n",
      "Epoch 1166/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8276 - accuracy: 0.7310 - val_loss: 1.6751 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01166: val_loss did not improve from 1.63494\n",
      "Epoch 1167/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8287 - accuracy: 0.7310 - val_loss: 1.6616 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01167: val_loss did not improve from 1.63494\n",
      "Epoch 1168/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8250 - accuracy: 0.7427 - val_loss: 1.6641 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01168: val_loss did not improve from 1.63494\n",
      "Epoch 1169/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8241 - accuracy: 0.7602 - val_loss: 1.6573 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01169: val_loss did not improve from 1.63494\n",
      "Epoch 1170/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8238 - accuracy: 0.7485 - val_loss: 1.6512 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01170: val_loss did not improve from 1.63494\n",
      "Epoch 1171/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8258 - accuracy: 0.7602 - val_loss: 1.6488 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01171: val_loss did not improve from 1.63494\n",
      "Epoch 1172/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8221 - accuracy: 0.7661 - val_loss: 1.6652 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01172: val_loss did not improve from 1.63494\n",
      "Epoch 1173/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8207 - accuracy: 0.7719 - val_loss: 1.6616 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01173: val_loss did not improve from 1.63494\n",
      "Epoch 1174/2000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8217 - accuracy: 0.7661 - val_loss: 1.6586 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01174: val_loss did not improve from 1.63494\n",
      "Epoch 1175/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8197 - accuracy: 0.7778 - val_loss: 1.6534 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01175: val_loss did not improve from 1.63494\n",
      "Epoch 1176/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8207 - accuracy: 0.7602 - val_loss: 1.6562 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01176: val_loss did not improve from 1.63494\n",
      "Epoch 1177/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8192 - accuracy: 0.7661 - val_loss: 1.6671 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01177: val_loss did not improve from 1.63494\n",
      "Epoch 1178/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8187 - accuracy: 0.7544 - val_loss: 1.6673 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01178: val_loss did not improve from 1.63494\n",
      "Epoch 1179/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8171 - accuracy: 0.7544 - val_loss: 1.6733 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01179: val_loss did not improve from 1.63494\n",
      "Epoch 1180/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8173 - accuracy: 0.7602 - val_loss: 1.6774 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01180: val_loss did not improve from 1.63494\n",
      "Epoch 1181/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8167 - accuracy: 0.7602 - val_loss: 1.6774 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01181: val_loss did not improve from 1.63494\n",
      "Epoch 1182/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8162 - accuracy: 0.7368 - val_loss: 1.6716 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01182: val_loss did not improve from 1.63494\n",
      "Epoch 1183/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8181 - accuracy: 0.7485 - val_loss: 1.6582 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01183: val_loss did not improve from 1.63494\n",
      "Epoch 1184/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8169 - accuracy: 0.7544 - val_loss: 1.6623 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01184: val_loss did not improve from 1.63494\n",
      "Epoch 1185/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8148 - accuracy: 0.7544 - val_loss: 1.6628 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01185: val_loss did not improve from 1.63494\n",
      "Epoch 1186/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8145 - accuracy: 0.7602 - val_loss: 1.6616 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01186: val_loss did not improve from 1.63494\n",
      "Epoch 1187/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8129 - accuracy: 0.7778 - val_loss: 1.6745 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01187: val_loss did not improve from 1.63494\n",
      "Epoch 1188/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8134 - accuracy: 0.7485 - val_loss: 1.6767 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01188: val_loss did not improve from 1.63494\n",
      "Epoch 1189/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8146 - accuracy: 0.7485 - val_loss: 1.6888 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01189: val_loss did not improve from 1.63494\n",
      "Epoch 1190/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8154 - accuracy: 0.7310 - val_loss: 1.6722 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01190: val_loss did not improve from 1.63494\n",
      "Epoch 1191/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8143 - accuracy: 0.7485 - val_loss: 1.6588 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01191: val_loss did not improve from 1.63494\n",
      "Epoch 1192/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8107 - accuracy: 0.7719 - val_loss: 1.6660 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01192: val_loss did not improve from 1.63494\n",
      "Epoch 1193/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8113 - accuracy: 0.7719 - val_loss: 1.6681 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01193: val_loss did not improve from 1.63494\n",
      "Epoch 1194/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8112 - accuracy: 0.7719 - val_loss: 1.6723 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01194: val_loss did not improve from 1.63494\n",
      "Epoch 1195/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8100 - accuracy: 0.7602 - val_loss: 1.6657 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01195: val_loss did not improve from 1.63494\n",
      "Epoch 1196/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8106 - accuracy: 0.7778 - val_loss: 1.6639 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01196: val_loss did not improve from 1.63494\n",
      "Epoch 1197/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.8099 - accuracy: 0.7836 - val_loss: 1.6681 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01197: val_loss did not improve from 1.63494\n",
      "Epoch 1198/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8090 - accuracy: 0.7661 - val_loss: 1.6838 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01198: val_loss did not improve from 1.63494\n",
      "Epoch 1199/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8109 - accuracy: 0.7778 - val_loss: 1.6759 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01199: val_loss did not improve from 1.63494\n",
      "Epoch 1200/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8084 - accuracy: 0.7661 - val_loss: 1.6681 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01200: val_loss did not improve from 1.63494\n",
      "Epoch 1201/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8087 - accuracy: 0.7427 - val_loss: 1.6693 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01201: val_loss did not improve from 1.63494\n",
      "Epoch 1202/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8081 - accuracy: 0.7661 - val_loss: 1.6686 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01202: val_loss did not improve from 1.63494\n",
      "Epoch 1203/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8052 - accuracy: 0.7602 - val_loss: 1.6860 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01203: val_loss did not improve from 1.63494\n",
      "Epoch 1204/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8049 - accuracy: 0.7602 - val_loss: 1.6880 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01204: val_loss did not improve from 1.63494\n",
      "Epoch 1205/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8064 - accuracy: 0.7544 - val_loss: 1.6868 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01205: val_loss did not improve from 1.63494\n",
      "Epoch 1206/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8020 - accuracy: 0.7661 - val_loss: 1.6777 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01206: val_loss did not improve from 1.63494\n",
      "Epoch 1207/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8017 - accuracy: 0.7661 - val_loss: 1.6706 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01207: val_loss did not improve from 1.63494\n",
      "Epoch 1208/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8042 - accuracy: 0.7602 - val_loss: 1.6524 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01208: val_loss did not improve from 1.63494\n",
      "Epoch 1209/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.8023 - accuracy: 0.7778 - val_loss: 1.6556 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01209: val_loss did not improve from 1.63494\n",
      "Epoch 1210/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8027 - accuracy: 0.7719 - val_loss: 1.6652 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01210: val_loss did not improve from 1.63494\n",
      "Epoch 1211/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8008 - accuracy: 0.7719 - val_loss: 1.6644 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01211: val_loss did not improve from 1.63494\n",
      "Epoch 1212/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8005 - accuracy: 0.7661 - val_loss: 1.6610 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01212: val_loss did not improve from 1.63494\n",
      "Epoch 1213/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8027 - accuracy: 0.7544 - val_loss: 1.6690 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01213: val_loss did not improve from 1.63494\n",
      "Epoch 1214/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7997 - accuracy: 0.7602 - val_loss: 1.6617 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01214: val_loss did not improve from 1.63494\n",
      "Epoch 1215/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8004 - accuracy: 0.7719 - val_loss: 1.6742 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01215: val_loss did not improve from 1.63494\n",
      "Epoch 1216/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8006 - accuracy: 0.7661 - val_loss: 1.6844 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01216: val_loss did not improve from 1.63494\n",
      "Epoch 1217/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7997 - accuracy: 0.7836 - val_loss: 1.6833 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01217: val_loss did not improve from 1.63494\n",
      "Epoch 1218/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7965 - accuracy: 0.7778 - val_loss: 1.6663 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01218: val_loss did not improve from 1.63494\n",
      "Epoch 1219/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7978 - accuracy: 0.7719 - val_loss: 1.6622 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01219: val_loss did not improve from 1.63494\n",
      "Epoch 1220/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7970 - accuracy: 0.7719 - val_loss: 1.6632 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01220: val_loss did not improve from 1.63494\n",
      "Epoch 1221/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7960 - accuracy: 0.7719 - val_loss: 1.6650 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01221: val_loss did not improve from 1.63494\n",
      "Epoch 1222/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7969 - accuracy: 0.7602 - val_loss: 1.6690 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01222: val_loss did not improve from 1.63494\n",
      "Epoch 1223/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7944 - accuracy: 0.7661 - val_loss: 1.6714 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01223: val_loss did not improve from 1.63494\n",
      "Epoch 1224/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7942 - accuracy: 0.7719 - val_loss: 1.6759 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01224: val_loss did not improve from 1.63494\n",
      "Epoch 1225/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7954 - accuracy: 0.7836 - val_loss: 1.6747 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01225: val_loss did not improve from 1.63494\n",
      "Epoch 1226/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7924 - accuracy: 0.7778 - val_loss: 1.6757 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01226: val_loss did not improve from 1.63494\n",
      "Epoch 1227/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7930 - accuracy: 0.7895 - val_loss: 1.6813 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01227: val_loss did not improve from 1.63494\n",
      "Epoch 1228/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7922 - accuracy: 0.7953 - val_loss: 1.6792 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01228: val_loss did not improve from 1.63494\n",
      "Epoch 1229/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7925 - accuracy: 0.7895 - val_loss: 1.6774 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01229: val_loss did not improve from 1.63494\n",
      "Epoch 1230/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7931 - accuracy: 0.7778 - val_loss: 1.6734 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01230: val_loss did not improve from 1.63494\n",
      "Epoch 1231/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7915 - accuracy: 0.7719 - val_loss: 1.6836 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01231: val_loss did not improve from 1.63494\n",
      "Epoch 1232/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7912 - accuracy: 0.7719 - val_loss: 1.6857 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01232: val_loss did not improve from 1.63494\n",
      "Epoch 1233/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7924 - accuracy: 0.7602 - val_loss: 1.6795 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01233: val_loss did not improve from 1.63494\n",
      "Epoch 1234/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7907 - accuracy: 0.7602 - val_loss: 1.6750 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01234: val_loss did not improve from 1.63494\n",
      "Epoch 1235/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7915 - accuracy: 0.7719 - val_loss: 1.6685 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01235: val_loss did not improve from 1.63494\n",
      "Epoch 1236/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7895 - accuracy: 0.7719 - val_loss: 1.6666 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01236: val_loss did not improve from 1.63494\n",
      "Epoch 1237/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7875 - accuracy: 0.7719 - val_loss: 1.6678 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01237: val_loss did not improve from 1.63494\n",
      "Epoch 1238/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7873 - accuracy: 0.7836 - val_loss: 1.6637 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01238: val_loss did not improve from 1.63494\n",
      "Epoch 1239/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7884 - accuracy: 0.7778 - val_loss: 1.6628 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01239: val_loss did not improve from 1.63494\n",
      "Epoch 1240/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7863 - accuracy: 0.7778 - val_loss: 1.6602 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01240: val_loss did not improve from 1.63494\n",
      "Epoch 1241/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7865 - accuracy: 0.7719 - val_loss: 1.6710 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01241: val_loss did not improve from 1.63494\n",
      "Epoch 1242/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7845 - accuracy: 0.7778 - val_loss: 1.6640 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01242: val_loss did not improve from 1.63494\n",
      "Epoch 1243/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7855 - accuracy: 0.7661 - val_loss: 1.6581 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01243: val_loss did not improve from 1.63494\n",
      "Epoch 1244/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7846 - accuracy: 0.7836 - val_loss: 1.6696 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01244: val_loss did not improve from 1.63494\n",
      "Epoch 1245/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7842 - accuracy: 0.7836 - val_loss: 1.6890 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01245: val_loss did not improve from 1.63494\n",
      "Epoch 1246/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7848 - accuracy: 0.7719 - val_loss: 1.6869 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01246: val_loss did not improve from 1.63494\n",
      "Epoch 1247/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7822 - accuracy: 0.7719 - val_loss: 1.6798 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01247: val_loss did not improve from 1.63494\n",
      "Epoch 1248/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7836 - accuracy: 0.7778 - val_loss: 1.6747 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01248: val_loss did not improve from 1.63494\n",
      "Epoch 1249/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7800 - accuracy: 0.7602 - val_loss: 1.6845 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01249: val_loss did not improve from 1.63494\n",
      "Epoch 1250/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7811 - accuracy: 0.7661 - val_loss: 1.6771 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01250: val_loss did not improve from 1.63494\n",
      "Epoch 1251/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7825 - accuracy: 0.7661 - val_loss: 1.6676 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01251: val_loss did not improve from 1.63494\n",
      "Epoch 1252/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7814 - accuracy: 0.7778 - val_loss: 1.6677 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01252: val_loss did not improve from 1.63494\n",
      "Epoch 1253/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7806 - accuracy: 0.7778 - val_loss: 1.6727 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01253: val_loss did not improve from 1.63494\n",
      "Epoch 1254/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7783 - accuracy: 0.7778 - val_loss: 1.6806 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01254: val_loss did not improve from 1.63494\n",
      "Epoch 1255/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7791 - accuracy: 0.7661 - val_loss: 1.6839 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01255: val_loss did not improve from 1.63494\n",
      "Epoch 1256/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7779 - accuracy: 0.7661 - val_loss: 1.6826 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01256: val_loss did not improve from 1.63494\n",
      "Epoch 1257/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7771 - accuracy: 0.7778 - val_loss: 1.6767 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01257: val_loss did not improve from 1.63494\n",
      "Epoch 1258/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7782 - accuracy: 0.7719 - val_loss: 1.6831 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01258: val_loss did not improve from 1.63494\n",
      "Epoch 1259/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7809 - accuracy: 0.7778 - val_loss: 1.6777 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01259: val_loss did not improve from 1.63494\n",
      "Epoch 1260/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7776 - accuracy: 0.7953 - val_loss: 1.6798 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01260: val_loss did not improve from 1.63494\n",
      "Epoch 1261/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7763 - accuracy: 0.7895 - val_loss: 1.6759 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01261: val_loss did not improve from 1.63494\n",
      "Epoch 1262/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7756 - accuracy: 0.7836 - val_loss: 1.6663 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01262: val_loss did not improve from 1.63494\n",
      "Epoch 1263/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7754 - accuracy: 0.7778 - val_loss: 1.6748 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01263: val_loss did not improve from 1.63494\n",
      "Epoch 1264/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7763 - accuracy: 0.7895 - val_loss: 1.6766 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01264: val_loss did not improve from 1.63494\n",
      "Epoch 1265/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7733 - accuracy: 0.7778 - val_loss: 1.6743 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01265: val_loss did not improve from 1.63494\n",
      "Epoch 1266/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7734 - accuracy: 0.7895 - val_loss: 1.6753 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01266: val_loss did not improve from 1.63494\n",
      "Epoch 1267/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7732 - accuracy: 0.7953 - val_loss: 1.6729 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01267: val_loss did not improve from 1.63494\n",
      "Epoch 1268/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7737 - accuracy: 0.7719 - val_loss: 1.6812 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01268: val_loss did not improve from 1.63494\n",
      "Epoch 1269/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7714 - accuracy: 0.7719 - val_loss: 1.6758 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01269: val_loss did not improve from 1.63494\n",
      "Epoch 1270/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7750 - accuracy: 0.7778 - val_loss: 1.6758 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01270: val_loss did not improve from 1.63494\n",
      "Epoch 1271/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7702 - accuracy: 0.7895 - val_loss: 1.6877 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01271: val_loss did not improve from 1.63494\n",
      "Epoch 1272/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7713 - accuracy: 0.7895 - val_loss: 1.6867 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01272: val_loss did not improve from 1.63494\n",
      "Epoch 1273/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7693 - accuracy: 0.7836 - val_loss: 1.6869 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01273: val_loss did not improve from 1.63494\n",
      "Epoch 1274/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7687 - accuracy: 0.7836 - val_loss: 1.6817 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01274: val_loss did not improve from 1.63494\n",
      "Epoch 1275/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7689 - accuracy: 0.7953 - val_loss: 1.6630 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01275: val_loss did not improve from 1.63494\n",
      "Epoch 1276/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7694 - accuracy: 0.8012 - val_loss: 1.6578 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01276: val_loss did not improve from 1.63494\n",
      "Epoch 1277/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7686 - accuracy: 0.8012 - val_loss: 1.6686 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01277: val_loss did not improve from 1.63494\n",
      "Epoch 1278/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7664 - accuracy: 0.7836 - val_loss: 1.6734 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01278: val_loss did not improve from 1.63494\n",
      "Epoch 1279/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7673 - accuracy: 0.7836 - val_loss: 1.6906 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01279: val_loss did not improve from 1.63494\n",
      "Epoch 1280/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7652 - accuracy: 0.7895 - val_loss: 1.6876 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01280: val_loss did not improve from 1.63494\n",
      "Epoch 1281/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7667 - accuracy: 0.7836 - val_loss: 1.6770 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01281: val_loss did not improve from 1.63494\n",
      "Epoch 1282/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7647 - accuracy: 0.7953 - val_loss: 1.6799 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01282: val_loss did not improve from 1.63494\n",
      "Epoch 1283/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7650 - accuracy: 0.7895 - val_loss: 1.6780 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01283: val_loss did not improve from 1.63494\n",
      "Epoch 1284/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7627 - accuracy: 0.7953 - val_loss: 1.6811 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01284: val_loss did not improve from 1.63494\n",
      "Epoch 1285/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7650 - accuracy: 0.8012 - val_loss: 1.6839 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01285: val_loss did not improve from 1.63494\n",
      "Epoch 1286/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7652 - accuracy: 0.8070 - val_loss: 1.6998 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01286: val_loss did not improve from 1.63494\n",
      "Epoch 1287/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7639 - accuracy: 0.7953 - val_loss: 1.6910 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01287: val_loss did not improve from 1.63494\n",
      "Epoch 1288/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7630 - accuracy: 0.7953 - val_loss: 1.6735 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01288: val_loss did not improve from 1.63494\n",
      "Epoch 1289/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7621 - accuracy: 0.7895 - val_loss: 1.6651 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01289: val_loss did not improve from 1.63494\n",
      "Epoch 1290/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7624 - accuracy: 0.8012 - val_loss: 1.6737 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01290: val_loss did not improve from 1.63494\n",
      "Epoch 1291/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7613 - accuracy: 0.8012 - val_loss: 1.6782 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01291: val_loss did not improve from 1.63494\n",
      "Epoch 1292/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7616 - accuracy: 0.7953 - val_loss: 1.6888 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01292: val_loss did not improve from 1.63494\n",
      "Epoch 1293/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7591 - accuracy: 0.8012 - val_loss: 1.6777 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01293: val_loss did not improve from 1.63494\n",
      "Epoch 1294/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7604 - accuracy: 0.7836 - val_loss: 1.6809 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01294: val_loss did not improve from 1.63494\n",
      "Epoch 1295/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7590 - accuracy: 0.7895 - val_loss: 1.6842 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01295: val_loss did not improve from 1.63494\n",
      "Epoch 1296/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7577 - accuracy: 0.7953 - val_loss: 1.6809 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01296: val_loss did not improve from 1.63494\n",
      "Epoch 1297/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7589 - accuracy: 0.7953 - val_loss: 1.6821 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01297: val_loss did not improve from 1.63494\n",
      "Epoch 1298/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7568 - accuracy: 0.7953 - val_loss: 1.6874 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01298: val_loss did not improve from 1.63494\n",
      "Epoch 1299/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7584 - accuracy: 0.8012 - val_loss: 1.6961 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01299: val_loss did not improve from 1.63494\n",
      "Epoch 1300/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7556 - accuracy: 0.8070 - val_loss: 1.6834 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01300: val_loss did not improve from 1.63494\n",
      "Epoch 1301/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7602 - accuracy: 0.7836 - val_loss: 1.6694 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01301: val_loss did not improve from 1.63494\n",
      "Epoch 1302/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7576 - accuracy: 0.7836 - val_loss: 1.6728 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01302: val_loss did not improve from 1.63494\n",
      "Epoch 1303/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7550 - accuracy: 0.8012 - val_loss: 1.6648 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01303: val_loss did not improve from 1.63494\n",
      "Epoch 1304/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7538 - accuracy: 0.7895 - val_loss: 1.6704 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01304: val_loss did not improve from 1.63494\n",
      "Epoch 1305/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7552 - accuracy: 0.7953 - val_loss: 1.6830 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01305: val_loss did not improve from 1.63494\n",
      "Epoch 1306/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7533 - accuracy: 0.7953 - val_loss: 1.6822 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01306: val_loss did not improve from 1.63494\n",
      "Epoch 1307/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7536 - accuracy: 0.7953 - val_loss: 1.6820 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01307: val_loss did not improve from 1.63494\n",
      "Epoch 1308/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7526 - accuracy: 0.8012 - val_loss: 1.6715 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01308: val_loss did not improve from 1.63494\n",
      "Epoch 1309/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7524 - accuracy: 0.8012 - val_loss: 1.6821 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01309: val_loss did not improve from 1.63494\n",
      "Epoch 1310/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7505 - accuracy: 0.7895 - val_loss: 1.6925 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01310: val_loss did not improve from 1.63494\n",
      "Epoch 1311/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7536 - accuracy: 0.8012 - val_loss: 1.6836 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01311: val_loss did not improve from 1.63494\n",
      "Epoch 1312/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7518 - accuracy: 0.8070 - val_loss: 1.6838 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01312: val_loss did not improve from 1.63494\n",
      "Epoch 1313/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7508 - accuracy: 0.8012 - val_loss: 1.6819 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01313: val_loss did not improve from 1.63494\n",
      "Epoch 1314/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7478 - accuracy: 0.8187 - val_loss: 1.6798 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01314: val_loss did not improve from 1.63494\n",
      "Epoch 1315/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7474 - accuracy: 0.8070 - val_loss: 1.6789 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01315: val_loss did not improve from 1.63494\n",
      "Epoch 1316/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7489 - accuracy: 0.8070 - val_loss: 1.6864 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01316: val_loss did not improve from 1.63494\n",
      "Epoch 1317/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7484 - accuracy: 0.8129 - val_loss: 1.6873 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01317: val_loss did not improve from 1.63494\n",
      "Epoch 1318/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7471 - accuracy: 0.8129 - val_loss: 1.6943 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01318: val_loss did not improve from 1.63494\n",
      "Epoch 1319/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7479 - accuracy: 0.7953 - val_loss: 1.7150 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01319: val_loss did not improve from 1.63494\n",
      "Epoch 1320/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7457 - accuracy: 0.8129 - val_loss: 1.7038 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01320: val_loss did not improve from 1.63494\n",
      "Epoch 1321/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7470 - accuracy: 0.8070 - val_loss: 1.6975 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01321: val_loss did not improve from 1.63494\n",
      "Epoch 1322/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7463 - accuracy: 0.8070 - val_loss: 1.6914 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01322: val_loss did not improve from 1.63494\n",
      "Epoch 1323/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7476 - accuracy: 0.8129 - val_loss: 1.6816 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01323: val_loss did not improve from 1.63494\n",
      "Epoch 1324/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7437 - accuracy: 0.8129 - val_loss: 1.6856 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01324: val_loss did not improve from 1.63494\n",
      "Epoch 1325/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7431 - accuracy: 0.8129 - val_loss: 1.6889 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01325: val_loss did not improve from 1.63494\n",
      "Epoch 1326/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7442 - accuracy: 0.8070 - val_loss: 1.6847 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01326: val_loss did not improve from 1.63494\n",
      "Epoch 1327/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7415 - accuracy: 0.8187 - val_loss: 1.6744 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01327: val_loss did not improve from 1.63494\n",
      "Epoch 1328/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7441 - accuracy: 0.8070 - val_loss: 1.6795 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01328: val_loss did not improve from 1.63494\n",
      "Epoch 1329/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7470 - accuracy: 0.8070 - val_loss: 1.6951 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01329: val_loss did not improve from 1.63494\n",
      "Epoch 1330/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7418 - accuracy: 0.8129 - val_loss: 1.6904 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01330: val_loss did not improve from 1.63494\n",
      "Epoch 1331/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7403 - accuracy: 0.8187 - val_loss: 1.6827 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01331: val_loss did not improve from 1.63494\n",
      "Epoch 1332/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7409 - accuracy: 0.8070 - val_loss: 1.6756 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01332: val_loss did not improve from 1.63494\n",
      "Epoch 1333/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7414 - accuracy: 0.7953 - val_loss: 1.6740 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01333: val_loss did not improve from 1.63494\n",
      "Epoch 1334/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7386 - accuracy: 0.8012 - val_loss: 1.6844 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01334: val_loss did not improve from 1.63494\n",
      "Epoch 1335/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7419 - accuracy: 0.8129 - val_loss: 1.7026 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01335: val_loss did not improve from 1.63494\n",
      "Epoch 1336/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7388 - accuracy: 0.8012 - val_loss: 1.6965 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01336: val_loss did not improve from 1.63494\n",
      "Epoch 1337/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7399 - accuracy: 0.8070 - val_loss: 1.6901 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01337: val_loss did not improve from 1.63494\n",
      "Epoch 1338/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7392 - accuracy: 0.8070 - val_loss: 1.6800 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01338: val_loss did not improve from 1.63494\n",
      "Epoch 1339/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7383 - accuracy: 0.8070 - val_loss: 1.6821 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01339: val_loss did not improve from 1.63494\n",
      "Epoch 1340/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7360 - accuracy: 0.8070 - val_loss: 1.6714 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01340: val_loss did not improve from 1.63494\n",
      "Epoch 1341/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7369 - accuracy: 0.8012 - val_loss: 1.6733 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01341: val_loss did not improve from 1.63494\n",
      "Epoch 1342/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7395 - accuracy: 0.8012 - val_loss: 1.6696 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01342: val_loss did not improve from 1.63494\n",
      "Epoch 1343/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7359 - accuracy: 0.8012 - val_loss: 1.6847 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01343: val_loss did not improve from 1.63494\n",
      "Epoch 1344/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7328 - accuracy: 0.8012 - val_loss: 1.6981 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01344: val_loss did not improve from 1.63494\n",
      "Epoch 1345/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7330 - accuracy: 0.7953 - val_loss: 1.7031 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01345: val_loss did not improve from 1.63494\n",
      "Epoch 1346/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7350 - accuracy: 0.7953 - val_loss: 1.7103 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01346: val_loss did not improve from 1.63494\n",
      "Epoch 1347/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7340 - accuracy: 0.7895 - val_loss: 1.7057 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01347: val_loss did not improve from 1.63494\n",
      "Epoch 1348/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7346 - accuracy: 0.8070 - val_loss: 1.6944 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01348: val_loss did not improve from 1.63494\n",
      "Epoch 1349/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7325 - accuracy: 0.8070 - val_loss: 1.6883 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01349: val_loss did not improve from 1.63494\n",
      "Epoch 1350/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7323 - accuracy: 0.8070 - val_loss: 1.6785 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01350: val_loss did not improve from 1.63494\n",
      "Epoch 1351/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7333 - accuracy: 0.8012 - val_loss: 1.6879 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01351: val_loss did not improve from 1.63494\n",
      "Epoch 1352/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7324 - accuracy: 0.8129 - val_loss: 1.6849 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01352: val_loss did not improve from 1.63494\n",
      "Epoch 1353/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7306 - accuracy: 0.8070 - val_loss: 1.6940 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01353: val_loss did not improve from 1.63494\n",
      "Epoch 1354/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7328 - accuracy: 0.7836 - val_loss: 1.6983 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01354: val_loss did not improve from 1.63494\n",
      "Epoch 1355/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7300 - accuracy: 0.7953 - val_loss: 1.6757 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01355: val_loss did not improve from 1.63494\n",
      "Epoch 1356/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7282 - accuracy: 0.8187 - val_loss: 1.6719 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01356: val_loss did not improve from 1.63494\n",
      "Epoch 1357/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7287 - accuracy: 0.8070 - val_loss: 1.6760 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01357: val_loss did not improve from 1.63494\n",
      "Epoch 1358/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7287 - accuracy: 0.8070 - val_loss: 1.6858 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01358: val_loss did not improve from 1.63494\n",
      "Epoch 1359/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7291 - accuracy: 0.8012 - val_loss: 1.6888 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01359: val_loss did not improve from 1.63494\n",
      "Epoch 1360/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7287 - accuracy: 0.8070 - val_loss: 1.6896 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01360: val_loss did not improve from 1.63494\n",
      "Epoch 1361/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7277 - accuracy: 0.8070 - val_loss: 1.6786 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01361: val_loss did not improve from 1.63494\n",
      "Epoch 1362/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7293 - accuracy: 0.8012 - val_loss: 1.6785 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01362: val_loss did not improve from 1.63494\n",
      "Epoch 1363/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7257 - accuracy: 0.8070 - val_loss: 1.6930 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01363: val_loss did not improve from 1.63494\n",
      "Epoch 1364/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7270 - accuracy: 0.8187 - val_loss: 1.6997 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01364: val_loss did not improve from 1.63494\n",
      "Epoch 1365/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7274 - accuracy: 0.8129 - val_loss: 1.6947 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01365: val_loss did not improve from 1.63494\n",
      "Epoch 1366/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7251 - accuracy: 0.8070 - val_loss: 1.6818 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01366: val_loss did not improve from 1.63494\n",
      "Epoch 1367/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7231 - accuracy: 0.8012 - val_loss: 1.6761 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01367: val_loss did not improve from 1.63494\n",
      "Epoch 1368/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7220 - accuracy: 0.8070 - val_loss: 1.6736 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01368: val_loss did not improve from 1.63494\n",
      "Epoch 1369/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7220 - accuracy: 0.8070 - val_loss: 1.6715 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01369: val_loss did not improve from 1.63494\n",
      "Epoch 1370/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7207 - accuracy: 0.8129 - val_loss: 1.6794 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01370: val_loss did not improve from 1.63494\n",
      "Epoch 1371/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7220 - accuracy: 0.8070 - val_loss: 1.6846 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01371: val_loss did not improve from 1.63494\n",
      "Epoch 1372/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7223 - accuracy: 0.8070 - val_loss: 1.6913 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01372: val_loss did not improve from 1.63494\n",
      "Epoch 1373/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7203 - accuracy: 0.8187 - val_loss: 1.6876 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01373: val_loss did not improve from 1.63494\n",
      "Epoch 1374/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7196 - accuracy: 0.8129 - val_loss: 1.6745 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01374: val_loss did not improve from 1.63494\n",
      "Epoch 1375/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7231 - accuracy: 0.8129 - val_loss: 1.6708 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01375: val_loss did not improve from 1.63494\n",
      "Epoch 1376/2000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7197 - accuracy: 0.8304 - val_loss: 1.6852 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01376: val_loss did not improve from 1.63494\n",
      "Epoch 1377/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7191 - accuracy: 0.8129 - val_loss: 1.6940 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01377: val_loss did not improve from 1.63494\n",
      "Epoch 1378/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7184 - accuracy: 0.8129 - val_loss: 1.6873 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01378: val_loss did not improve from 1.63494\n",
      "Epoch 1379/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7211 - accuracy: 0.8304 - val_loss: 1.6829 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01379: val_loss did not improve from 1.63494\n",
      "Epoch 1380/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7192 - accuracy: 0.8129 - val_loss: 1.6825 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01380: val_loss did not improve from 1.63494\n",
      "Epoch 1381/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7188 - accuracy: 0.8070 - val_loss: 1.6867 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01381: val_loss did not improve from 1.63494\n",
      "Epoch 1382/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7164 - accuracy: 0.8129 - val_loss: 1.6794 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01382: val_loss did not improve from 1.63494\n",
      "Epoch 1383/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7153 - accuracy: 0.8187 - val_loss: 1.6781 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01383: val_loss did not improve from 1.63494\n",
      "Epoch 1384/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7147 - accuracy: 0.8187 - val_loss: 1.6770 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01384: val_loss did not improve from 1.63494\n",
      "Epoch 1385/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7149 - accuracy: 0.8129 - val_loss: 1.6951 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01385: val_loss did not improve from 1.63494\n",
      "Epoch 1386/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7146 - accuracy: 0.8246 - val_loss: 1.6949 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01386: val_loss did not improve from 1.63494\n",
      "Epoch 1387/2000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7144 - accuracy: 0.8129 - val_loss: 1.6824 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01387: val_loss did not improve from 1.63494\n",
      "Epoch 1388/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7155 - accuracy: 0.8246 - val_loss: 1.6834 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01388: val_loss did not improve from 1.63494\n",
      "Epoch 1389/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7142 - accuracy: 0.8129 - val_loss: 1.6743 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01389: val_loss did not improve from 1.63494\n",
      "Epoch 1390/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7136 - accuracy: 0.8129 - val_loss: 1.6816 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01390: val_loss did not improve from 1.63494\n",
      "Epoch 1391/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7133 - accuracy: 0.8070 - val_loss: 1.6793 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01391: val_loss did not improve from 1.63494\n",
      "Epoch 1392/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7126 - accuracy: 0.8129 - val_loss: 1.6731 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01392: val_loss did not improve from 1.63494\n",
      "Epoch 1393/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7148 - accuracy: 0.8129 - val_loss: 1.6668 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01393: val_loss did not improve from 1.63494\n",
      "Epoch 1394/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7109 - accuracy: 0.8187 - val_loss: 1.6881 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01394: val_loss did not improve from 1.63494\n",
      "Epoch 1395/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7106 - accuracy: 0.8246 - val_loss: 1.6842 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01395: val_loss did not improve from 1.63494\n",
      "Epoch 1396/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7114 - accuracy: 0.8304 - val_loss: 1.6606 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01396: val_loss did not improve from 1.63494\n",
      "Epoch 1397/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7111 - accuracy: 0.8246 - val_loss: 1.6771 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01397: val_loss did not improve from 1.63494\n",
      "Epoch 1398/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7102 - accuracy: 0.8070 - val_loss: 1.6756 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01398: val_loss did not improve from 1.63494\n",
      "Epoch 1399/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7087 - accuracy: 0.8129 - val_loss: 1.6794 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01399: val_loss did not improve from 1.63494\n",
      "Epoch 1400/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7085 - accuracy: 0.8246 - val_loss: 1.6804 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01400: val_loss did not improve from 1.63494\n",
      "Epoch 1401/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7075 - accuracy: 0.8304 - val_loss: 1.6890 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01401: val_loss did not improve from 1.63494\n",
      "Epoch 1402/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7078 - accuracy: 0.8363 - val_loss: 1.6900 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01402: val_loss did not improve from 1.63494\n",
      "Epoch 1403/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7069 - accuracy: 0.8246 - val_loss: 1.6752 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01403: val_loss did not improve from 1.63494\n",
      "Epoch 1404/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7083 - accuracy: 0.8187 - val_loss: 1.6678 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01404: val_loss did not improve from 1.63494\n",
      "Epoch 1405/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7054 - accuracy: 0.8070 - val_loss: 1.6705 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01405: val_loss did not improve from 1.63494\n",
      "Epoch 1406/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7071 - accuracy: 0.8246 - val_loss: 1.6813 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01406: val_loss did not improve from 1.63494\n",
      "Epoch 1407/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7050 - accuracy: 0.8363 - val_loss: 1.6874 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01407: val_loss did not improve from 1.63494\n",
      "Epoch 1408/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7030 - accuracy: 0.8246 - val_loss: 1.6846 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01408: val_loss did not improve from 1.63494\n",
      "Epoch 1409/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7043 - accuracy: 0.8187 - val_loss: 1.6719 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01409: val_loss did not improve from 1.63494\n",
      "Epoch 1410/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7033 - accuracy: 0.8304 - val_loss: 1.6767 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01410: val_loss did not improve from 1.63494\n",
      "Epoch 1411/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7023 - accuracy: 0.8304 - val_loss: 1.6814 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01411: val_loss did not improve from 1.63494\n",
      "Epoch 1412/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7025 - accuracy: 0.8187 - val_loss: 1.6838 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01412: val_loss did not improve from 1.63494\n",
      "Epoch 1413/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7028 - accuracy: 0.8246 - val_loss: 1.6847 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01413: val_loss did not improve from 1.63494\n",
      "Epoch 1414/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6999 - accuracy: 0.8246 - val_loss: 1.6874 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01414: val_loss did not improve from 1.63494\n",
      "Epoch 1415/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7010 - accuracy: 0.8187 - val_loss: 1.6901 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01415: val_loss did not improve from 1.63494\n",
      "Epoch 1416/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7045 - accuracy: 0.8070 - val_loss: 1.6702 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01416: val_loss did not improve from 1.63494\n",
      "Epoch 1417/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7031 - accuracy: 0.8187 - val_loss: 1.6795 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01417: val_loss did not improve from 1.63494\n",
      "Epoch 1418/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6990 - accuracy: 0.8304 - val_loss: 1.6871 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01418: val_loss did not improve from 1.63494\n",
      "Epoch 1419/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7024 - accuracy: 0.8304 - val_loss: 1.6953 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01419: val_loss did not improve from 1.63494\n",
      "Epoch 1420/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7010 - accuracy: 0.8246 - val_loss: 1.6866 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01420: val_loss did not improve from 1.63494\n",
      "Epoch 1421/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6983 - accuracy: 0.8129 - val_loss: 1.6776 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01421: val_loss did not improve from 1.63494\n",
      "Epoch 1422/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7007 - accuracy: 0.8187 - val_loss: 1.6727 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01422: val_loss did not improve from 1.63494\n",
      "Epoch 1423/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6993 - accuracy: 0.8187 - val_loss: 1.6774 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01423: val_loss did not improve from 1.63494\n",
      "Epoch 1424/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6989 - accuracy: 0.8070 - val_loss: 1.6907 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01424: val_loss did not improve from 1.63494\n",
      "Epoch 1425/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6983 - accuracy: 0.8187 - val_loss: 1.6939 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01425: val_loss did not improve from 1.63494\n",
      "Epoch 1426/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6977 - accuracy: 0.8246 - val_loss: 1.6865 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01426: val_loss did not improve from 1.63494\n",
      "Epoch 1427/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6972 - accuracy: 0.8246 - val_loss: 1.6820 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01427: val_loss did not improve from 1.63494\n",
      "Epoch 1428/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6948 - accuracy: 0.8129 - val_loss: 1.6700 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01428: val_loss did not improve from 1.63494\n",
      "Epoch 1429/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6971 - accuracy: 0.8129 - val_loss: 1.6695 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01429: val_loss did not improve from 1.63494\n",
      "Epoch 1430/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6959 - accuracy: 0.8129 - val_loss: 1.6675 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01430: val_loss did not improve from 1.63494\n",
      "Epoch 1431/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6928 - accuracy: 0.8246 - val_loss: 1.6821 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01431: val_loss did not improve from 1.63494\n",
      "Epoch 1432/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.8070 - val_loss: 1.6922 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01432: val_loss did not improve from 1.63494\n",
      "Epoch 1433/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6935 - accuracy: 0.8129 - val_loss: 1.6828 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01433: val_loss did not improve from 1.63494\n",
      "Epoch 1434/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6923 - accuracy: 0.8246 - val_loss: 1.6903 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01434: val_loss did not improve from 1.63494\n",
      "Epoch 1435/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6946 - accuracy: 0.8304 - val_loss: 1.6898 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01435: val_loss did not improve from 1.63494\n",
      "Epoch 1436/2000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6916 - accuracy: 0.8246 - val_loss: 1.6915 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01436: val_loss did not improve from 1.63494\n",
      "Epoch 1437/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6935 - accuracy: 0.8187 - val_loss: 1.7021 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01437: val_loss did not improve from 1.63494\n",
      "Epoch 1438/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6916 - accuracy: 0.8304 - val_loss: 1.6890 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01438: val_loss did not improve from 1.63494\n",
      "Epoch 1439/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6906 - accuracy: 0.8187 - val_loss: 1.6896 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01439: val_loss did not improve from 1.63494\n",
      "Epoch 1440/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6916 - accuracy: 0.8070 - val_loss: 1.6842 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01440: val_loss did not improve from 1.63494\n",
      "Epoch 1441/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6898 - accuracy: 0.8129 - val_loss: 1.6887 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01441: val_loss did not improve from 1.63494\n",
      "Epoch 1442/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6908 - accuracy: 0.8187 - val_loss: 1.7038 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01442: val_loss did not improve from 1.63494\n",
      "Epoch 1443/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6906 - accuracy: 0.8304 - val_loss: 1.7076 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01443: val_loss did not improve from 1.63494\n",
      "Epoch 1444/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6878 - accuracy: 0.8304 - val_loss: 1.6951 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01444: val_loss did not improve from 1.63494\n",
      "Epoch 1445/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6882 - accuracy: 0.8304 - val_loss: 1.6853 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01445: val_loss did not improve from 1.63494\n",
      "Epoch 1446/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6878 - accuracy: 0.8129 - val_loss: 1.6930 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01446: val_loss did not improve from 1.63494\n",
      "Epoch 1447/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6878 - accuracy: 0.8187 - val_loss: 1.6813 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01447: val_loss did not improve from 1.63494\n",
      "Epoch 1448/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6864 - accuracy: 0.8246 - val_loss: 1.6877 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01448: val_loss did not improve from 1.63494\n",
      "Epoch 1449/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6856 - accuracy: 0.8246 - val_loss: 1.6953 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01449: val_loss did not improve from 1.63494\n",
      "Epoch 1450/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6850 - accuracy: 0.8304 - val_loss: 1.6966 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01450: val_loss did not improve from 1.63494\n",
      "Epoch 1451/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6861 - accuracy: 0.8363 - val_loss: 1.6966 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01451: val_loss did not improve from 1.63494\n",
      "Epoch 1452/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6867 - accuracy: 0.8363 - val_loss: 1.6888 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01452: val_loss did not improve from 1.63494\n",
      "Epoch 1453/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6853 - accuracy: 0.8304 - val_loss: 1.6865 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01453: val_loss did not improve from 1.63494\n",
      "Epoch 1454/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6854 - accuracy: 0.8187 - val_loss: 1.7036 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01454: val_loss did not improve from 1.63494\n",
      "Epoch 1455/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6835 - accuracy: 0.8304 - val_loss: 1.7044 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01455: val_loss did not improve from 1.63494\n",
      "Epoch 1456/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6828 - accuracy: 0.8129 - val_loss: 1.6963 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01456: val_loss did not improve from 1.63494\n",
      "Epoch 1457/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6814 - accuracy: 0.8187 - val_loss: 1.6906 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01457: val_loss did not improve from 1.63494\n",
      "Epoch 1458/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6820 - accuracy: 0.8304 - val_loss: 1.6893 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01458: val_loss did not improve from 1.63494\n",
      "Epoch 1459/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6807 - accuracy: 0.8304 - val_loss: 1.6820 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01459: val_loss did not improve from 1.63494\n",
      "Epoch 1460/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6812 - accuracy: 0.8246 - val_loss: 1.6810 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01460: val_loss did not improve from 1.63494\n",
      "Epoch 1461/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6825 - accuracy: 0.8304 - val_loss: 1.6909 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01461: val_loss did not improve from 1.63494\n",
      "Epoch 1462/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6800 - accuracy: 0.8246 - val_loss: 1.7026 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01462: val_loss did not improve from 1.63494\n",
      "Epoch 1463/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6807 - accuracy: 0.8187 - val_loss: 1.7053 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01463: val_loss did not improve from 1.63494\n",
      "Epoch 1464/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6801 - accuracy: 0.8421 - val_loss: 1.7045 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01464: val_loss did not improve from 1.63494\n",
      "Epoch 1465/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6795 - accuracy: 0.8304 - val_loss: 1.7063 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01465: val_loss did not improve from 1.63494\n",
      "Epoch 1466/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6781 - accuracy: 0.8304 - val_loss: 1.6958 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01466: val_loss did not improve from 1.63494\n",
      "Epoch 1467/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6785 - accuracy: 0.8246 - val_loss: 1.6927 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01467: val_loss did not improve from 1.63494\n",
      "Epoch 1468/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6774 - accuracy: 0.8304 - val_loss: 1.6757 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01468: val_loss did not improve from 1.63494\n",
      "Epoch 1469/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6768 - accuracy: 0.8246 - val_loss: 1.6863 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01469: val_loss did not improve from 1.63494\n",
      "Epoch 1470/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6793 - accuracy: 0.8246 - val_loss: 1.6988 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01470: val_loss did not improve from 1.63494\n",
      "Epoch 1471/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6791 - accuracy: 0.8246 - val_loss: 1.6980 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01471: val_loss did not improve from 1.63494\n",
      "Epoch 1472/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6766 - accuracy: 0.8304 - val_loss: 1.7060 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01472: val_loss did not improve from 1.63494\n",
      "Epoch 1473/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6773 - accuracy: 0.8363 - val_loss: 1.7067 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01473: val_loss did not improve from 1.63494\n",
      "Epoch 1474/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6761 - accuracy: 0.8363 - val_loss: 1.6939 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01474: val_loss did not improve from 1.63494\n",
      "Epoch 1475/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6755 - accuracy: 0.8246 - val_loss: 1.6950 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01475: val_loss did not improve from 1.63494\n",
      "Epoch 1476/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6766 - accuracy: 0.8304 - val_loss: 1.6982 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01476: val_loss did not improve from 1.63494\n",
      "Epoch 1477/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6742 - accuracy: 0.8304 - val_loss: 1.6923 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01477: val_loss did not improve from 1.63494\n",
      "Epoch 1478/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6736 - accuracy: 0.8246 - val_loss: 1.6991 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01478: val_loss did not improve from 1.63494\n",
      "Epoch 1479/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6744 - accuracy: 0.8421 - val_loss: 1.6959 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01479: val_loss did not improve from 1.63494\n",
      "Epoch 1480/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6756 - accuracy: 0.8304 - val_loss: 1.6950 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01480: val_loss did not improve from 1.63494\n",
      "Epoch 1481/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6717 - accuracy: 0.8421 - val_loss: 1.6933 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01481: val_loss did not improve from 1.63494\n",
      "Epoch 1482/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6721 - accuracy: 0.8363 - val_loss: 1.6955 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01482: val_loss did not improve from 1.63494\n",
      "Epoch 1483/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6727 - accuracy: 0.8363 - val_loss: 1.7013 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01483: val_loss did not improve from 1.63494\n",
      "Epoch 1484/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6728 - accuracy: 0.8363 - val_loss: 1.7233 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01484: val_loss did not improve from 1.63494\n",
      "Epoch 1485/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6734 - accuracy: 0.8363 - val_loss: 1.7164 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01485: val_loss did not improve from 1.63494\n",
      "Epoch 1486/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6742 - accuracy: 0.8421 - val_loss: 1.7040 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01486: val_loss did not improve from 1.63494\n",
      "Epoch 1487/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6703 - accuracy: 0.8421 - val_loss: 1.6986 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01487: val_loss did not improve from 1.63494\n",
      "Epoch 1488/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6679 - accuracy: 0.8304 - val_loss: 1.6987 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01488: val_loss did not improve from 1.63494\n",
      "Epoch 1489/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6705 - accuracy: 0.8421 - val_loss: 1.7016 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01489: val_loss did not improve from 1.63494\n",
      "Epoch 1490/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6704 - accuracy: 0.8421 - val_loss: 1.7057 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01490: val_loss did not improve from 1.63494\n",
      "Epoch 1491/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6692 - accuracy: 0.8363 - val_loss: 1.6934 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01491: val_loss did not improve from 1.63494\n",
      "Epoch 1492/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6676 - accuracy: 0.8363 - val_loss: 1.7011 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01492: val_loss did not improve from 1.63494\n",
      "Epoch 1493/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6688 - accuracy: 0.8363 - val_loss: 1.7109 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01493: val_loss did not improve from 1.63494\n",
      "Epoch 1494/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6686 - accuracy: 0.8304 - val_loss: 1.7083 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01494: val_loss did not improve from 1.63494\n",
      "Epoch 1495/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6656 - accuracy: 0.8304 - val_loss: 1.7043 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01495: val_loss did not improve from 1.63494\n",
      "Epoch 1496/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6646 - accuracy: 0.8304 - val_loss: 1.7040 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01496: val_loss did not improve from 1.63494\n",
      "Epoch 1497/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6645 - accuracy: 0.8246 - val_loss: 1.7009 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01497: val_loss did not improve from 1.63494\n",
      "Epoch 1498/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6657 - accuracy: 0.8363 - val_loss: 1.7039 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01498: val_loss did not improve from 1.63494\n",
      "Epoch 1499/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6635 - accuracy: 0.8363 - val_loss: 1.6917 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01499: val_loss did not improve from 1.63494\n",
      "Epoch 1500/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6641 - accuracy: 0.8421 - val_loss: 1.6902 - val_accuracy: 0.4737\n",
      "\n",
      "Epoch 01500: val_loss did not improve from 1.63494\n",
      "Epoch 1501/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6655 - accuracy: 0.8363 - val_loss: 1.6836 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01501: val_loss did not improve from 1.63494\n",
      "Epoch 1502/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6668 - accuracy: 0.8304 - val_loss: 1.7114 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01502: val_loss did not improve from 1.63494\n",
      "Epoch 1503/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6647 - accuracy: 0.8363 - val_loss: 1.7279 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01503: val_loss did not improve from 1.63494\n",
      "Epoch 1504/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6639 - accuracy: 0.8363 - val_loss: 1.7205 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01504: val_loss did not improve from 1.63494\n",
      "Epoch 1505/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6625 - accuracy: 0.8363 - val_loss: 1.7135 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01505: val_loss did not improve from 1.63494\n",
      "Epoch 1506/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6625 - accuracy: 0.8363 - val_loss: 1.6925 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01506: val_loss did not improve from 1.63494\n",
      "Epoch 1507/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6593 - accuracy: 0.8480 - val_loss: 1.6901 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01507: val_loss did not improve from 1.63494\n",
      "Epoch 1508/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6608 - accuracy: 0.8421 - val_loss: 1.6921 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01508: val_loss did not improve from 1.63494\n",
      "Epoch 1509/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6623 - accuracy: 0.8187 - val_loss: 1.6950 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01509: val_loss did not improve from 1.63494\n",
      "Epoch 1510/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6603 - accuracy: 0.8363 - val_loss: 1.6841 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01510: val_loss did not improve from 1.63494\n",
      "Epoch 1511/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6598 - accuracy: 0.8421 - val_loss: 1.6956 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01511: val_loss did not improve from 1.63494\n",
      "Epoch 1512/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6600 - accuracy: 0.8421 - val_loss: 1.7014 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01512: val_loss did not improve from 1.63494\n",
      "Epoch 1513/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6609 - accuracy: 0.8421 - val_loss: 1.7078 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01513: val_loss did not improve from 1.63494\n",
      "Epoch 1514/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6556 - accuracy: 0.8421 - val_loss: 1.6893 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01514: val_loss did not improve from 1.63494\n",
      "Epoch 1515/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6566 - accuracy: 0.8421 - val_loss: 1.6761 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01515: val_loss did not improve from 1.63494\n",
      "Epoch 1516/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6610 - accuracy: 0.8246 - val_loss: 1.6758 - val_accuracy: 0.4737\n",
      "\n",
      "Epoch 01516: val_loss did not improve from 1.63494\n",
      "Epoch 1517/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6644 - accuracy: 0.8304 - val_loss: 1.6785 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01517: val_loss did not improve from 1.63494\n",
      "Epoch 1518/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6596 - accuracy: 0.8363 - val_loss: 1.7005 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01518: val_loss did not improve from 1.63494\n",
      "Epoch 1519/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6566 - accuracy: 0.8480 - val_loss: 1.7085 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01519: val_loss did not improve from 1.63494\n",
      "Epoch 1520/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6565 - accuracy: 0.8421 - val_loss: 1.7103 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01520: val_loss did not improve from 1.63494\n",
      "Epoch 1521/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6572 - accuracy: 0.8304 - val_loss: 1.7037 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01521: val_loss did not improve from 1.63494\n",
      "Epoch 1522/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6552 - accuracy: 0.8304 - val_loss: 1.7077 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01522: val_loss did not improve from 1.63494\n",
      "Epoch 1523/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6576 - accuracy: 0.8363 - val_loss: 1.7038 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01523: val_loss did not improve from 1.63494\n",
      "Epoch 1524/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6534 - accuracy: 0.8363 - val_loss: 1.6981 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01524: val_loss did not improve from 1.63494\n",
      "Epoch 1525/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6537 - accuracy: 0.8363 - val_loss: 1.6916 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01525: val_loss did not improve from 1.63494\n",
      "Epoch 1526/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6540 - accuracy: 0.8363 - val_loss: 1.6794 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01526: val_loss did not improve from 1.63494\n",
      "Epoch 1527/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6541 - accuracy: 0.8363 - val_loss: 1.6849 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01527: val_loss did not improve from 1.63494\n",
      "Epoch 1528/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6514 - accuracy: 0.8363 - val_loss: 1.7010 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01528: val_loss did not improve from 1.63494\n",
      "Epoch 1529/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6534 - accuracy: 0.8421 - val_loss: 1.7135 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01529: val_loss did not improve from 1.63494\n",
      "Epoch 1530/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6516 - accuracy: 0.8421 - val_loss: 1.7104 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01530: val_loss did not improve from 1.63494\n",
      "Epoch 1531/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6496 - accuracy: 0.8421 - val_loss: 1.6950 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01531: val_loss did not improve from 1.63494\n",
      "Epoch 1532/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6506 - accuracy: 0.8480 - val_loss: 1.6961 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01532: val_loss did not improve from 1.63494\n",
      "Epoch 1533/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6519 - accuracy: 0.8421 - val_loss: 1.7060 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01533: val_loss did not improve from 1.63494\n",
      "Epoch 1534/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6526 - accuracy: 0.8246 - val_loss: 1.7109 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01534: val_loss did not improve from 1.63494\n",
      "Epoch 1535/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6504 - accuracy: 0.8246 - val_loss: 1.7144 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01535: val_loss did not improve from 1.63494\n",
      "Epoch 1536/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6503 - accuracy: 0.8480 - val_loss: 1.7007 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01536: val_loss did not improve from 1.63494\n",
      "Epoch 1537/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6505 - accuracy: 0.8538 - val_loss: 1.6997 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01537: val_loss did not improve from 1.63494\n",
      "Epoch 1538/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6464 - accuracy: 0.8363 - val_loss: 1.7134 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01538: val_loss did not improve from 1.63494\n",
      "Epoch 1539/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6470 - accuracy: 0.8304 - val_loss: 1.7238 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01539: val_loss did not improve from 1.63494\n",
      "Epoch 1540/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6475 - accuracy: 0.8363 - val_loss: 1.7187 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01540: val_loss did not improve from 1.63494\n",
      "Epoch 1541/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6491 - accuracy: 0.8596 - val_loss: 1.7140 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01541: val_loss did not improve from 1.63494\n",
      "Epoch 1542/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6485 - accuracy: 0.8480 - val_loss: 1.6951 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01542: val_loss did not improve from 1.63494\n",
      "Epoch 1543/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6488 - accuracy: 0.8480 - val_loss: 1.7114 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01543: val_loss did not improve from 1.63494\n",
      "Epoch 1544/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6453 - accuracy: 0.8480 - val_loss: 1.7064 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01544: val_loss did not improve from 1.63494\n",
      "Epoch 1545/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6465 - accuracy: 0.8480 - val_loss: 1.7048 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01545: val_loss did not improve from 1.63494\n",
      "Epoch 1546/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6443 - accuracy: 0.8480 - val_loss: 1.7267 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01546: val_loss did not improve from 1.63494\n",
      "Epoch 1547/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6430 - accuracy: 0.8421 - val_loss: 1.7242 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01547: val_loss did not improve from 1.63494\n",
      "Epoch 1548/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6431 - accuracy: 0.8421 - val_loss: 1.7186 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01548: val_loss did not improve from 1.63494\n",
      "Epoch 1549/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6429 - accuracy: 0.8480 - val_loss: 1.7084 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01549: val_loss did not improve from 1.63494\n",
      "Epoch 1550/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6436 - accuracy: 0.8421 - val_loss: 1.7062 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01550: val_loss did not improve from 1.63494\n",
      "Epoch 1551/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6447 - accuracy: 0.8363 - val_loss: 1.7230 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01551: val_loss did not improve from 1.63494\n",
      "Epoch 1552/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6419 - accuracy: 0.8421 - val_loss: 1.7280 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01552: val_loss did not improve from 1.63494\n",
      "Epoch 1553/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6419 - accuracy: 0.8363 - val_loss: 1.7211 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01553: val_loss did not improve from 1.63494\n",
      "Epoch 1554/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6418 - accuracy: 0.8421 - val_loss: 1.7041 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01554: val_loss did not improve from 1.63494\n",
      "Epoch 1555/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6423 - accuracy: 0.8421 - val_loss: 1.7062 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01555: val_loss did not improve from 1.63494\n",
      "Epoch 1556/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6402 - accuracy: 0.8363 - val_loss: 1.7073 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01556: val_loss did not improve from 1.63494\n",
      "Epoch 1557/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6399 - accuracy: 0.8363 - val_loss: 1.7008 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01557: val_loss did not improve from 1.63494\n",
      "Epoch 1558/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6398 - accuracy: 0.8421 - val_loss: 1.7229 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01558: val_loss did not improve from 1.63494\n",
      "Epoch 1559/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6413 - accuracy: 0.8421 - val_loss: 1.7293 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01559: val_loss did not improve from 1.63494\n",
      "Epoch 1560/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6399 - accuracy: 0.8480 - val_loss: 1.7182 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01560: val_loss did not improve from 1.63494\n",
      "Epoch 1561/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6379 - accuracy: 0.8480 - val_loss: 1.7100 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01561: val_loss did not improve from 1.63494\n",
      "Epoch 1562/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6399 - accuracy: 0.8421 - val_loss: 1.6992 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01562: val_loss did not improve from 1.63494\n",
      "Epoch 1563/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6384 - accuracy: 0.8480 - val_loss: 1.6953 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01563: val_loss did not improve from 1.63494\n",
      "Epoch 1564/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6388 - accuracy: 0.8480 - val_loss: 1.7004 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01564: val_loss did not improve from 1.63494\n",
      "Epoch 1565/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6362 - accuracy: 0.8421 - val_loss: 1.7030 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01565: val_loss did not improve from 1.63494\n",
      "Epoch 1566/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6378 - accuracy: 0.8304 - val_loss: 1.7104 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01566: val_loss did not improve from 1.63494\n",
      "Epoch 1567/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6361 - accuracy: 0.8480 - val_loss: 1.7172 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01567: val_loss did not improve from 1.63494\n",
      "Epoch 1568/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6372 - accuracy: 0.8363 - val_loss: 1.7184 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01568: val_loss did not improve from 1.63494\n",
      "Epoch 1569/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6341 - accuracy: 0.8480 - val_loss: 1.7084 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01569: val_loss did not improve from 1.63494\n",
      "Epoch 1570/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6329 - accuracy: 0.8538 - val_loss: 1.7118 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01570: val_loss did not improve from 1.63494\n",
      "Epoch 1571/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6350 - accuracy: 0.8421 - val_loss: 1.7129 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01571: val_loss did not improve from 1.63494\n",
      "Epoch 1572/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6363 - accuracy: 0.8421 - val_loss: 1.7004 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01572: val_loss did not improve from 1.63494\n",
      "Epoch 1573/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6375 - accuracy: 0.8421 - val_loss: 1.6930 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01573: val_loss did not improve from 1.63494\n",
      "Epoch 1574/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6345 - accuracy: 0.8480 - val_loss: 1.7087 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01574: val_loss did not improve from 1.63494\n",
      "Epoch 1575/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6342 - accuracy: 0.8480 - val_loss: 1.7202 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01575: val_loss did not improve from 1.63494\n",
      "Epoch 1576/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6323 - accuracy: 0.8421 - val_loss: 1.7034 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01576: val_loss did not improve from 1.63494\n",
      "Epoch 1577/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6326 - accuracy: 0.8363 - val_loss: 1.7091 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01577: val_loss did not improve from 1.63494\n",
      "Epoch 1578/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6337 - accuracy: 0.8363 - val_loss: 1.7180 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01578: val_loss did not improve from 1.63494\n",
      "Epoch 1579/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6341 - accuracy: 0.8304 - val_loss: 1.7231 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01579: val_loss did not improve from 1.63494\n",
      "Epoch 1580/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6342 - accuracy: 0.8363 - val_loss: 1.7190 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01580: val_loss did not improve from 1.63494\n",
      "Epoch 1581/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6311 - accuracy: 0.8421 - val_loss: 1.6984 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01581: val_loss did not improve from 1.63494\n",
      "Epoch 1582/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6291 - accuracy: 0.8304 - val_loss: 1.6886 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01582: val_loss did not improve from 1.63494\n",
      "Epoch 1583/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6298 - accuracy: 0.8363 - val_loss: 1.6978 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01583: val_loss did not improve from 1.63494\n",
      "Epoch 1584/2000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6310 - accuracy: 0.8363 - val_loss: 1.7170 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01584: val_loss did not improve from 1.63494\n",
      "Epoch 1585/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6283 - accuracy: 0.8480 - val_loss: 1.7087 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01585: val_loss did not improve from 1.63494\n",
      "Epoch 1586/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6278 - accuracy: 0.8596 - val_loss: 1.7095 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01586: val_loss did not improve from 1.63494\n",
      "Epoch 1587/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6304 - accuracy: 0.8538 - val_loss: 1.7147 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01587: val_loss did not improve from 1.63494\n",
      "Epoch 1588/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6292 - accuracy: 0.8480 - val_loss: 1.7122 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01588: val_loss did not improve from 1.63494\n",
      "Epoch 1589/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6261 - accuracy: 0.8480 - val_loss: 1.7087 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01589: val_loss did not improve from 1.63494\n",
      "Epoch 1590/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6297 - accuracy: 0.8421 - val_loss: 1.6968 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01590: val_loss did not improve from 1.63494\n",
      "Epoch 1591/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6267 - accuracy: 0.8421 - val_loss: 1.6967 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01591: val_loss did not improve from 1.63494\n",
      "Epoch 1592/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6277 - accuracy: 0.8421 - val_loss: 1.7065 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01592: val_loss did not improve from 1.63494\n",
      "Epoch 1593/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6272 - accuracy: 0.8538 - val_loss: 1.7268 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01593: val_loss did not improve from 1.63494\n",
      "Epoch 1594/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6231 - accuracy: 0.8596 - val_loss: 1.7250 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01594: val_loss did not improve from 1.63494\n",
      "Epoch 1595/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6260 - accuracy: 0.8421 - val_loss: 1.7172 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01595: val_loss did not improve from 1.63494\n",
      "Epoch 1596/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6253 - accuracy: 0.8538 - val_loss: 1.7155 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01596: val_loss did not improve from 1.63494\n",
      "Epoch 1597/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6224 - accuracy: 0.8596 - val_loss: 1.7078 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01597: val_loss did not improve from 1.63494\n",
      "Epoch 1598/2000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6243 - accuracy: 0.8538 - val_loss: 1.7039 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01598: val_loss did not improve from 1.63494\n",
      "Epoch 1599/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6212 - accuracy: 0.8596 - val_loss: 1.7220 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01599: val_loss did not improve from 1.63494\n",
      "Epoch 1600/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6221 - accuracy: 0.8538 - val_loss: 1.7412 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01600: val_loss did not improve from 1.63494\n",
      "Epoch 1601/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6228 - accuracy: 0.8538 - val_loss: 1.7291 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01601: val_loss did not improve from 1.63494\n",
      "Epoch 1602/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6228 - accuracy: 0.8655 - val_loss: 1.7216 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01602: val_loss did not improve from 1.63494\n",
      "Epoch 1603/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6232 - accuracy: 0.8538 - val_loss: 1.7055 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01603: val_loss did not improve from 1.63494\n",
      "Epoch 1604/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6214 - accuracy: 0.8480 - val_loss: 1.7146 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01604: val_loss did not improve from 1.63494\n",
      "Epoch 1605/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6210 - accuracy: 0.8596 - val_loss: 1.7206 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01605: val_loss did not improve from 1.63494\n",
      "Epoch 1606/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6186 - accuracy: 0.8655 - val_loss: 1.7068 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01606: val_loss did not improve from 1.63494\n",
      "Epoch 1607/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6189 - accuracy: 0.8480 - val_loss: 1.7103 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01607: val_loss did not improve from 1.63494\n",
      "Epoch 1608/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6196 - accuracy: 0.8480 - val_loss: 1.7119 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01608: val_loss did not improve from 1.63494\n",
      "Epoch 1609/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6183 - accuracy: 0.8596 - val_loss: 1.7181 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01609: val_loss did not improve from 1.63494\n",
      "Epoch 1610/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6209 - accuracy: 0.8538 - val_loss: 1.7142 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01610: val_loss did not improve from 1.63494\n",
      "Epoch 1611/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6203 - accuracy: 0.8538 - val_loss: 1.7212 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01611: val_loss did not improve from 1.63494\n",
      "Epoch 1612/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6174 - accuracy: 0.8596 - val_loss: 1.7109 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01612: val_loss did not improve from 1.63494\n",
      "Epoch 1613/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6170 - accuracy: 0.8596 - val_loss: 1.7189 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01613: val_loss did not improve from 1.63494\n",
      "Epoch 1614/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6176 - accuracy: 0.8655 - val_loss: 1.7193 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01614: val_loss did not improve from 1.63494\n",
      "Epoch 1615/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6188 - accuracy: 0.8596 - val_loss: 1.7325 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01615: val_loss did not improve from 1.63494\n",
      "Epoch 1616/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6180 - accuracy: 0.8538 - val_loss: 1.7308 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01616: val_loss did not improve from 1.63494\n",
      "Epoch 1617/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6159 - accuracy: 0.8596 - val_loss: 1.7182 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01617: val_loss did not improve from 1.63494\n",
      "Epoch 1618/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6140 - accuracy: 0.8538 - val_loss: 1.7161 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01618: val_loss did not improve from 1.63494\n",
      "Epoch 1619/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6170 - accuracy: 0.8480 - val_loss: 1.7049 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01619: val_loss did not improve from 1.63494\n",
      "Epoch 1620/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6147 - accuracy: 0.8480 - val_loss: 1.7054 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01620: val_loss did not improve from 1.63494\n",
      "Epoch 1621/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6152 - accuracy: 0.8538 - val_loss: 1.7101 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01621: val_loss did not improve from 1.63494\n",
      "Epoch 1622/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6141 - accuracy: 0.8596 - val_loss: 1.7233 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01622: val_loss did not improve from 1.63494\n",
      "Epoch 1623/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6139 - accuracy: 0.8655 - val_loss: 1.7196 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01623: val_loss did not improve from 1.63494\n",
      "Epoch 1624/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6120 - accuracy: 0.8538 - val_loss: 1.7149 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01624: val_loss did not improve from 1.63494\n",
      "Epoch 1625/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6134 - accuracy: 0.8480 - val_loss: 1.7167 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01625: val_loss did not improve from 1.63494\n",
      "Epoch 1626/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6140 - accuracy: 0.8480 - val_loss: 1.7212 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01626: val_loss did not improve from 1.63494\n",
      "Epoch 1627/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6130 - accuracy: 0.8538 - val_loss: 1.7328 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01627: val_loss did not improve from 1.63494\n",
      "Epoch 1628/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6118 - accuracy: 0.8655 - val_loss: 1.7341 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01628: val_loss did not improve from 1.63494\n",
      "Epoch 1629/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6153 - accuracy: 0.8655 - val_loss: 1.7022 - val_accuracy: 0.4737\n",
      "\n",
      "Epoch 01629: val_loss did not improve from 1.63494\n",
      "Epoch 1630/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6136 - accuracy: 0.8480 - val_loss: 1.7107 - val_accuracy: 0.4737\n",
      "\n",
      "Epoch 01630: val_loss did not improve from 1.63494\n",
      "Epoch 1631/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6126 - accuracy: 0.8538 - val_loss: 1.6995 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01631: val_loss did not improve from 1.63494\n",
      "Epoch 1632/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6093 - accuracy: 0.8538 - val_loss: 1.7041 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01632: val_loss did not improve from 1.63494\n",
      "Epoch 1633/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6109 - accuracy: 0.8655 - val_loss: 1.7166 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01633: val_loss did not improve from 1.63494\n",
      "Epoch 1634/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6093 - accuracy: 0.8596 - val_loss: 1.7283 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01634: val_loss did not improve from 1.63494\n",
      "Epoch 1635/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6091 - accuracy: 0.8538 - val_loss: 1.7182 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01635: val_loss did not improve from 1.63494\n",
      "Epoch 1636/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6083 - accuracy: 0.8596 - val_loss: 1.7211 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01636: val_loss did not improve from 1.63494\n",
      "Epoch 1637/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6084 - accuracy: 0.8538 - val_loss: 1.7311 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01637: val_loss did not improve from 1.63494\n",
      "Epoch 1638/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6110 - accuracy: 0.8538 - val_loss: 1.7159 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01638: val_loss did not improve from 1.63494\n",
      "Epoch 1639/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6089 - accuracy: 0.8538 - val_loss: 1.7226 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01639: val_loss did not improve from 1.63494\n",
      "Epoch 1640/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6068 - accuracy: 0.8538 - val_loss: 1.7266 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01640: val_loss did not improve from 1.63494\n",
      "Epoch 1641/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6069 - accuracy: 0.8596 - val_loss: 1.7197 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01641: val_loss did not improve from 1.63494\n",
      "Epoch 1642/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6042 - accuracy: 0.8655 - val_loss: 1.7235 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01642: val_loss did not improve from 1.63494\n",
      "Epoch 1643/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6073 - accuracy: 0.8596 - val_loss: 1.7318 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01643: val_loss did not improve from 1.63494\n",
      "Epoch 1644/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6070 - accuracy: 0.8596 - val_loss: 1.7247 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01644: val_loss did not improve from 1.63494\n",
      "Epoch 1645/2000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6045 - accuracy: 0.8538 - val_loss: 1.7259 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01645: val_loss did not improve from 1.63494\n",
      "Epoch 1646/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6049 - accuracy: 0.8596 - val_loss: 1.7222 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01646: val_loss did not improve from 1.63494\n",
      "Epoch 1647/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6035 - accuracy: 0.8596 - val_loss: 1.7262 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01647: val_loss did not improve from 1.63494\n",
      "Epoch 1648/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6029 - accuracy: 0.8538 - val_loss: 1.7271 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01648: val_loss did not improve from 1.63494\n",
      "Epoch 1649/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6025 - accuracy: 0.8538 - val_loss: 1.7427 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01649: val_loss did not improve from 1.63494\n",
      "Epoch 1650/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6034 - accuracy: 0.8655 - val_loss: 1.7417 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01650: val_loss did not improve from 1.63494\n",
      "Epoch 1651/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6015 - accuracy: 0.8655 - val_loss: 1.7372 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01651: val_loss did not improve from 1.63494\n",
      "Epoch 1652/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6045 - accuracy: 0.8596 - val_loss: 1.7211 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01652: val_loss did not improve from 1.63494\n",
      "Epoch 1653/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6014 - accuracy: 0.8596 - val_loss: 1.7338 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01653: val_loss did not improve from 1.63494\n",
      "Epoch 1654/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6015 - accuracy: 0.8480 - val_loss: 1.7323 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01654: val_loss did not improve from 1.63494\n",
      "Epoch 1655/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6045 - accuracy: 0.8480 - val_loss: 1.7093 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01655: val_loss did not improve from 1.63494\n",
      "Epoch 1656/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6050 - accuracy: 0.8538 - val_loss: 1.7028 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01656: val_loss did not improve from 1.63494\n",
      "Epoch 1657/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6014 - accuracy: 0.8538 - val_loss: 1.7096 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01657: val_loss did not improve from 1.63494\n",
      "Epoch 1658/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6001 - accuracy: 0.8713 - val_loss: 1.7083 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01658: val_loss did not improve from 1.63494\n",
      "Epoch 1659/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6008 - accuracy: 0.8772 - val_loss: 1.7194 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01659: val_loss did not improve from 1.63494\n",
      "Epoch 1660/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5988 - accuracy: 0.8772 - val_loss: 1.7221 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01660: val_loss did not improve from 1.63494\n",
      "Epoch 1661/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5975 - accuracy: 0.8655 - val_loss: 1.7189 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01661: val_loss did not improve from 1.63494\n",
      "Epoch 1662/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5980 - accuracy: 0.8655 - val_loss: 1.7188 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01662: val_loss did not improve from 1.63494\n",
      "Epoch 1663/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5963 - accuracy: 0.8596 - val_loss: 1.7284 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01663: val_loss did not improve from 1.63494\n",
      "Epoch 1664/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5984 - accuracy: 0.8713 - val_loss: 1.7458 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01664: val_loss did not improve from 1.63494\n",
      "Epoch 1665/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5975 - accuracy: 0.8772 - val_loss: 1.7389 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01665: val_loss did not improve from 1.63494\n",
      "Epoch 1666/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5956 - accuracy: 0.8655 - val_loss: 1.7304 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01666: val_loss did not improve from 1.63494\n",
      "Epoch 1667/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5971 - accuracy: 0.8596 - val_loss: 1.7192 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01667: val_loss did not improve from 1.63494\n",
      "Epoch 1668/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5981 - accuracy: 0.8596 - val_loss: 1.7274 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01668: val_loss did not improve from 1.63494\n",
      "Epoch 1669/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5969 - accuracy: 0.8596 - val_loss: 1.7319 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01669: val_loss did not improve from 1.63494\n",
      "Epoch 1670/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5974 - accuracy: 0.8713 - val_loss: 1.7433 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01670: val_loss did not improve from 1.63494\n",
      "Epoch 1671/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5963 - accuracy: 0.8713 - val_loss: 1.7312 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01671: val_loss did not improve from 1.63494\n",
      "Epoch 1672/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5954 - accuracy: 0.8713 - val_loss: 1.7232 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01672: val_loss did not improve from 1.63494\n",
      "Epoch 1673/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5949 - accuracy: 0.8713 - val_loss: 1.7313 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01673: val_loss did not improve from 1.63494\n",
      "Epoch 1674/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5936 - accuracy: 0.8655 - val_loss: 1.7243 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01674: val_loss did not improve from 1.63494\n",
      "Epoch 1675/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5939 - accuracy: 0.8713 - val_loss: 1.7243 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01675: val_loss did not improve from 1.63494\n",
      "Epoch 1676/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5932 - accuracy: 0.8655 - val_loss: 1.7338 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01676: val_loss did not improve from 1.63494\n",
      "Epoch 1677/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5928 - accuracy: 0.8596 - val_loss: 1.7315 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01677: val_loss did not improve from 1.63494\n",
      "Epoch 1678/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5960 - accuracy: 0.8363 - val_loss: 1.7185 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01678: val_loss did not improve from 1.63494\n",
      "Epoch 1679/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5968 - accuracy: 0.8480 - val_loss: 1.7260 - val_accuracy: 0.4737\n",
      "\n",
      "Epoch 01679: val_loss did not improve from 1.63494\n",
      "Epoch 1680/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5924 - accuracy: 0.8596 - val_loss: 1.7238 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01680: val_loss did not improve from 1.63494\n",
      "Epoch 1681/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5929 - accuracy: 0.8713 - val_loss: 1.7379 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01681: val_loss did not improve from 1.63494\n",
      "Epoch 1682/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5918 - accuracy: 0.8713 - val_loss: 1.7328 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01682: val_loss did not improve from 1.63494\n",
      "Epoch 1683/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5914 - accuracy: 0.8772 - val_loss: 1.7318 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01683: val_loss did not improve from 1.63494\n",
      "Epoch 1684/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5882 - accuracy: 0.8655 - val_loss: 1.7147 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01684: val_loss did not improve from 1.63494\n",
      "Epoch 1685/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5899 - accuracy: 0.8538 - val_loss: 1.7144 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01685: val_loss did not improve from 1.63494\n",
      "Epoch 1686/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5918 - accuracy: 0.8655 - val_loss: 1.7158 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01686: val_loss did not improve from 1.63494\n",
      "Epoch 1687/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5892 - accuracy: 0.8596 - val_loss: 1.7342 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01687: val_loss did not improve from 1.63494\n",
      "Epoch 1688/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5878 - accuracy: 0.8655 - val_loss: 1.7417 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01688: val_loss did not improve from 1.63494\n",
      "Epoch 1689/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5898 - accuracy: 0.8655 - val_loss: 1.7198 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01689: val_loss did not improve from 1.63494\n",
      "Epoch 1690/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5894 - accuracy: 0.8655 - val_loss: 1.7153 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01690: val_loss did not improve from 1.63494\n",
      "Epoch 1691/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5877 - accuracy: 0.8655 - val_loss: 1.7267 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01691: val_loss did not improve from 1.63494\n",
      "Epoch 1692/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5902 - accuracy: 0.8538 - val_loss: 1.7305 - val_accuracy: 0.4737\n",
      "\n",
      "Epoch 01692: val_loss did not improve from 1.63494\n",
      "Epoch 1693/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5885 - accuracy: 0.8596 - val_loss: 1.7464 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01693: val_loss did not improve from 1.63494\n",
      "Epoch 1694/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5864 - accuracy: 0.8596 - val_loss: 1.7330 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01694: val_loss did not improve from 1.63494\n",
      "Epoch 1695/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5861 - accuracy: 0.8596 - val_loss: 1.7326 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01695: val_loss did not improve from 1.63494\n",
      "Epoch 1696/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5866 - accuracy: 0.8538 - val_loss: 1.7384 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01696: val_loss did not improve from 1.63494\n",
      "Epoch 1697/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5861 - accuracy: 0.8596 - val_loss: 1.7250 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01697: val_loss did not improve from 1.63494\n",
      "Epoch 1698/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5848 - accuracy: 0.8655 - val_loss: 1.7285 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01698: val_loss did not improve from 1.63494\n",
      "Epoch 1699/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5846 - accuracy: 0.8655 - val_loss: 1.7341 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01699: val_loss did not improve from 1.63494\n",
      "Epoch 1700/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5828 - accuracy: 0.8655 - val_loss: 1.7250 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01700: val_loss did not improve from 1.63494\n",
      "Epoch 1701/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5836 - accuracy: 0.8655 - val_loss: 1.7266 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01701: val_loss did not improve from 1.63494\n",
      "Epoch 1702/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5827 - accuracy: 0.8772 - val_loss: 1.7309 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01702: val_loss did not improve from 1.63494\n",
      "Epoch 1703/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5828 - accuracy: 0.8655 - val_loss: 1.7419 - val_accuracy: 0.4737\n",
      "\n",
      "Epoch 01703: val_loss did not improve from 1.63494\n",
      "Epoch 1704/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5827 - accuracy: 0.8713 - val_loss: 1.7339 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01704: val_loss did not improve from 1.63494\n",
      "Epoch 1705/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5822 - accuracy: 0.8596 - val_loss: 1.7452 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01705: val_loss did not improve from 1.63494\n",
      "Epoch 1706/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5810 - accuracy: 0.8713 - val_loss: 1.7342 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01706: val_loss did not improve from 1.63494\n",
      "Epoch 1707/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5806 - accuracy: 0.8713 - val_loss: 1.7297 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01707: val_loss did not improve from 1.63494\n",
      "Epoch 1708/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5806 - accuracy: 0.8713 - val_loss: 1.7226 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01708: val_loss did not improve from 1.63494\n",
      "Epoch 1709/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5818 - accuracy: 0.8713 - val_loss: 1.7294 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01709: val_loss did not improve from 1.63494\n",
      "Epoch 1710/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5813 - accuracy: 0.8655 - val_loss: 1.7333 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01710: val_loss did not improve from 1.63494\n",
      "Epoch 1711/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5813 - accuracy: 0.8655 - val_loss: 1.7403 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01711: val_loss did not improve from 1.63494\n",
      "Epoch 1712/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5777 - accuracy: 0.8596 - val_loss: 1.7199 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01712: val_loss did not improve from 1.63494\n",
      "Epoch 1713/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5821 - accuracy: 0.8655 - val_loss: 1.7261 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01713: val_loss did not improve from 1.63494\n",
      "Epoch 1714/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5793 - accuracy: 0.8596 - val_loss: 1.7364 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01714: val_loss did not improve from 1.63494\n",
      "Epoch 1715/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5774 - accuracy: 0.8772 - val_loss: 1.7312 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01715: val_loss did not improve from 1.63494\n",
      "Epoch 1716/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5769 - accuracy: 0.8655 - val_loss: 1.7371 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01716: val_loss did not improve from 1.63494\n",
      "Epoch 1717/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5759 - accuracy: 0.8596 - val_loss: 1.7395 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01717: val_loss did not improve from 1.63494\n",
      "Epoch 1718/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5770 - accuracy: 0.8596 - val_loss: 1.7268 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01718: val_loss did not improve from 1.63494\n",
      "Epoch 1719/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5766 - accuracy: 0.8596 - val_loss: 1.7262 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01719: val_loss did not improve from 1.63494\n",
      "Epoch 1720/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5769 - accuracy: 0.8655 - val_loss: 1.7473 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01720: val_loss did not improve from 1.63494\n",
      "Epoch 1721/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5785 - accuracy: 0.8713 - val_loss: 1.7491 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01721: val_loss did not improve from 1.63494\n",
      "Epoch 1722/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5745 - accuracy: 0.8772 - val_loss: 1.7352 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01722: val_loss did not improve from 1.63494\n",
      "Epoch 1723/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5766 - accuracy: 0.8713 - val_loss: 1.7228 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01723: val_loss did not improve from 1.63494\n",
      "Epoch 1724/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5755 - accuracy: 0.8655 - val_loss: 1.7471 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01724: val_loss did not improve from 1.63494\n",
      "Epoch 1725/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5749 - accuracy: 0.8713 - val_loss: 1.7479 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01725: val_loss did not improve from 1.63494\n",
      "Epoch 1726/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5731 - accuracy: 0.8713 - val_loss: 1.7459 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01726: val_loss did not improve from 1.63494\n",
      "Epoch 1727/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5724 - accuracy: 0.8713 - val_loss: 1.7435 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01727: val_loss did not improve from 1.63494\n",
      "Epoch 1728/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5722 - accuracy: 0.8772 - val_loss: 1.7350 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01728: val_loss did not improve from 1.63494\n",
      "Epoch 1729/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5728 - accuracy: 0.8772 - val_loss: 1.7302 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01729: val_loss did not improve from 1.63494\n",
      "Epoch 1730/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5713 - accuracy: 0.8830 - val_loss: 1.7380 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01730: val_loss did not improve from 1.63494\n",
      "Epoch 1731/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5723 - accuracy: 0.8713 - val_loss: 1.7469 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01731: val_loss did not improve from 1.63494\n",
      "Epoch 1732/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5716 - accuracy: 0.8596 - val_loss: 1.7512 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01732: val_loss did not improve from 1.63494\n",
      "Epoch 1733/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5706 - accuracy: 0.8713 - val_loss: 1.7487 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01733: val_loss did not improve from 1.63494\n",
      "Epoch 1734/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5699 - accuracy: 0.8655 - val_loss: 1.7442 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01734: val_loss did not improve from 1.63494\n",
      "Epoch 1735/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5705 - accuracy: 0.8713 - val_loss: 1.7406 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01735: val_loss did not improve from 1.63494\n",
      "Epoch 1736/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5706 - accuracy: 0.8830 - val_loss: 1.7443 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01736: val_loss did not improve from 1.63494\n",
      "Epoch 1737/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5693 - accuracy: 0.8713 - val_loss: 1.7471 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01737: val_loss did not improve from 1.63494\n",
      "Epoch 1738/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5687 - accuracy: 0.8713 - val_loss: 1.7441 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01738: val_loss did not improve from 1.63494\n",
      "Epoch 1739/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5704 - accuracy: 0.8655 - val_loss: 1.7266 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01739: val_loss did not improve from 1.63494\n",
      "Epoch 1740/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5683 - accuracy: 0.8713 - val_loss: 1.7213 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01740: val_loss did not improve from 1.63494\n",
      "Epoch 1741/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5672 - accuracy: 0.8772 - val_loss: 1.7401 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01741: val_loss did not improve from 1.63494\n",
      "Epoch 1742/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5685 - accuracy: 0.8713 - val_loss: 1.7570 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01742: val_loss did not improve from 1.63494\n",
      "Epoch 1743/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5687 - accuracy: 0.8713 - val_loss: 1.7533 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01743: val_loss did not improve from 1.63494\n",
      "Epoch 1744/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5676 - accuracy: 0.8713 - val_loss: 1.7655 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01744: val_loss did not improve from 1.63494\n",
      "Epoch 1745/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5702 - accuracy: 0.8655 - val_loss: 1.7453 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01745: val_loss did not improve from 1.63494\n",
      "Epoch 1746/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5677 - accuracy: 0.8596 - val_loss: 1.7310 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01746: val_loss did not improve from 1.63494\n",
      "Epoch 1747/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5662 - accuracy: 0.8713 - val_loss: 1.7305 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01747: val_loss did not improve from 1.63494\n",
      "Epoch 1748/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5673 - accuracy: 0.8830 - val_loss: 1.7525 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01748: val_loss did not improve from 1.63494\n",
      "Epoch 1749/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5668 - accuracy: 0.8596 - val_loss: 1.7367 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01749: val_loss did not improve from 1.63494\n",
      "Epoch 1750/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5649 - accuracy: 0.8596 - val_loss: 1.7361 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01750: val_loss did not improve from 1.63494\n",
      "Epoch 1751/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5662 - accuracy: 0.8772 - val_loss: 1.7358 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01751: val_loss did not improve from 1.63494\n",
      "Epoch 1752/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5632 - accuracy: 0.8772 - val_loss: 1.7479 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01752: val_loss did not improve from 1.63494\n",
      "Epoch 1753/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5631 - accuracy: 0.8772 - val_loss: 1.7331 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01753: val_loss did not improve from 1.63494\n",
      "Epoch 1754/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5631 - accuracy: 0.8772 - val_loss: 1.7427 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01754: val_loss did not improve from 1.63494\n",
      "Epoch 1755/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5628 - accuracy: 0.8713 - val_loss: 1.7389 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01755: val_loss did not improve from 1.63494\n",
      "Epoch 1756/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5636 - accuracy: 0.8655 - val_loss: 1.7499 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01756: val_loss did not improve from 1.63494\n",
      "Epoch 1757/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5626 - accuracy: 0.8655 - val_loss: 1.7370 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01757: val_loss did not improve from 1.63494\n",
      "Epoch 1758/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5605 - accuracy: 0.8772 - val_loss: 1.7310 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01758: val_loss did not improve from 1.63494\n",
      "Epoch 1759/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5596 - accuracy: 0.8772 - val_loss: 1.7409 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01759: val_loss did not improve from 1.63494\n",
      "Epoch 1760/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5600 - accuracy: 0.8772 - val_loss: 1.7523 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01760: val_loss did not improve from 1.63494\n",
      "Epoch 1761/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5623 - accuracy: 0.8830 - val_loss: 1.7566 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01761: val_loss did not improve from 1.63494\n",
      "Epoch 1762/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5610 - accuracy: 0.8772 - val_loss: 1.7447 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01762: val_loss did not improve from 1.63494\n",
      "Epoch 1763/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5603 - accuracy: 0.8713 - val_loss: 1.7392 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01763: val_loss did not improve from 1.63494\n",
      "Epoch 1764/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5595 - accuracy: 0.8655 - val_loss: 1.7363 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01764: val_loss did not improve from 1.63494\n",
      "Epoch 1765/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5612 - accuracy: 0.8713 - val_loss: 1.7234 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01765: val_loss did not improve from 1.63494\n",
      "Epoch 1766/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5582 - accuracy: 0.8713 - val_loss: 1.7378 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01766: val_loss did not improve from 1.63494\n",
      "Epoch 1767/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5586 - accuracy: 0.8713 - val_loss: 1.7524 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01767: val_loss did not improve from 1.63494\n",
      "Epoch 1768/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5596 - accuracy: 0.8772 - val_loss: 1.7600 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01768: val_loss did not improve from 1.63494\n",
      "Epoch 1769/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5579 - accuracy: 0.8772 - val_loss: 1.7405 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01769: val_loss did not improve from 1.63494\n",
      "Epoch 1770/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5583 - accuracy: 0.8772 - val_loss: 1.7265 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01770: val_loss did not improve from 1.63494\n",
      "Epoch 1771/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5566 - accuracy: 0.8713 - val_loss: 1.7337 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01771: val_loss did not improve from 1.63494\n",
      "Epoch 1772/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5579 - accuracy: 0.8655 - val_loss: 1.7359 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01772: val_loss did not improve from 1.63494\n",
      "Epoch 1773/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5563 - accuracy: 0.8713 - val_loss: 1.7393 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01773: val_loss did not improve from 1.63494\n",
      "Epoch 1774/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5547 - accuracy: 0.8772 - val_loss: 1.7461 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01774: val_loss did not improve from 1.63494\n",
      "Epoch 1775/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5548 - accuracy: 0.8713 - val_loss: 1.7495 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01775: val_loss did not improve from 1.63494\n",
      "Epoch 1776/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5559 - accuracy: 0.8772 - val_loss: 1.7476 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01776: val_loss did not improve from 1.63494\n",
      "Epoch 1777/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5569 - accuracy: 0.8713 - val_loss: 1.7585 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01777: val_loss did not improve from 1.63494\n",
      "Epoch 1778/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5577 - accuracy: 0.8713 - val_loss: 1.7575 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01778: val_loss did not improve from 1.63494\n",
      "Epoch 1779/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5543 - accuracy: 0.8772 - val_loss: 1.7490 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01779: val_loss did not improve from 1.63494\n",
      "Epoch 1780/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5527 - accuracy: 0.8713 - val_loss: 1.7347 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01780: val_loss did not improve from 1.63494\n",
      "Epoch 1781/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5535 - accuracy: 0.8713 - val_loss: 1.7449 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01781: val_loss did not improve from 1.63494\n",
      "Epoch 1782/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5535 - accuracy: 0.8713 - val_loss: 1.7511 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01782: val_loss did not improve from 1.63494\n",
      "Epoch 1783/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5527 - accuracy: 0.8655 - val_loss: 1.7494 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01783: val_loss did not improve from 1.63494\n",
      "Epoch 1784/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5511 - accuracy: 0.8772 - val_loss: 1.7523 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01784: val_loss did not improve from 1.63494\n",
      "Epoch 1785/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5515 - accuracy: 0.8772 - val_loss: 1.7389 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01785: val_loss did not improve from 1.63494\n",
      "Epoch 1786/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5522 - accuracy: 0.8772 - val_loss: 1.7529 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01786: val_loss did not improve from 1.63494\n",
      "Epoch 1787/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5519 - accuracy: 0.8713 - val_loss: 1.7705 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01787: val_loss did not improve from 1.63494\n",
      "Epoch 1788/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5508 - accuracy: 0.8772 - val_loss: 1.7607 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01788: val_loss did not improve from 1.63494\n",
      "Epoch 1789/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5516 - accuracy: 0.8830 - val_loss: 1.7472 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01789: val_loss did not improve from 1.63494\n",
      "Epoch 1790/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5504 - accuracy: 0.8772 - val_loss: 1.7449 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01790: val_loss did not improve from 1.63494\n",
      "Epoch 1791/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5512 - accuracy: 0.8772 - val_loss: 1.7579 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01791: val_loss did not improve from 1.63494\n",
      "Epoch 1792/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5494 - accuracy: 0.8713 - val_loss: 1.7585 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01792: val_loss did not improve from 1.63494\n",
      "Epoch 1793/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5495 - accuracy: 0.8713 - val_loss: 1.7504 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01793: val_loss did not improve from 1.63494\n",
      "Epoch 1794/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5475 - accuracy: 0.8713 - val_loss: 1.7531 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01794: val_loss did not improve from 1.63494\n",
      "Epoch 1795/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5469 - accuracy: 0.8713 - val_loss: 1.7595 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01795: val_loss did not improve from 1.63494\n",
      "Epoch 1796/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5494 - accuracy: 0.8772 - val_loss: 1.7770 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01796: val_loss did not improve from 1.63494\n",
      "Epoch 1797/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5489 - accuracy: 0.8772 - val_loss: 1.7795 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01797: val_loss did not improve from 1.63494\n",
      "Epoch 1798/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5482 - accuracy: 0.8772 - val_loss: 1.7482 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01798: val_loss did not improve from 1.63494\n",
      "Epoch 1799/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5474 - accuracy: 0.8772 - val_loss: 1.7383 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01799: val_loss did not improve from 1.63494\n",
      "Epoch 1800/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5445 - accuracy: 0.8772 - val_loss: 1.7471 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01800: val_loss did not improve from 1.63494\n",
      "Epoch 1801/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5462 - accuracy: 0.8655 - val_loss: 1.7638 - val_accuracy: 0.4737\n",
      "\n",
      "Epoch 01801: val_loss did not improve from 1.63494\n",
      "Epoch 1802/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5469 - accuracy: 0.8655 - val_loss: 1.7633 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01802: val_loss did not improve from 1.63494\n",
      "Epoch 1803/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5458 - accuracy: 0.8713 - val_loss: 1.7535 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01803: val_loss did not improve from 1.63494\n",
      "Epoch 1804/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5447 - accuracy: 0.8772 - val_loss: 1.7566 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01804: val_loss did not improve from 1.63494\n",
      "Epoch 1805/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5446 - accuracy: 0.8713 - val_loss: 1.7519 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01805: val_loss did not improve from 1.63494\n",
      "Epoch 1806/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5449 - accuracy: 0.8655 - val_loss: 1.7356 - val_accuracy: 0.4737\n",
      "\n",
      "Epoch 01806: val_loss did not improve from 1.63494\n",
      "Epoch 1807/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5437 - accuracy: 0.8655 - val_loss: 1.7254 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01807: val_loss did not improve from 1.63494\n",
      "Epoch 1808/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5455 - accuracy: 0.8772 - val_loss: 1.7388 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01808: val_loss did not improve from 1.63494\n",
      "Epoch 1809/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5442 - accuracy: 0.8772 - val_loss: 1.7628 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01809: val_loss did not improve from 1.63494\n",
      "Epoch 1810/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5431 - accuracy: 0.8772 - val_loss: 1.7642 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01810: val_loss did not improve from 1.63494\n",
      "Epoch 1811/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5443 - accuracy: 0.8772 - val_loss: 1.7767 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01811: val_loss did not improve from 1.63494\n",
      "Epoch 1812/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5425 - accuracy: 0.8713 - val_loss: 1.7632 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01812: val_loss did not improve from 1.63494\n",
      "Epoch 1813/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5419 - accuracy: 0.8772 - val_loss: 1.7636 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01813: val_loss did not improve from 1.63494\n",
      "Epoch 1814/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5406 - accuracy: 0.8713 - val_loss: 1.7568 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01814: val_loss did not improve from 1.63494\n",
      "Epoch 1815/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5407 - accuracy: 0.8772 - val_loss: 1.7584 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01815: val_loss did not improve from 1.63494\n",
      "Epoch 1816/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5407 - accuracy: 0.8772 - val_loss: 1.7554 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01816: val_loss did not improve from 1.63494\n",
      "Epoch 1817/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5389 - accuracy: 0.8772 - val_loss: 1.7396 - val_accuracy: 0.4737\n",
      "\n",
      "Epoch 01817: val_loss did not improve from 1.63494\n",
      "Epoch 1818/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5403 - accuracy: 0.8830 - val_loss: 1.7350 - val_accuracy: 0.4737\n",
      "\n",
      "Epoch 01818: val_loss did not improve from 1.63494\n",
      "Epoch 1819/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5426 - accuracy: 0.8772 - val_loss: 1.7324 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01819: val_loss did not improve from 1.63494\n",
      "Epoch 1820/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5410 - accuracy: 0.8713 - val_loss: 1.7614 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01820: val_loss did not improve from 1.63494\n",
      "Epoch 1821/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5396 - accuracy: 0.8772 - val_loss: 1.7758 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01821: val_loss did not improve from 1.63494\n",
      "Epoch 1822/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5406 - accuracy: 0.8772 - val_loss: 1.7756 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01822: val_loss did not improve from 1.63494\n",
      "Epoch 1823/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5416 - accuracy: 0.8772 - val_loss: 1.7587 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01823: val_loss did not improve from 1.63494\n",
      "Epoch 1824/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5393 - accuracy: 0.8772 - val_loss: 1.7669 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01824: val_loss did not improve from 1.63494\n",
      "Epoch 1825/2000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5378 - accuracy: 0.8772 - val_loss: 1.7817 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01825: val_loss did not improve from 1.63494\n",
      "Epoch 1826/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5394 - accuracy: 0.8830 - val_loss: 1.7822 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01826: val_loss did not improve from 1.63494\n",
      "Epoch 1827/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5362 - accuracy: 0.8772 - val_loss: 1.7568 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01827: val_loss did not improve from 1.63494\n",
      "Epoch 1828/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5361 - accuracy: 0.8655 - val_loss: 1.7526 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01828: val_loss did not improve from 1.63494\n",
      "Epoch 1829/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5371 - accuracy: 0.8655 - val_loss: 1.7424 - val_accuracy: 0.4737\n",
      "\n",
      "Epoch 01829: val_loss did not improve from 1.63494\n",
      "Epoch 1830/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5363 - accuracy: 0.8713 - val_loss: 1.7427 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01830: val_loss did not improve from 1.63494\n",
      "Epoch 1831/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5369 - accuracy: 0.8772 - val_loss: 1.7605 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01831: val_loss did not improve from 1.63494\n",
      "Epoch 1832/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5361 - accuracy: 0.8772 - val_loss: 1.7823 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01832: val_loss did not improve from 1.63494\n",
      "Epoch 1833/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5369 - accuracy: 0.8713 - val_loss: 1.7921 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01833: val_loss did not improve from 1.63494\n",
      "Epoch 1834/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5361 - accuracy: 0.8713 - val_loss: 1.7678 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01834: val_loss did not improve from 1.63494\n",
      "Epoch 1835/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5354 - accuracy: 0.8713 - val_loss: 1.7567 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01835: val_loss did not improve from 1.63494\n",
      "Epoch 1836/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5319 - accuracy: 0.8772 - val_loss: 1.7648 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01836: val_loss did not improve from 1.63494\n",
      "Epoch 1837/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5319 - accuracy: 0.8713 - val_loss: 1.7676 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01837: val_loss did not improve from 1.63494\n",
      "Epoch 1838/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5349 - accuracy: 0.8655 - val_loss: 1.7589 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01838: val_loss did not improve from 1.63494\n",
      "Epoch 1839/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5321 - accuracy: 0.8772 - val_loss: 1.7501 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01839: val_loss did not improve from 1.63494\n",
      "Epoch 1840/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5336 - accuracy: 0.8713 - val_loss: 1.7522 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01840: val_loss did not improve from 1.63494\n",
      "Epoch 1841/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5303 - accuracy: 0.8830 - val_loss: 1.7485 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01841: val_loss did not improve from 1.63494\n",
      "Epoch 1842/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5332 - accuracy: 0.8772 - val_loss: 1.7452 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01842: val_loss did not improve from 1.63494\n",
      "Epoch 1843/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5312 - accuracy: 0.8947 - val_loss: 1.7549 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01843: val_loss did not improve from 1.63494\n",
      "Epoch 1844/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5346 - accuracy: 0.8830 - val_loss: 1.7633 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01844: val_loss did not improve from 1.63494\n",
      "Epoch 1845/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5315 - accuracy: 0.8772 - val_loss: 1.7512 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01845: val_loss did not improve from 1.63494\n",
      "Epoch 1846/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5312 - accuracy: 0.8655 - val_loss: 1.7601 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01846: val_loss did not improve from 1.63494\n",
      "Epoch 1847/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5321 - accuracy: 0.8713 - val_loss: 1.7557 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01847: val_loss did not improve from 1.63494\n",
      "Epoch 1848/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5299 - accuracy: 0.8713 - val_loss: 1.7589 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01848: val_loss did not improve from 1.63494\n",
      "Epoch 1849/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5288 - accuracy: 0.8772 - val_loss: 1.7542 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01849: val_loss did not improve from 1.63494\n",
      "Epoch 1850/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5286 - accuracy: 0.8772 - val_loss: 1.7597 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01850: val_loss did not improve from 1.63494\n",
      "Epoch 1851/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5269 - accuracy: 0.8772 - val_loss: 1.7747 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01851: val_loss did not improve from 1.63494\n",
      "Epoch 1852/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5268 - accuracy: 0.8830 - val_loss: 1.7887 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01852: val_loss did not improve from 1.63494\n",
      "Epoch 1853/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5278 - accuracy: 0.8830 - val_loss: 1.7842 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01853: val_loss did not improve from 1.63494\n",
      "Epoch 1854/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5280 - accuracy: 0.8772 - val_loss: 1.7721 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01854: val_loss did not improve from 1.63494\n",
      "Epoch 1855/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5285 - accuracy: 0.8772 - val_loss: 1.7709 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01855: val_loss did not improve from 1.63494\n",
      "Epoch 1856/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5273 - accuracy: 0.8772 - val_loss: 1.7806 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01856: val_loss did not improve from 1.63494\n",
      "Epoch 1857/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5263 - accuracy: 0.8713 - val_loss: 1.7753 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01857: val_loss did not improve from 1.63494\n",
      "Epoch 1858/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5267 - accuracy: 0.8830 - val_loss: 1.7669 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01858: val_loss did not improve from 1.63494\n",
      "Epoch 1859/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5264 - accuracy: 0.8713 - val_loss: 1.7658 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01859: val_loss did not improve from 1.63494\n",
      "Epoch 1860/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5244 - accuracy: 0.8713 - val_loss: 1.7786 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01860: val_loss did not improve from 1.63494\n",
      "Epoch 1861/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5250 - accuracy: 0.8830 - val_loss: 1.7855 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01861: val_loss did not improve from 1.63494\n",
      "Epoch 1862/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5272 - accuracy: 0.8772 - val_loss: 1.7805 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01862: val_loss did not improve from 1.63494\n",
      "Epoch 1863/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5251 - accuracy: 0.8772 - val_loss: 1.7719 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01863: val_loss did not improve from 1.63494\n",
      "Epoch 1864/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5246 - accuracy: 0.8772 - val_loss: 1.7834 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01864: val_loss did not improve from 1.63494\n",
      "Epoch 1865/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5250 - accuracy: 0.8772 - val_loss: 1.7816 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01865: val_loss did not improve from 1.63494\n",
      "Epoch 1866/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5211 - accuracy: 0.8772 - val_loss: 1.7767 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01866: val_loss did not improve from 1.63494\n",
      "Epoch 1867/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5223 - accuracy: 0.8772 - val_loss: 1.7689 - val_accuracy: 0.4737\n",
      "\n",
      "Epoch 01867: val_loss did not improve from 1.63494\n",
      "Epoch 1868/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5230 - accuracy: 0.8772 - val_loss: 1.7802 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01868: val_loss did not improve from 1.63494\n",
      "Epoch 1869/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5219 - accuracy: 0.8772 - val_loss: 1.7878 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01869: val_loss did not improve from 1.63494\n",
      "Epoch 1870/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5221 - accuracy: 0.8830 - val_loss: 1.7692 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01870: val_loss did not improve from 1.63494\n",
      "Epoch 1871/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5217 - accuracy: 0.8889 - val_loss: 1.7637 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01871: val_loss did not improve from 1.63494\n",
      "Epoch 1872/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5258 - accuracy: 0.8830 - val_loss: 1.7555 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01872: val_loss did not improve from 1.63494\n",
      "Epoch 1873/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5250 - accuracy: 0.8889 - val_loss: 1.7547 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01873: val_loss did not improve from 1.63494\n",
      "Epoch 1874/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5194 - accuracy: 0.8830 - val_loss: 1.7701 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01874: val_loss did not improve from 1.63494\n",
      "Epoch 1875/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5195 - accuracy: 0.8713 - val_loss: 1.7753 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01875: val_loss did not improve from 1.63494\n",
      "Epoch 1876/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5200 - accuracy: 0.8713 - val_loss: 1.7730 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01876: val_loss did not improve from 1.63494\n",
      "Epoch 1877/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5186 - accuracy: 0.8713 - val_loss: 1.7578 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01877: val_loss did not improve from 1.63494\n",
      "Epoch 1878/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5199 - accuracy: 0.8889 - val_loss: 1.7570 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01878: val_loss did not improve from 1.63494\n",
      "Epoch 1879/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5211 - accuracy: 0.8830 - val_loss: 1.7532 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01879: val_loss did not improve from 1.63494\n",
      "Epoch 1880/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5203 - accuracy: 0.8713 - val_loss: 1.7775 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01880: val_loss did not improve from 1.63494\n",
      "Epoch 1881/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5178 - accuracy: 0.8772 - val_loss: 1.7842 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01881: val_loss did not improve from 1.63494\n",
      "Epoch 1882/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5183 - accuracy: 0.8772 - val_loss: 1.7822 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01882: val_loss did not improve from 1.63494\n",
      "Epoch 1883/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5163 - accuracy: 0.8772 - val_loss: 1.7664 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01883: val_loss did not improve from 1.63494\n",
      "Epoch 1884/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5169 - accuracy: 0.8889 - val_loss: 1.7720 - val_accuracy: 0.4737\n",
      "\n",
      "Epoch 01884: val_loss did not improve from 1.63494\n",
      "Epoch 1885/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5169 - accuracy: 0.8772 - val_loss: 1.7690 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01885: val_loss did not improve from 1.63494\n",
      "Epoch 1886/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5173 - accuracy: 0.8655 - val_loss: 1.7602 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01886: val_loss did not improve from 1.63494\n",
      "Epoch 1887/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5163 - accuracy: 0.8772 - val_loss: 1.7667 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01887: val_loss did not improve from 1.63494\n",
      "Epoch 1888/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5153 - accuracy: 0.8772 - val_loss: 1.7879 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01888: val_loss did not improve from 1.63494\n",
      "Epoch 1889/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5157 - accuracy: 0.8772 - val_loss: 1.7783 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01889: val_loss did not improve from 1.63494\n",
      "Epoch 1890/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5156 - accuracy: 0.8772 - val_loss: 1.7820 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01890: val_loss did not improve from 1.63494\n",
      "Epoch 1891/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5135 - accuracy: 0.8830 - val_loss: 1.7735 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01891: val_loss did not improve from 1.63494\n",
      "Epoch 1892/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5132 - accuracy: 0.8830 - val_loss: 1.7897 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01892: val_loss did not improve from 1.63494\n",
      "Epoch 1893/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5129 - accuracy: 0.8772 - val_loss: 1.8027 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01893: val_loss did not improve from 1.63494\n",
      "Epoch 1894/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5123 - accuracy: 0.8830 - val_loss: 1.7865 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01894: val_loss did not improve from 1.63494\n",
      "Epoch 1895/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5137 - accuracy: 0.8713 - val_loss: 1.7704 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01895: val_loss did not improve from 1.63494\n",
      "Epoch 1896/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5130 - accuracy: 0.8830 - val_loss: 1.7644 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01896: val_loss did not improve from 1.63494\n",
      "Epoch 1897/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5122 - accuracy: 0.8830 - val_loss: 1.7714 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01897: val_loss did not improve from 1.63494\n",
      "Epoch 1898/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5136 - accuracy: 0.8772 - val_loss: 1.7740 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01898: val_loss did not improve from 1.63494\n",
      "Epoch 1899/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5131 - accuracy: 0.8830 - val_loss: 1.7894 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01899: val_loss did not improve from 1.63494\n",
      "Epoch 1900/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5136 - accuracy: 0.8713 - val_loss: 1.7997 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01900: val_loss did not improve from 1.63494\n",
      "Epoch 1901/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5107 - accuracy: 0.8713 - val_loss: 1.7776 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01901: val_loss did not improve from 1.63494\n",
      "Epoch 1902/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5105 - accuracy: 0.8830 - val_loss: 1.7665 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01902: val_loss did not improve from 1.63494\n",
      "Epoch 1903/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5093 - accuracy: 0.8889 - val_loss: 1.7559 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01903: val_loss did not improve from 1.63494\n",
      "Epoch 1904/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5104 - accuracy: 0.8889 - val_loss: 1.7688 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01904: val_loss did not improve from 1.63494\n",
      "Epoch 1905/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5099 - accuracy: 0.8830 - val_loss: 1.7715 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01905: val_loss did not improve from 1.63494\n",
      "Epoch 1906/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5092 - accuracy: 0.8830 - val_loss: 1.7888 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01906: val_loss did not improve from 1.63494\n",
      "Epoch 1907/2000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5095 - accuracy: 0.8830 - val_loss: 1.7841 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01907: val_loss did not improve from 1.63494\n",
      "Epoch 1908/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5119 - accuracy: 0.8830 - val_loss: 1.7813 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01908: val_loss did not improve from 1.63494\n",
      "Epoch 1909/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5119 - accuracy: 0.8889 - val_loss: 1.7736 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01909: val_loss did not improve from 1.63494\n",
      "Epoch 1910/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5115 - accuracy: 0.8830 - val_loss: 1.7620 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01910: val_loss did not improve from 1.63494\n",
      "Epoch 1911/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5090 - accuracy: 0.8889 - val_loss: 1.7558 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01911: val_loss did not improve from 1.63494\n",
      "Epoch 1912/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5089 - accuracy: 0.8830 - val_loss: 1.7688 - val_accuracy: 0.4737\n",
      "\n",
      "Epoch 01912: val_loss did not improve from 1.63494\n",
      "Epoch 1913/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5077 - accuracy: 0.8947 - val_loss: 1.7759 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01913: val_loss did not improve from 1.63494\n",
      "Epoch 1914/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5058 - accuracy: 0.8889 - val_loss: 1.7721 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01914: val_loss did not improve from 1.63494\n",
      "Epoch 1915/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5036 - accuracy: 0.8889 - val_loss: 1.7656 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01915: val_loss did not improve from 1.63494\n",
      "Epoch 1916/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5042 - accuracy: 0.8947 - val_loss: 1.7617 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01916: val_loss did not improve from 1.63494\n",
      "Epoch 1917/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5055 - accuracy: 0.8772 - val_loss: 1.7711 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01917: val_loss did not improve from 1.63494\n",
      "Epoch 1918/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5038 - accuracy: 0.8830 - val_loss: 1.7823 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01918: val_loss did not improve from 1.63494\n",
      "Epoch 1919/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5050 - accuracy: 0.8830 - val_loss: 1.7807 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01919: val_loss did not improve from 1.63494\n",
      "Epoch 1920/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5043 - accuracy: 0.8830 - val_loss: 1.7798 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01920: val_loss did not improve from 1.63494\n",
      "Epoch 1921/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5038 - accuracy: 0.8830 - val_loss: 1.7584 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01921: val_loss did not improve from 1.63494\n",
      "Epoch 1922/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5040 - accuracy: 0.8889 - val_loss: 1.7618 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01922: val_loss did not improve from 1.63494\n",
      "Epoch 1923/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5023 - accuracy: 0.8889 - val_loss: 1.7790 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01923: val_loss did not improve from 1.63494\n",
      "Epoch 1924/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5031 - accuracy: 0.8889 - val_loss: 1.7998 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01924: val_loss did not improve from 1.63494\n",
      "Epoch 1925/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5021 - accuracy: 0.8889 - val_loss: 1.7909 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01925: val_loss did not improve from 1.63494\n",
      "Epoch 1926/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5021 - accuracy: 0.8772 - val_loss: 1.7756 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01926: val_loss did not improve from 1.63494\n",
      "Epoch 1927/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5039 - accuracy: 0.9006 - val_loss: 1.7640 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01927: val_loss did not improve from 1.63494\n",
      "Epoch 1928/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5032 - accuracy: 0.9006 - val_loss: 1.7577 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01928: val_loss did not improve from 1.63494\n",
      "Epoch 1929/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5004 - accuracy: 0.8889 - val_loss: 1.7577 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01929: val_loss did not improve from 1.63494\n",
      "Epoch 1930/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5014 - accuracy: 0.8772 - val_loss: 1.7587 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01930: val_loss did not improve from 1.63494\n",
      "Epoch 1931/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5033 - accuracy: 0.8830 - val_loss: 1.7731 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01931: val_loss did not improve from 1.63494\n",
      "Epoch 1932/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5020 - accuracy: 0.8830 - val_loss: 1.7845 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01932: val_loss did not improve from 1.63494\n",
      "Epoch 1933/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4997 - accuracy: 0.8772 - val_loss: 1.8004 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01933: val_loss did not improve from 1.63494\n",
      "Epoch 1934/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5010 - accuracy: 0.8713 - val_loss: 1.8065 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01934: val_loss did not improve from 1.63494\n",
      "Epoch 1935/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5007 - accuracy: 0.8830 - val_loss: 1.7923 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01935: val_loss did not improve from 1.63494\n",
      "Epoch 1936/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5013 - accuracy: 0.8830 - val_loss: 1.7906 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01936: val_loss did not improve from 1.63494\n",
      "Epoch 1937/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4993 - accuracy: 0.8889 - val_loss: 1.7759 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01937: val_loss did not improve from 1.63494\n",
      "Epoch 1938/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4997 - accuracy: 0.8772 - val_loss: 1.7754 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01938: val_loss did not improve from 1.63494\n",
      "Epoch 1939/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4990 - accuracy: 0.8889 - val_loss: 1.7710 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01939: val_loss did not improve from 1.63494\n",
      "Epoch 1940/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4962 - accuracy: 0.8889 - val_loss: 1.7781 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01940: val_loss did not improve from 1.63494\n",
      "Epoch 1941/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4963 - accuracy: 0.8889 - val_loss: 1.7795 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01941: val_loss did not improve from 1.63494\n",
      "Epoch 1942/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4967 - accuracy: 0.9006 - val_loss: 1.7785 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01942: val_loss did not improve from 1.63494\n",
      "Epoch 1943/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4974 - accuracy: 0.8772 - val_loss: 1.7742 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01943: val_loss did not improve from 1.63494\n",
      "Epoch 1944/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4960 - accuracy: 0.8889 - val_loss: 1.7839 - val_accuracy: 0.4737\n",
      "\n",
      "Epoch 01944: val_loss did not improve from 1.63494\n",
      "Epoch 1945/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4946 - accuracy: 0.8889 - val_loss: 1.7879 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01945: val_loss did not improve from 1.63494\n",
      "Epoch 1946/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4958 - accuracy: 0.8830 - val_loss: 1.7966 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01946: val_loss did not improve from 1.63494\n",
      "Epoch 1947/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4972 - accuracy: 0.8772 - val_loss: 1.7894 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01947: val_loss did not improve from 1.63494\n",
      "Epoch 1948/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4949 - accuracy: 0.8889 - val_loss: 1.7874 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01948: val_loss did not improve from 1.63494\n",
      "Epoch 1949/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4932 - accuracy: 0.8889 - val_loss: 1.7928 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01949: val_loss did not improve from 1.63494\n",
      "Epoch 1950/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4937 - accuracy: 0.8830 - val_loss: 1.7859 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01950: val_loss did not improve from 1.63494\n",
      "Epoch 1951/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4935 - accuracy: 0.8889 - val_loss: 1.7932 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01951: val_loss did not improve from 1.63494\n",
      "Epoch 1952/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4924 - accuracy: 0.8889 - val_loss: 1.7945 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01952: val_loss did not improve from 1.63494\n",
      "Epoch 1953/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4940 - accuracy: 0.8889 - val_loss: 1.7811 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01953: val_loss did not improve from 1.63494\n",
      "Epoch 1954/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4942 - accuracy: 0.8947 - val_loss: 1.7799 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01954: val_loss did not improve from 1.63494\n",
      "Epoch 1955/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4937 - accuracy: 0.8889 - val_loss: 1.7836 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01955: val_loss did not improve from 1.63494\n",
      "Epoch 1956/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4936 - accuracy: 0.8947 - val_loss: 1.7782 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01956: val_loss did not improve from 1.63494\n",
      "Epoch 1957/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4912 - accuracy: 0.8947 - val_loss: 1.7758 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01957: val_loss did not improve from 1.63494\n",
      "Epoch 1958/2000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.4901 - accuracy: 0.8889 - val_loss: 1.7762 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01958: val_loss did not improve from 1.63494\n",
      "Epoch 1959/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4924 - accuracy: 0.9006 - val_loss: 1.7570 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01959: val_loss did not improve from 1.63494\n",
      "Epoch 1960/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4952 - accuracy: 0.8889 - val_loss: 1.7550 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01960: val_loss did not improve from 1.63494\n",
      "Epoch 1961/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4932 - accuracy: 0.9064 - val_loss: 1.7735 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01961: val_loss did not improve from 1.63494\n",
      "Epoch 1962/2000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4890 - accuracy: 0.8947 - val_loss: 1.7873 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01962: val_loss did not improve from 1.63494\n",
      "Epoch 1963/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4889 - accuracy: 0.8889 - val_loss: 1.8127 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01963: val_loss did not improve from 1.63494\n",
      "Epoch 1964/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4903 - accuracy: 0.8713 - val_loss: 1.8188 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01964: val_loss did not improve from 1.63494\n",
      "Epoch 1965/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4903 - accuracy: 0.8772 - val_loss: 1.8108 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01965: val_loss did not improve from 1.63494\n",
      "Epoch 1966/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4899 - accuracy: 0.8772 - val_loss: 1.8011 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01966: val_loss did not improve from 1.63494\n",
      "Epoch 1967/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4889 - accuracy: 0.8830 - val_loss: 1.7839 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01967: val_loss did not improve from 1.63494\n",
      "Epoch 1968/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4891 - accuracy: 0.8889 - val_loss: 1.7830 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01968: val_loss did not improve from 1.63494\n",
      "Epoch 1969/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4874 - accuracy: 0.8947 - val_loss: 1.7951 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01969: val_loss did not improve from 1.63494\n",
      "Epoch 1970/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4871 - accuracy: 0.8889 - val_loss: 1.8021 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01970: val_loss did not improve from 1.63494\n",
      "Epoch 1971/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4895 - accuracy: 0.8772 - val_loss: 1.8027 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01971: val_loss did not improve from 1.63494\n",
      "Epoch 1972/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4865 - accuracy: 0.8772 - val_loss: 1.8079 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01972: val_loss did not improve from 1.63494\n",
      "Epoch 1973/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4885 - accuracy: 0.8772 - val_loss: 1.7837 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01973: val_loss did not improve from 1.63494\n",
      "Epoch 1974/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4875 - accuracy: 0.8889 - val_loss: 1.7892 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01974: val_loss did not improve from 1.63494\n",
      "Epoch 1975/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4856 - accuracy: 0.8889 - val_loss: 1.8016 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01975: val_loss did not improve from 1.63494\n",
      "Epoch 1976/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4863 - accuracy: 0.8947 - val_loss: 1.7981 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01976: val_loss did not improve from 1.63494\n",
      "Epoch 1977/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4860 - accuracy: 0.8889 - val_loss: 1.7751 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01977: val_loss did not improve from 1.63494\n",
      "Epoch 1978/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4860 - accuracy: 0.8947 - val_loss: 1.7830 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01978: val_loss did not improve from 1.63494\n",
      "Epoch 1979/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4851 - accuracy: 0.8889 - val_loss: 1.7972 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01979: val_loss did not improve from 1.63494\n",
      "Epoch 1980/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4833 - accuracy: 0.8889 - val_loss: 1.8035 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01980: val_loss did not improve from 1.63494\n",
      "Epoch 1981/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4872 - accuracy: 0.8830 - val_loss: 1.8071 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01981: val_loss did not improve from 1.63494\n",
      "Epoch 1982/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4862 - accuracy: 0.8830 - val_loss: 1.8191 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01982: val_loss did not improve from 1.63494\n",
      "Epoch 1983/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4830 - accuracy: 0.8830 - val_loss: 1.8140 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01983: val_loss did not improve from 1.63494\n",
      "Epoch 1984/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4835 - accuracy: 0.8830 - val_loss: 1.8114 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01984: val_loss did not improve from 1.63494\n",
      "Epoch 1985/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4839 - accuracy: 0.8947 - val_loss: 1.7961 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01985: val_loss did not improve from 1.63494\n",
      "Epoch 1986/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4824 - accuracy: 0.8889 - val_loss: 1.7927 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01986: val_loss did not improve from 1.63494\n",
      "Epoch 1987/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4834 - accuracy: 0.8947 - val_loss: 1.7868 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01987: val_loss did not improve from 1.63494\n",
      "Epoch 1988/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4831 - accuracy: 0.8889 - val_loss: 1.7761 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01988: val_loss did not improve from 1.63494\n",
      "Epoch 1989/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4816 - accuracy: 0.8947 - val_loss: 1.7822 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01989: val_loss did not improve from 1.63494\n",
      "Epoch 1990/2000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.4807 - accuracy: 0.8889 - val_loss: 1.7901 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01990: val_loss did not improve from 1.63494\n",
      "Epoch 1991/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4799 - accuracy: 0.9006 - val_loss: 1.7938 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 01991: val_loss did not improve from 1.63494\n",
      "Epoch 1992/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4796 - accuracy: 0.8889 - val_loss: 1.7974 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01992: val_loss did not improve from 1.63494\n",
      "Epoch 1993/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4775 - accuracy: 0.8889 - val_loss: 1.7889 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01993: val_loss did not improve from 1.63494\n",
      "Epoch 1994/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4792 - accuracy: 0.8947 - val_loss: 1.7804 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 01994: val_loss did not improve from 1.63494\n",
      "Epoch 1995/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4820 - accuracy: 0.8889 - val_loss: 1.7896 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01995: val_loss did not improve from 1.63494\n",
      "Epoch 1996/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4805 - accuracy: 0.8889 - val_loss: 1.7926 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01996: val_loss did not improve from 1.63494\n",
      "Epoch 1997/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4786 - accuracy: 0.8889 - val_loss: 1.7993 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 01997: val_loss did not improve from 1.63494\n",
      "Epoch 1998/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4786 - accuracy: 0.8889 - val_loss: 1.8070 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01998: val_loss did not improve from 1.63494\n",
      "Epoch 1999/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4775 - accuracy: 0.9006 - val_loss: 1.7902 - val_accuracy: 0.4211\n",
      "\n",
      "Epoch 01999: val_loss did not improve from 1.63494\n",
      "Epoch 2000/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4787 - accuracy: 0.9006 - val_loss: 1.7699 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 02000: val_loss did not improve from 1.63494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2184daed910>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=2000,\n",
    "    batch_size=32,\n",
    "    callbacks=[checkpoint_callback, tb_callback]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61474e21",
   "metadata": {},
   "source": [
    "## Save Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8f76ac20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T08:58:39.742207Z",
     "start_time": "2023-01-12T08:58:39.736226Z"
    }
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "81f68c5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T08:59:30.091317Z",
     "start_time": "2023-01-12T08:59:30.064297Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the best model weights\n",
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6589a532",
   "metadata": {},
   "source": [
    "## 10. Evaluation using Confusion Matrix and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "86b75086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the H5 file\n",
    "model_path = \"models/best_model_weights_ten.h5\"\n",
    "model = model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ad2f925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .npy data\n",
    "def load_data(base_data_path, actions, sequence_length):\n",
    "    label_map = {label: num for num, label in enumerate(actions)}\n",
    "    sequences, labels = [], []\n",
    "    for action in actions:\n",
    "        source_folder = os.path.join(base_data_path, action)\n",
    "        leng = len(os.listdir(source_folder))\n",
    "        for sequence in range(leng):\n",
    "            window = []\n",
    "            for frame_num in range(sequence_length):\n",
    "                frame_path = os.path.join(source_folder, str(sequence), \"{}.npy\".format(frame_num))\n",
    "                res = np.load(frame_path)\n",
    "                window.append(res)\n",
    "            sequences.append(window)\n",
    "            labels.append(label_map[action])\n",
    "    return sequences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cde64f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths to your test data and actions\n",
    "test_data_path = \"data/test\"\n",
    "actions = np.array(['book', 'drink', 'computer', 'before', 'chair', 'go', 'clothes', 'who', 'candy', 'cousin'])  # Update this list with your action names\n",
    "sequence_length = 30  # Update this with your sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7ef328b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data and convert the labels to categorical\n",
    "test_sequences, test_labels = load_data(test_data_path, actions, sequence_length)\n",
    "test_labels_categorical = to_categorical(test_labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ae30307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the sequences and labels to NumPy arrays\n",
    "X_test, y_test = np.array(test_sequences), test_labels_categorical\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Get the predicted class indices\n",
    "predicted_class_indices = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(test_labels, predicted_class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c4396148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=actions, yticklabels=actions)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "29c90091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.0938\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(test_labels, predicted_class_indices)\n",
    "print(\"Test accuracy: {:.4f}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp-tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "249.797px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
