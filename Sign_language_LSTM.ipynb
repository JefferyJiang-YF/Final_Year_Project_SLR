{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d00ef8b",
   "metadata": {},
   "source": [
    "## 1. Import and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026a05f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T04:08:25.323067Z",
     "start_time": "2023-01-12T04:08:24.567024Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pip install --user tensorflow==2.6.0 tensorflow-gpu==2.6.0 opencv-python mediapipe sklearn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8bc7e92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T08:53:52.807044Z",
     "start_time": "2023-01-15T08:53:51.645005Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a61cdf6",
   "metadata": {},
   "source": [
    "## 2. Keypoints using Mediapipe Holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5dd32af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T08:53:53.744988Z",
     "start_time": "2023-01-15T08:53:53.739007Z"
    }
   },
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic #Holistic model 整体模型mp\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities 绘图工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da11ddb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T08:53:54.398998Z",
     "start_time": "2023-01-15T08:53:54.388036Z"
    }
   },
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR Conversion BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                  # Image is now writeable\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR Conversion RGB 2  BGR\n",
    "    return image, results\n",
    "\n",
    "def draw_styled_landmarks(image, results):\n",
    "    \n",
    "     # 轮廓线 Draw face connection\n",
    "    #mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS,\n",
    "                             #mp_drawing.DrawingSpec(color=(80,110,10), thickness = 1, circle_radius = 1),\n",
    "                             #mp_drawing.DrawingSpec(color=(80,256,121), thickness = 1, circle_radius = 1))\n",
    "    \n",
    "     # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness = 2, circle_radius = 4),\n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness = 2, circle_radius = 2)) \n",
    "    \n",
    "    # draw left hand connections,\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness = 2, circle_radius = 4),\n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness = 2, circle_radius = 2))\n",
    "    \n",
    "    # draw right hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness = 2, circle_radius = 4),\n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness = 2, circle_radius = 2))\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    #如果frame中没有左手关键点就会抛出错误 注意左右手没有 res.visibility参数\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)# 压平 33 * 4\n",
    "    #face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose,face,lh,rh])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd8b2d3",
   "metadata": {},
   "source": [
    "## 4. Setup folders for collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ce4d55b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T08:54:37.196994Z",
     "start_time": "2023-01-15T08:54:37.188023Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays 制作关键点数据集文件夹\n",
    "DATA_PATH = os.path.join('MP_Data') \n",
    "\n",
    "DATA_PATH = os.path.join('data/train') \n",
    "wlasl = ['book', 'drink', 'computer', 'before', 'chair', 'go', 'clothes', 'who', 'candy', 'cousin','deaf', 'fine', 'help', 'no', 'thin', 'walk', 'year', 'yes', 'all', 'black', 'cool', 'finish', 'hot', 'like', 'many', 'mother', 'now', 'orange', 'table', 'thanksgiving', 'what', 'woman', 'bed', 'blue', 'bowling', 'can', 'dog', 'white', 'wrong', 'accident', 'apple', 'bird', 'change', 'color', 'corn', 'cow', 'dance', 'dark', 'doctor']\n",
    "# Actions that we try to detect 只需要在这里加action即可 参考路径 data\\WLASL_train下的文件名\n",
    "actions = np.array(sorted(wlasl[0:10]))\n",
    "\n",
    "# Thirty videos worth of data\n",
    "#no_sequences = 40\n",
    "\n",
    "# Videos are going to be 30 frames in length\n",
    "sequence_length = 30\n",
    "\n",
    "# Folder start\n",
    "# start_folder = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4001a4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 获取视频数据集中每条视频帧的数量，i.e.,no_fps 并保存到 fps_list\n",
    "for action in actions:\n",
    "    fps_list = []\n",
    "    for root, dirs, files in os.walk(r\"C:\\deep-learning\\HKMU\\Extrat_keypoints\\data\\WLASL_train\\{}\".format(action)):  # 这里就填文件夹目录就可以了\n",
    "        for file in files:\n",
    "            # 获取文件路径\n",
    "            if ('.mp4' in file):\n",
    "                path = os.path.join(root, file)\n",
    "                video = cv2.VideoCapture(path)\n",
    "                no_fps = video.get(7)\n",
    "                # video_fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "                fps_list.append(no_fps)\n",
    "        print(action, \"'s # of videos: \", len(files)) # 把这个数 可以作为no_sequences 视频数量 ！！注意必须与此Cell中#2 for 循环一起组合使用，否则len（files）数量不正确。原因是得不到正确的遍历，值只为最后一个动作的文件数总和\n",
    "        print(\"The frames that each video contains: \", fps_list,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "638e3844",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T08:54:41.334034Z",
     "start_time": "2023-01-15T08:54:41.277972Z"
    }
   },
   "outputs": [],
   "source": [
    "# for action in actions:\n",
    "#     for sequence in range (no_sequences):\n",
    "#         try:\n",
    "#             os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "#         except:\n",
    "#             pass\n",
    "# 制作对应手语单词的视频数量的文件夹，index 0 ~ （len - 1）\n",
    "for action in actions:\n",
    "    # NEW For loop\n",
    "    for root, dirs, files in os.walk(r\"C:\\deep-learning\\HKMU\\Extrat_keypoints\\data\\WLASL_train\\{}\".format(action)):\n",
    "        for sequence in range (len(files)):\n",
    "            try:\n",
    "                os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f907ea",
   "metadata": {},
   "source": [
    "## 5. Collect Keypoint Values for Training and Testing|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7458d91b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:05:35.941863Z",
     "start_time": "2023-01-15T08:55:39.802014Z"
    }
   },
   "outputs": [],
   "source": [
    "cap  = cv2.VideoCapture(0)\n",
    "# Set mdieapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    #NEW LOOP\n",
    "    # Loop through actions\n",
    "    for action in actions:\n",
    "        # Loop through sequnece aka videos\n",
    "        for sequence in range(no_sequences):\n",
    "            # Loop through video length aka sequence length\n",
    "            for frame_num in range(sequence_length):\n",
    "        \n",
    "                # Read feed 读取喂入模型的图片\n",
    "                ret, frame = cap.read() # !!!ret 不知道是什么参数\n",
    "\n",
    "                # Make detections\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "                print(results)\n",
    "\n",
    "                # Draw landmarks\n",
    "                draw_styled_landmarks(image, results)\n",
    "                \n",
    "                # NEW Apply wait logic\n",
    "                if frame_num == 0:\n",
    "                    cv2.putText(image, 'START COLLECTION', (120,200),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 4, cv2.LINE_AA)\n",
    "                    cv2.putText(image, 'Collecting frmaes for {} video Number {}'.format(action,sequence), (15,12),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    # Show to screen\n",
    "                    cv2.imshow(\"OpenCV feed\", image)                    \n",
    "                    cv2.waitKey(2000)\n",
    "                else:\n",
    "                    cv2.putText(image, 'Collecting frmaes for {} video Number {}'.format(action,sequence), (15,12),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    # Show to screen\n",
    "                    cv2.imshow(\"OpenCV feed\", image)   \n",
    "                    \n",
    "                # NEW export keypoints   \n",
    "                keypoints = extract_keypoints(results)\n",
    "                npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
    "                np.save(npy_path, keypoints)\n",
    "\n",
    "                # Break gracefully 优雅地中断\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7e948b",
   "metadata": {},
   "source": [
    "## 6. Preprocess Data and Create Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "056be4cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:06:02.288957Z",
     "start_time": "2023-01-15T09:05:47.251110Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical ##与Up主不一致的新的import方法\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a55389c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:06:04.230877Z",
     "start_time": "2023-01-15T09:06:04.220911Z"
    }
   },
   "outputs": [],
   "source": [
    "def label_data(base_data_path, actions, sequence_length):\n",
    "    label_map = {label: num for num, label in enumerate(actions)}\n",
    "    sequences, labels = [], []\n",
    "    for action in actions:\n",
    "        source_folder = os.path.join(base_data_path, action)\n",
    "        leng = len(os.listdir(source_folder))\n",
    "        for sequence in range(leng):\n",
    "            window = []\n",
    "            for frame_num in range(sequence_length):\n",
    "                frame_path = os.path.join(source_folder, str(sequence), \"{}.npy\".format(frame_num))\n",
    "                res = np.load(frame_path)\n",
    "                window.append(res)\n",
    "            sequences.append(window)\n",
    "            labels.append(label_map[action])\n",
    "    print(label_map)\n",
    "    return sequences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac0fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"data/train\"\n",
    "val_data_path = \"data/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a517d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'before': 0, 'book': 1, 'candy': 2, 'chair': 3, 'clothes': 4, 'computer': 5, 'cousin': 6, 'drink': 7, 'go': 8, 'who': 9}\n",
      "{'before': 0, 'book': 1, 'candy': 2, 'chair': 3, 'clothes': 4, 'computer': 5, 'cousin': 6, 'drink': 7, 'go': 8, 'who': 9}\n"
     ]
    }
   ],
   "source": [
    "train_sequences, train_labels = label_data(train_data_path, actions, sequence_length)\n",
    "val_sequences, val_labels = label_data(val_data_path, actions, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73b3659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to_categorical(labels).astype(int) on labels\n",
    "train_labels_categorical = to_categorical(train_labels).astype(int)\n",
    "val_labels_categorical = to_categorical(val_labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75abc1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(train_sequences),train_labels_categorical\n",
    "X_val, y_val = np.array(val_sequences), val_labels_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b73198",
   "metadata": {},
   "source": [
    "## 7. Build and Train LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35120426",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:07:04.827943Z",
     "start_time": "2023-01-15T09:07:04.814988Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential # allow us to build a sequential neural network\n",
    "from tensorflow.python.keras.layers import LSTM, Dense,Dropout # LSTM: temoporal component, Dense: a normal fully connected layer\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint # allow us to perform some logging inside, trace and monitor our model as its training\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "648111ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:07:06.339016Z",
     "start_time": "2023-01-15T09:07:06.239069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-10-14-29\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "log_dir = os.path.join('Logs', \"LSTM\",now.strftime(\"%Y-%m-%d-%H-%M-L2\"))\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "print(now.strftime(\"%Y-%m-%d-%H-%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "53395f4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:07:10.431039Z",
     "start_time": "2023-01-15T09:07:09.499971Z"
    }
   },
   "outputs": [],
   "source": [
    "# dropout_rate = 0.5\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30, 258))) # 64 LSTM units not layers 30 frames with 1662 param\n",
    "# model.add(Dropout(dropout_rate))\n",
    "# model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "# model.add(Dropout(dropout_rate))\n",
    "# model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "# model.add(Dropout(dropout_rate))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(dropout_rate))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(dropout_rate))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dropout(dropout_rate))\n",
    "# model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f74d9b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "reg_strength = 0.001\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30, 258), kernel_regularizer=l2(reg_strength))) # 64 LSTM units not layers 30 frames with 1662 param\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu', kernel_regularizer=l2(reg_strength)))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu', kernel_regularizer=l2(reg_strength)))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(reg_strength)))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(reg_strength)))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=l2(reg_strength)))\n",
    "model.add(Dense(actions.shape[0], activation='softmax', kernel_regularizer=l2(reg_strength)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "accc22f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:07:20.027889Z",
     "start_time": "2023-01-15T09:07:19.994002Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',  \n",
    "loss='categorical_crossentropy', \n",
    "metrics = ['accuracy']) #多类别的loss使用中间的，二分的类别使用binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3dce3230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the ModelCheckpoint callback\n",
    "checkpoint_filepath = (\"models/LSTM/best_model_weights.h5\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "23bb5588",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:15:36.389020Z",
     "start_time": "2023-01-15T09:07:28.159038Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 12s 1s/step - loss: 2.9993 - accuracy: 0.0702 - val_loss: 2.9165 - val_accuracy: 0.0789\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 2.8624 - accuracy: 0.1111 - val_loss: 2.8312 - val_accuracy: 0.0526\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 6s 972ms/step - loss: 2.8077 - accuracy: 0.1287 - val_loss: 2.7763 - val_accuracy: 0.1053\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.7680 - accuracy: 0.1345 - val_loss: 2.6777 - val_accuracy: 0.1579\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.6500 - accuracy: 0.1871 - val_loss: 2.7291 - val_accuracy: 0.1579\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.6996 - accuracy: 0.1930 - val_loss: 2.6020 - val_accuracy: 0.1316\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 6s 978ms/step - loss: 2.7903 - accuracy: 0.2164 - val_loss: 2.6069 - val_accuracy: 0.1053\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 2.4832 - accuracy: 0.1637 - val_loss: 2.5688 - val_accuracy: 0.1316\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.4653 - accuracy: 0.1754 - val_loss: 2.4792 - val_accuracy: 0.1316\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 2.3985 - accuracy: 0.1930 - val_loss: 2.4494 - val_accuracy: 0.1579\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 2.3448 - accuracy: 0.1930 - val_loss: 2.4207 - val_accuracy: 0.1053\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 2.3409 - accuracy: 0.1579 - val_loss: 2.3786 - val_accuracy: 0.1842\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.2397 - accuracy: 0.1871 - val_loss: 2.3478 - val_accuracy: 0.2632\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.2308 - accuracy: 0.2690 - val_loss: 2.3369 - val_accuracy: 0.1842\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.1758 - accuracy: 0.3041 - val_loss: 2.3353 - val_accuracy: 0.1842\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 2.1255 - accuracy: 0.3099 - val_loss: 2.3497 - val_accuracy: 0.1842\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 2.1352 - accuracy: 0.2573 - val_loss: 2.2831 - val_accuracy: 0.1316\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.0587 - accuracy: 0.2807 - val_loss: 2.2208 - val_accuracy: 0.2368\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.0794 - accuracy: 0.2865 - val_loss: 2.2955 - val_accuracy: 0.2368\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 2.1057 - accuracy: 0.2690 - val_loss: 2.2372 - val_accuracy: 0.2105\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.0549 - accuracy: 0.2982 - val_loss: 2.2457 - val_accuracy: 0.1842\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.0336 - accuracy: 0.2749 - val_loss: 2.1511 - val_accuracy: 0.1579\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.0210 - accuracy: 0.3450 - val_loss: 2.2144 - val_accuracy: 0.2895\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.0513 - accuracy: 0.3275 - val_loss: 2.1447 - val_accuracy: 0.2632\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.0356 - accuracy: 0.2807 - val_loss: 2.2442 - val_accuracy: 0.1842\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.0771 - accuracy: 0.2924 - val_loss: 2.3590 - val_accuracy: 0.1842\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.0516 - accuracy: 0.2924 - val_loss: 2.2319 - val_accuracy: 0.2895\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.9966 - accuracy: 0.3158 - val_loss: 2.1108 - val_accuracy: 0.3158\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.9411 - accuracy: 0.3684 - val_loss: 2.0885 - val_accuracy: 0.3158\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.8809 - accuracy: 0.3626 - val_loss: 2.0344 - val_accuracy: 0.3158\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.8506 - accuracy: 0.3333 - val_loss: 2.1606 - val_accuracy: 0.2105\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.9542 - accuracy: 0.3041 - val_loss: 2.3581 - val_accuracy: 0.2105\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.0492 - accuracy: 0.2690 - val_loss: 2.2706 - val_accuracy: 0.1316\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.1940 - accuracy: 0.1930 - val_loss: 2.2777 - val_accuracy: 0.1053\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.1207 - accuracy: 0.2398 - val_loss: 2.3753 - val_accuracy: 0.1579\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.1328 - accuracy: 0.2281 - val_loss: 2.1974 - val_accuracy: 0.1579\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.0467 - accuracy: 0.2807 - val_loss: 2.2985 - val_accuracy: 0.2105\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.9777 - accuracy: 0.3041 - val_loss: 2.1866 - val_accuracy: 0.2368\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.9019 - accuracy: 0.3158 - val_loss: 2.2020 - val_accuracy: 0.1316\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.8808 - accuracy: 0.3041 - val_loss: 2.2110 - val_accuracy: 0.1579\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.9570 - accuracy: 0.3099 - val_loss: 2.2686 - val_accuracy: 0.1842\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 2.1813 - accuracy: 0.2105 - val_loss: 2.1864 - val_accuracy: 0.1579\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.0374 - accuracy: 0.2515 - val_loss: 2.2558 - val_accuracy: 0.1842\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.0253 - accuracy: 0.2749 - val_loss: 2.2556 - val_accuracy: 0.1579\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.0065 - accuracy: 0.2749 - val_loss: 2.1816 - val_accuracy: 0.1579\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.9743 - accuracy: 0.2749 - val_loss: 2.1757 - val_accuracy: 0.1579\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.9413 - accuracy: 0.2807 - val_loss: 2.1461 - val_accuracy: 0.1842\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.8886 - accuracy: 0.2865 - val_loss: 2.1681 - val_accuracy: 0.2368\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.9789 - accuracy: 0.2573 - val_loss: 2.1750 - val_accuracy: 0.1579\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.9302 - accuracy: 0.3333 - val_loss: 2.1560 - val_accuracy: 0.2105\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.9048 - accuracy: 0.2807 - val_loss: 2.1164 - val_accuracy: 0.2105\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.8573 - accuracy: 0.3099 - val_loss: 2.2581 - val_accuracy: 0.2105\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.8319 - accuracy: 0.3216 - val_loss: 2.2525 - val_accuracy: 0.1842\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.9121 - accuracy: 0.2924 - val_loss: 2.1779 - val_accuracy: 0.1579\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.8701 - accuracy: 0.3567 - val_loss: 2.2190 - val_accuracy: 0.2105\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.8351 - accuracy: 0.3450 - val_loss: 2.1751 - val_accuracy: 0.1316\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.8087 - accuracy: 0.3743 - val_loss: 2.1377 - val_accuracy: 0.2368\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.9614 - accuracy: 0.3743 - val_loss: 2.1529 - val_accuracy: 0.2105\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.9359 - accuracy: 0.2690 - val_loss: 2.3003 - val_accuracy: 0.1842\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.9199 - accuracy: 0.2515 - val_loss: 2.1435 - val_accuracy: 0.1316\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.8165 - accuracy: 0.3275 - val_loss: 2.1606 - val_accuracy: 0.2368\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.7985 - accuracy: 0.3509 - val_loss: 2.1309 - val_accuracy: 0.1842\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.7903 - accuracy: 0.3450 - val_loss: 2.1711 - val_accuracy: 0.1842\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.8876 - accuracy: 0.3216 - val_loss: 2.2445 - val_accuracy: 0.1842\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.9209 - accuracy: 0.2690 - val_loss: 2.5702 - val_accuracy: 0.2368\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 2.0383 - accuracy: 0.2807 - val_loss: 2.2013 - val_accuracy: 0.2105\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.9153 - accuracy: 0.3041 - val_loss: 2.3280 - val_accuracy: 0.1053\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.8879 - accuracy: 0.3275 - val_loss: 2.1290 - val_accuracy: 0.1842\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.8504 - accuracy: 0.3392 - val_loss: 2.1030 - val_accuracy: 0.1579\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.8262 - accuracy: 0.3743 - val_loss: 2.1319 - val_accuracy: 0.2105\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.8174 - accuracy: 0.3392 - val_loss: 2.1910 - val_accuracy: 0.1053\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.7753 - accuracy: 0.3684 - val_loss: 2.1439 - val_accuracy: 0.1579\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.7772 - accuracy: 0.3743 - val_loss: 2.1452 - val_accuracy: 0.1842\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.7386 - accuracy: 0.3684 - val_loss: 2.2891 - val_accuracy: 0.1579\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.7888 - accuracy: 0.3626 - val_loss: 2.1503 - val_accuracy: 0.1842\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.8840 - accuracy: 0.3509 - val_loss: 2.3741 - val_accuracy: 0.2105\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.8607 - accuracy: 0.3333 - val_loss: 2.1763 - val_accuracy: 0.1579\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.8179 - accuracy: 0.3099 - val_loss: 2.1212 - val_accuracy: 0.1842\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.7620 - accuracy: 0.3860 - val_loss: 2.1616 - val_accuracy: 0.1579\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.7676 - accuracy: 0.3392 - val_loss: 2.1833 - val_accuracy: 0.1053\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.7120 - accuracy: 0.3977 - val_loss: 2.2344 - val_accuracy: 0.1316\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.6970 - accuracy: 0.3684 - val_loss: 2.3714 - val_accuracy: 0.1579\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.6768 - accuracy: 0.4035 - val_loss: 2.2934 - val_accuracy: 0.1316\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.6557 - accuracy: 0.4035 - val_loss: 2.5096 - val_accuracy: 0.1842\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.6325 - accuracy: 0.4327 - val_loss: 2.2540 - val_accuracy: 0.1316\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.6789 - accuracy: 0.3977 - val_loss: 2.6242 - val_accuracy: 0.2632\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.7782 - accuracy: 0.3509 - val_loss: 2.5317 - val_accuracy: 0.1316\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.8481 - accuracy: 0.3333 - val_loss: 2.3375 - val_accuracy: 0.2105\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.7973 - accuracy: 0.3216 - val_loss: 2.3217 - val_accuracy: 0.1579\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.6521 - accuracy: 0.4327 - val_loss: 2.5771 - val_accuracy: 0.2105\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.8217 - accuracy: 0.3801 - val_loss: 2.3584 - val_accuracy: 0.1579\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.9165 - accuracy: 0.3216 - val_loss: 2.4022 - val_accuracy: 0.1579\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.8267 - accuracy: 0.3743 - val_loss: 2.3119 - val_accuracy: 0.2105\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.7861 - accuracy: 0.3684 - val_loss: 2.2483 - val_accuracy: 0.2105\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.7034 - accuracy: 0.4152 - val_loss: 2.1836 - val_accuracy: 0.2368\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.6677 - accuracy: 0.4035 - val_loss: 2.1460 - val_accuracy: 0.2105\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.6711 - accuracy: 0.4094 - val_loss: 2.5739 - val_accuracy: 0.2105\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.7499 - accuracy: 0.3743 - val_loss: 2.5426 - val_accuracy: 0.2368\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.7754 - accuracy: 0.3684 - val_loss: 2.2059 - val_accuracy: 0.1579\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.7255 - accuracy: 0.3801 - val_loss: 2.2957 - val_accuracy: 0.1842\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.6507 - accuracy: 0.4503 - val_loss: 2.3488 - val_accuracy: 0.1579\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.6401 - accuracy: 0.3801 - val_loss: 2.2556 - val_accuracy: 0.1316\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.5842 - accuracy: 0.4327 - val_loss: 2.3244 - val_accuracy: 0.2368\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.5353 - accuracy: 0.4503 - val_loss: 2.3442 - val_accuracy: 0.2105\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.5777 - accuracy: 0.4561 - val_loss: 2.6836 - val_accuracy: 0.2368\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.5733 - accuracy: 0.4620 - val_loss: 2.3348 - val_accuracy: 0.2632\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.5655 - accuracy: 0.4269 - val_loss: 2.1861 - val_accuracy: 0.2632\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.5598 - accuracy: 0.4211 - val_loss: 3.1157 - val_accuracy: 0.2632\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.1115 - accuracy: 0.3216 - val_loss: 2.2769 - val_accuracy: 0.1842\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.0404 - accuracy: 0.2924 - val_loss: 2.0717 - val_accuracy: 0.2895\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.8688 - accuracy: 0.3567 - val_loss: 2.2904 - val_accuracy: 0.3158\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.8168 - accuracy: 0.3626 - val_loss: 2.0761 - val_accuracy: 0.2368\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.7410 - accuracy: 0.4094 - val_loss: 2.0236 - val_accuracy: 0.2632\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.6926 - accuracy: 0.4035 - val_loss: 2.2364 - val_accuracy: 0.2105\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.7093 - accuracy: 0.3860 - val_loss: 2.0501 - val_accuracy: 0.2632\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.7091 - accuracy: 0.4035 - val_loss: 2.1315 - val_accuracy: 0.2368\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.9603 - accuracy: 0.3684 - val_loss: 2.4618 - val_accuracy: 0.1579\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.7500 - accuracy: 0.3743 - val_loss: 2.5429 - val_accuracy: 0.1579\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.6773 - accuracy: 0.4094 - val_loss: 2.4865 - val_accuracy: 0.2105\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.5927 - accuracy: 0.4269 - val_loss: 2.4854 - val_accuracy: 0.1316\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.5194 - accuracy: 0.4444 - val_loss: 2.7461 - val_accuracy: 0.2105\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.5136 - accuracy: 0.5205 - val_loss: 2.6057 - val_accuracy: 0.1579\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.5517 - accuracy: 0.4327 - val_loss: 2.5251 - val_accuracy: 0.2105\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.5206 - accuracy: 0.4795 - val_loss: 2.9739 - val_accuracy: 0.1579\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.4648 - accuracy: 0.4678 - val_loss: 2.4465 - val_accuracy: 0.2368\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.4608 - accuracy: 0.5088 - val_loss: 2.5850 - val_accuracy: 0.3421\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.3807 - accuracy: 0.4854 - val_loss: 2.5691 - val_accuracy: 0.2105\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.3582 - accuracy: 0.5439 - val_loss: 2.5987 - val_accuracy: 0.2632\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.3211 - accuracy: 0.5731 - val_loss: 2.7438 - val_accuracy: 0.3158\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.5571 - accuracy: 0.5146 - val_loss: 2.6060 - val_accuracy: 0.2105\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.7242 - accuracy: 0.4503 - val_loss: 2.8384 - val_accuracy: 0.2105\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.5899 - accuracy: 0.4678 - val_loss: 2.5956 - val_accuracy: 0.2368\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.5692 - accuracy: 0.4620 - val_loss: 2.3777 - val_accuracy: 0.2632\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.4242 - accuracy: 0.5263 - val_loss: 2.7044 - val_accuracy: 0.2895\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.3874 - accuracy: 0.5439 - val_loss: 2.8425 - val_accuracy: 0.2368\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.3538 - accuracy: 0.5380 - val_loss: 2.5776 - val_accuracy: 0.2632\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.3924 - accuracy: 0.5322 - val_loss: 2.5304 - val_accuracy: 0.3158\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.2706 - accuracy: 0.5673 - val_loss: 3.0169 - val_accuracy: 0.2105\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.5423 - accuracy: 0.4737 - val_loss: 3.7067 - val_accuracy: 0.2632\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.5179 - accuracy: 0.4561 - val_loss: 2.4724 - val_accuracy: 0.3158\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.4509 - accuracy: 0.4912 - val_loss: 3.1794 - val_accuracy: 0.2105\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.4713 - accuracy: 0.4912 - val_loss: 2.3122 - val_accuracy: 0.2895\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.4800 - accuracy: 0.4912 - val_loss: 2.5185 - val_accuracy: 0.2632\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.3879 - accuracy: 0.5322 - val_loss: 2.7413 - val_accuracy: 0.2632\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.3136 - accuracy: 0.5556 - val_loss: 2.3627 - val_accuracy: 0.3158\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.2785 - accuracy: 0.5848 - val_loss: 2.9519 - val_accuracy: 0.2895\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.2696 - accuracy: 0.5848 - val_loss: 2.7379 - val_accuracy: 0.2895\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.3545 - accuracy: 0.5146 - val_loss: 3.2372 - val_accuracy: 0.2632\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.4780 - accuracy: 0.4795 - val_loss: 5.5540 - val_accuracy: 0.1842\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 3.4415 - accuracy: 0.2339 - val_loss: 2.9150 - val_accuracy: 0.1579\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.1937 - accuracy: 0.3158 - val_loss: 2.2980 - val_accuracy: 0.1053\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 2.2028 - accuracy: 0.2339 - val_loss: 2.5087 - val_accuracy: 0.1316\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.9580 - accuracy: 0.2749 - val_loss: 3.3892 - val_accuracy: 0.1316\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.9551 - accuracy: 0.2456 - val_loss: 3.5097 - val_accuracy: 0.1842\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.9203 - accuracy: 0.3509 - val_loss: 3.0868 - val_accuracy: 0.2368\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.8316 - accuracy: 0.3801 - val_loss: 3.6341 - val_accuracy: 0.1842\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.7719 - accuracy: 0.4094 - val_loss: 3.5870 - val_accuracy: 0.1579\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.7904 - accuracy: 0.4094 - val_loss: 2.8792 - val_accuracy: 0.2105\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.7641 - accuracy: 0.3860 - val_loss: 3.3412 - val_accuracy: 0.2105\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.6913 - accuracy: 0.4444 - val_loss: 3.2121 - val_accuracy: 0.2368\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.6550 - accuracy: 0.4678 - val_loss: 3.1253 - val_accuracy: 0.2895\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.7098 - accuracy: 0.4152 - val_loss: 3.2505 - val_accuracy: 0.2368\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.9113 - accuracy: 0.3275 - val_loss: 2.7665 - val_accuracy: 0.2632\n",
      "Epoch 164/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.8426 - accuracy: 0.3509 - val_loss: 3.0248 - val_accuracy: 0.2368\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.7818 - accuracy: 0.3918 - val_loss: 3.9327 - val_accuracy: 0.1579\n",
      "Epoch 166/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.7524 - accuracy: 0.4094 - val_loss: 3.4563 - val_accuracy: 0.1842\n",
      "Epoch 167/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.6959 - accuracy: 0.4152 - val_loss: 3.6965 - val_accuracy: 0.1842\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.7402 - accuracy: 0.4035 - val_loss: 3.4516 - val_accuracy: 0.2105\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.6693 - accuracy: 0.4386 - val_loss: 5.8650 - val_accuracy: 0.2368\n",
      "Epoch 170/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.6675 - accuracy: 0.4444 - val_loss: 5.9716 - val_accuracy: 0.2368\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.6432 - accuracy: 0.4269 - val_loss: 4.9455 - val_accuracy: 0.2632\n",
      "Epoch 172/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.7093 - accuracy: 0.3801 - val_loss: 4.3095 - val_accuracy: 0.2368\n",
      "Epoch 173/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.6020 - accuracy: 0.4386 - val_loss: 4.8538 - val_accuracy: 0.2368\n",
      "Epoch 174/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.5591 - accuracy: 0.4678 - val_loss: 5.4730 - val_accuracy: 0.2895\n",
      "Epoch 175/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.5584 - accuracy: 0.4620 - val_loss: 5.8075 - val_accuracy: 0.2632\n",
      "Epoch 176/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.5263 - accuracy: 0.4561 - val_loss: 5.2562 - val_accuracy: 0.2368\n",
      "Epoch 177/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.6976 - accuracy: 0.4386 - val_loss: 4.2364 - val_accuracy: 0.2632\n",
      "Epoch 178/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.1497 - accuracy: 0.2749 - val_loss: 3.1477 - val_accuracy: 0.1316\n",
      "Epoch 179/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.8850 - accuracy: 0.3801 - val_loss: 2.1852 - val_accuracy: 0.2105\n",
      "Epoch 180/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.7020 - accuracy: 0.3977 - val_loss: 2.1698 - val_accuracy: 0.1579\n",
      "Epoch 181/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.7129 - accuracy: 0.4035 - val_loss: 2.1638 - val_accuracy: 0.2368\n",
      "Epoch 182/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.7058 - accuracy: 0.4327 - val_loss: 2.2764 - val_accuracy: 0.2368\n",
      "Epoch 183/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.6740 - accuracy: 0.4094 - val_loss: 2.3907 - val_accuracy: 0.1842\n",
      "Epoch 184/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.6140 - accuracy: 0.4211 - val_loss: 2.2570 - val_accuracy: 0.2368\n",
      "Epoch 185/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.5647 - accuracy: 0.4444 - val_loss: 2.4856 - val_accuracy: 0.2632\n",
      "Epoch 186/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.5156 - accuracy: 0.4971 - val_loss: 2.4210 - val_accuracy: 0.3158\n",
      "Epoch 187/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.4891 - accuracy: 0.4737 - val_loss: 2.5674 - val_accuracy: 0.2895\n",
      "Epoch 188/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.4859 - accuracy: 0.4620 - val_loss: 2.7297 - val_accuracy: 0.2105\n",
      "Epoch 189/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.5242 - accuracy: 0.4971 - val_loss: 2.4542 - val_accuracy: 0.3421\n",
      "Epoch 190/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.4727 - accuracy: 0.5088 - val_loss: 2.5670 - val_accuracy: 0.2895\n",
      "Epoch 191/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.4835 - accuracy: 0.4678 - val_loss: 2.8736 - val_accuracy: 0.2368\n",
      "Epoch 192/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.4561 - accuracy: 0.5029 - val_loss: 2.6149 - val_accuracy: 0.2895\n",
      "Epoch 193/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.3964 - accuracy: 0.5263 - val_loss: 2.6230 - val_accuracy: 0.2368\n",
      "Epoch 194/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.7414 - accuracy: 0.4327 - val_loss: 2.4547 - val_accuracy: 0.2368\n",
      "Epoch 195/200\n",
      "6/6 [==============================] - 6s 1s/step - loss: 1.7785 - accuracy: 0.3743 - val_loss: 2.3292 - val_accuracy: 0.2368\n",
      "Epoch 196/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.6764 - accuracy: 0.4386 - val_loss: 2.0425 - val_accuracy: 0.2632\n",
      "Epoch 197/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.6358 - accuracy: 0.4386 - val_loss: 1.9777 - val_accuracy: 0.2105\n",
      "Epoch 198/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.6176 - accuracy: 0.4211 - val_loss: 2.0392 - val_accuracy: 0.2895\n",
      "Epoch 199/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.5484 - accuracy: 0.4620 - val_loss: 2.0333 - val_accuracy: 0.2895\n",
      "Epoch 200/200\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.5125 - accuracy: 0.4854 - val_loss: 2.1719 - val_accuracy: 0.2368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2d1dca095e0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=200, \n",
    "    callbacks = [tb_callback],\n",
    "    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab299f12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T08:51:58.867225Z",
     "start_time": "2023-01-12T08:51:58.857258Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 30, 64)            82688     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 30, 128)           98816     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 241,642\n",
      "Trainable params: 241,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e05134d",
   "metadata": {},
   "source": [
    "## 8. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a40f33fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:18:23.276153Z",
     "start_time": "2023-01-15T09:18:22.891000Z"
    }
   },
   "outputs": [],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e7ca17f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:18:26.762002Z",
     "start_time": "2023-01-15T09:18:26.749088Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2ce420c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:18:29.186038Z",
     "start_time": "2023-01-15T09:18:29.177068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(y_test[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61474e21",
   "metadata": {},
   "source": [
    "## 9. Save Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9fe10f35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T08:57:36.403310Z",
     "start_time": "2023-01-12T08:57:36.360222Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('action_220_5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f76ac20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T08:58:39.742207Z",
     "start_time": "2023-01-12T08:58:39.736226Z"
    }
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "81f68c5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T08:59:30.091317Z",
     "start_time": "2023-01-12T08:59:30.064297Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights('action_220_3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6589a532",
   "metadata": {},
   "source": [
    "## 10. Evaluation using Confusion Matrix and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9c7a97dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T09:00:14.626139Z",
     "start_time": "2023-01-12T09:00:14.613183Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0b5f02c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T09:06:39.943160Z",
     "start_time": "2023-01-12T09:06:39.832313Z"
    }
   },
   "outputs": [],
   "source": [
    "yhat = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "247bab9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T09:06:41.959068Z",
     "start_time": "2023-01-12T09:06:41.942255Z"
    }
   },
   "outputs": [],
   "source": [
    "ytrue = np.argmax(y_train, axis = 1).tolist()\n",
    "yhat = np.argmax(yhat, axis = 1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9a1a15c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T09:06:44.310691Z",
     "start_time": "2023-01-12T09:06:44.301478Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1, 28],\n",
       "        [ 1, 37]],\n",
       "\n",
       "       [[49,  1],\n",
       "        [16,  1]],\n",
       "\n",
       "       [[55,  0],\n",
       "        [12,  0]]], dtype=int64)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0881e297",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T09:07:02.999281Z",
     "start_time": "2023-01-12T09:07:02.993302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5671641791044776"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac84eacf",
   "metadata": {},
   "source": [
    "## 11 . Test in Real Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e11de749",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T09:18:38.917901Z",
     "start_time": "2023-01-15T09:18:38.898966Z"
    }
   },
   "outputs": [],
   "source": [
    "colors = [(245,117,16), (117,245,16), (16,117,245)]\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3964e84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T07:27:28.516382Z",
     "start_time": "2023-01-22T07:27:28.267420Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. New detection variables\n",
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.95\n",
    "\n",
    "cap  = cv2.VideoCapture(0)\n",
    "# Set mdieapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        \n",
    "        # Read feed 读取喂入模型的图片\n",
    "        ret, frame = cap.read() # !!!ret 不知道是什么参数\n",
    "        \n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        print(results)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        # 2. Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "#         sequence.insert(0,keypoints)\n",
    "#         sequence = sequence[:30]\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "        \n",
    "        if len(sequence) == 30:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(actions[np.argmax(res)])\n",
    "            \n",
    "        #3. Viz logic\n",
    "            if res[np.argmax(res)] > threshold: \n",
    "                if len(sentence) > 0: \n",
    "                    if actions[np.argmax(res)] != sentence[-1]:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "                else:\n",
    "                    sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "            if len(sentence) > 5: \n",
    "                sentence = sentence[-5:]\n",
    "\n",
    "            # Viz probabilities\n",
    "            image = prob_viz(res, actions, image, colors)\n",
    "            \n",
    "        cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Show to screen\n",
    "        cv2.imshow(\"OpenCV feed\", image)\n",
    "\n",
    "        # Break gracefully 优雅地中断\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04be3a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1662)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp-tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "249.797px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
